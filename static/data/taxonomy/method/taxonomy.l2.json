[
  {
    "topic_id": 0,
    "size": 181,
    "keywords": [
      "temporal",
      "spatiotemporal",
      "pooling",
      "multihead",
      "spatiotemporal feature",
      "multihead attention",
      "attention",
      "lstm",
      "interpolation",
      "temporal modeling"
    ],
    "examples": [
      "boosted spatiotemporal feature extraction",
      "boosted spatiotemporal feature extraction",
      "dual-sequence labeling synchronization",
      "temporal feature pooling",
      "temporal interpolation techniques",
      "temporal interpolation techniques",
      "implicit sequence learning paradigm",
      "temporal interpolation modeling"
    ],
    "topic_fingerprint": "68e0b414711108625234fc7095f89552f110ae6314c817af30f823d39da7747a",
    "l2_name": "Temporal Modeling",
    "definition": "Methods designed to capture, extract, and fuse temporal or spatiotemporal dependencies in sequential data using techniques such as attention mechanisms, recurrent networks, pooling, and interpolation.",
    "aliases": [
      "temporal analysis",
      "spatiotemporal modeling",
      "sequence modeling",
      "temporal feature extraction",
      "temporal fusion",
      "implicit sequence learning",
      "temporal interpolation",
      "spatiotemporal feature learning"
    ]
  },
  {
    "topic_id": 1,
    "size": 127,
    "keywords": [
      "speech",
      "acoustic",
      "audiovisual",
      "audiovisual feature",
      "audio",
      "prosody",
      "prosodic",
      "speech synthesis",
      "synthesis",
      "extraction"
    ],
    "examples": [
      "acoustic low-level feature extraction",
      "intonation modeling",
      "prosodic feature extraction",
      "nonlinear prosody modeling",
      "audio-visual modality fusion",
      "emotional speech synthesis",
      "audio-visual feature analysis",
      "segmental cepstral-based features"
    ],
    "topic_fingerprint": "113bfbf16f2dcb378076a1bba2a01d800d85aa9dd5c797285ccfa1619d09cf90",
    "l2_name": "Speech Feature Extraction and Synthesis",
    "definition": "This method involves the computational analysis, modeling, and generation of acoustic, prosodic, and audiovisual characteristics of human speech.",
    "aliases": [
      "acoustic feature extraction",
      "prosody modeling",
      "speech synthesis",
      "audiovisual speech analysis",
      "prosodic feature extraction",
      "low-level speech feature extraction",
      "emotional speech synthesis",
      "audio-visual modality fusion",
      "cepstral feature extraction",
      "prosody transformation"
    ]
  },
  {
    "topic_id": 2,
    "size": 95,
    "keywords": [
      "evaluation",
      "benchmark",
      "benchmarking",
      "baseline",
      "performance",
      "evaluation baseline",
      "protocols",
      "unified",
      "performance evaluation",
      "benchmark dataset"
    ],
    "examples": [
      "synthesis result evaluation",
      "challenge benchmark evaluation",
      "correlation-based performance evaluation",
      "gold standard comparison",
      "baseline detection and recognition benchmarking",
      "baseline performance evaluation",
      "practice-based training protocols",
      "comprehensive benchmark creation"
    ],
    "topic_fingerprint": "1be515efa931e2605dbac359aa7057e093ec4ee96c83dc6a93174b0c4ad93162",
    "l2_name": "Benchmarking and Evaluation",
    "definition": "The systematic assessment of system performance against established baselines, standardized datasets, and defined protocols.",
    "aliases": [
      "performance evaluation",
      "benchmarking",
      "baseline evaluation",
      "benchmark dataset analysis",
      "evaluation protocols",
      "gold standard comparison",
      "comprehensive benchmarking"
    ]
  },
  {
    "topic_id": 3,
    "size": 65,
    "keywords": [
      "feature extraction",
      "extraction",
      "feature",
      "principlesofart feature",
      "principlesofart",
      "extraction principlesofart",
      "extraction techniques",
      "extraction hybrid",
      "stateoftheart feature",
      "extraction feature"
    ],
    "examples": [
      "multidimensional feature extraction",
      "nonlinear feature extraction",
      "gabor wavelet features",
      "principles-of-art feature extraction",
      "principles-of-art feature extraction",
      "harris 3d feature detection",
      "computer vision feature extraction",
      "monogenic filter feature extraction"
    ],
    "topic_fingerprint": "07b58ea33552e649954ff812ae8575508f2cc0a8169ae119a075526130eef8a7",
    "l2_name": "Feature Extraction",
    "definition": "The process of transforming raw data into a reduced set of informative features that capture the essential characteristics of the input for analysis or classification.",
    "aliases": [
      "feature extraction techniques",
      "multidimensional feature extraction",
      "nonlinear feature extraction",
      "extraction methods",
      "feature detection",
      "feature analysis",
      "principles-of-art feature extraction"
    ]
  },
  {
    "topic_id": 4,
    "size": 58,
    "keywords": [
      "multitask",
      "multitask learning",
      "multimodal transformer",
      "framework multitask",
      "framework",
      "learning framework",
      "learning multitask",
      "transformer",
      "multitask transformer",
      "inverted teacherstudent"
    ],
    "examples": [
      "cascaded task framework",
      "multi-task learning",
      "multi-task learning framework",
      "shared task evaluation framework",
      "multi-task joint optimization",
      "multi-task learning strategy",
      "multi-task deep framework",
      "multi-task convolutional neural network"
    ],
    "topic_fingerprint": "781eaae924536e513fac4129063f59bb7275ddb3afb82ed0975b4d7a085afbb0",
    "l2_name": "Multi-task Learning Framework",
    "definition": "A computational architecture designed to jointly optimize multiple related tasks by sharing representations and parameters within a unified model structure.",
    "aliases": [
      "multitask learning",
      "multi-task framework",
      "joint optimization framework",
      "multitask transformer",
      "shared task evaluation framework",
      "end-to-end multi-task learning",
      "multimodal multitask framework"
    ]
  },
  {
    "topic_id": 5,
    "size": 51,
    "keywords": [
      "emotion",
      "emotion feature",
      "learning emotion",
      "extraction emotion",
      "emotion distribution",
      "network emotion",
      "distribution learning",
      "changing",
      "context changing",
      "emotionaware"
    ],
    "examples": [
      "emoticon-based distant supervision",
      "emoticon-based distant supervision",
      "emotion feature extraction",
      "emotional patches feature extraction",
      "emotion distribution learning",
      "emotion feature extraction",
      "emotion representation models",
      "emotional transition tensor"
    ],
    "topic_fingerprint": "ac320d539b233f875a1eee03827783d97dfabc88bcc64bd18c6a5941ebd4cc5f",
    "l2_name": "Emotion Feature Extraction",
    "definition": "The methodological process of identifying, isolating, and representing emotional signals from data sources such as text, images, or context for computational analysis.",
    "aliases": [
      "emotion feature extraction",
      "extraction emotion",
      "learning emotion",
      "emotion representation",
      "emotional patches feature extraction",
      "emotion distribution learning",
      "emotion-aware feature learning"
    ]
  },
  {
    "topic_id": 6,
    "size": 50,
    "keywords": [
      "contrastive",
      "contrastive learning",
      "learning contrastive",
      "supervised contrastive",
      "contrastive adaptation",
      "supervised",
      "learning module",
      "contrastive loss",
      "multicue",
      "magnification"
    ],
    "examples": [
      "contrast divergence algorithm",
      "neural activation contrast analysis",
      "inter-contrastive learning design",
      "intra-contrastive learning module",
      "adaptive magnification learning",
      "contrastive learning regularization",
      "joint cross-entropy and contrastive loss",
      "supervised contrastive learning"
    ],
    "topic_fingerprint": "31ffa2952d304b21a35b32684b2141d2f3bbe50a31567d699fb099e6fede1070",
    "l2_name": "Contrastive Learning",
    "definition": "A self-supervised or supervised method that learns representations by maximizing agreement between similar data pairs and minimizing agreement between dissimilar pairs using contrastive loss functions.",
    "aliases": [
      "contrastive adaptation",
      "supervised contrastive learning",
      "contrastive loss optimization",
      "inter-contrastive learning",
      "intra-contrastive learning",
      "margin-based temporal contrastive learning",
      "joint cross-entropy and contrastive loss"
    ]
  },
  {
    "topic_id": 7,
    "size": 50,
    "keywords": [
      "weight",
      "weighting",
      "adaptive",
      "balance factor",
      "weighting dynamic",
      "adaptive region",
      "dynamic",
      "balance",
      "factor",
      "weight optimization"
    ],
    "examples": [
      "particle advection",
      "adaptive distance-based feature weighting",
      "filtering rule application",
      "adaptive weighted fusion",
      "multi-feature weight optimization",
      "adaptive color template matching",
      "clause weight calculation",
      "class activation mapping"
    ],
    "topic_fingerprint": "bbb22b3c82b76decc7e7f62872f12e8dd99bffa9ea73e8c8e54b19bf57f0d6da",
    "l2_name": "Adaptive Weighting",
    "definition": "A method that dynamically adjusts the importance or influence of data elements, features, or regions based on local context or optimization criteria.",
    "aliases": [
      "dynamic weighting",
      "weight optimization",
      "adaptive reweighting",
      "balance factor adjustment",
      "feature weighting",
      "region weighting",
      "patch reweighting"
    ]
  },
  {
    "topic_id": 8,
    "size": 48,
    "keywords": [
      "discriminative",
      "discriminative model",
      "discriminative feature",
      "dictionary learning",
      "dictionary",
      "learning discriminative",
      "modeling discriminative",
      "discriminative modeling",
      "classification discriminative",
      "model classification"
    ],
    "examples": [
      "discriminative modeling techniques",
      "training-free detection method",
      "training-free detection method",
      "discriminative latent modeling",
      "discriminative neighborhood preserving embedding",
      "discriminative model classification",
      "discriminative latent variable modeling",
      "discriminative feature subset evaluation"
    ],
    "topic_fingerprint": "192f8fe221d9a860e4a017c843ffd7917e015c0cddf50124b2f2b7611bdc0ba7",
    "l2_name": "Discriminative Modeling",
    "definition": "A methodological approach that directly models the decision boundary or conditional probability between inputs and labels to optimize classification performance.",
    "aliases": [
      "discriminative model",
      "discriminative learning",
      "discriminant modeling",
      "discriminative feature learning",
      "discriminative dictionary learning",
      "discriminative embedding"
    ]
  },
  {
    "topic_id": 9,
    "size": 46,
    "keywords": [
      "language",
      "large",
      "large language",
      "language model",
      "language models",
      "models",
      "visionlanguage",
      "models large",
      "model",
      "multimodal large"
    ],
    "examples": [
      "neural network language model",
      "autoregressive language modeling",
      "language model analysis",
      "pre-trained language models",
      "large language model disambiguation",
      "large language model disambiguation",
      "large language model disambiguation",
      "large language model adaptation"
    ],
    "topic_fingerprint": "9cc674f45e7643427c0a8444189cd1a3c3009413767121d065417886008f96cc",
    "l2_name": "Large Language Models",
    "definition": "The study and application of neural network-based language models with massive parameter counts, including their pre-training, adaptation, evaluation, and extension to multimodal contexts.",
    "aliases": [
      "LLM",
      "large language model",
      "language models",
      "pre-trained language models",
      "foundation models",
      "multimodal large language models",
      "vision-language models"
    ]
  },
  {
    "topic_id": 10,
    "size": 45,
    "keywords": [
      "embedding",
      "latent",
      "knowledge",
      "commonsense knowledge",
      "commonsense",
      "space",
      "lipschitz embedding",
      "enhanced lipschitz",
      "lipschitz",
      "injection"
    ],
    "examples": [
      "enhanced lipschitz embedding",
      "enhanced lipschitz embedding",
      "enhanced lipschitz embedding",
      "enhanced lipschitz embedding",
      "emotion embedding vectors",
      "sub-event decomposition modeling",
      "latent common feature space learning",
      "asynchronous keyword injection"
    ],
    "topic_fingerprint": "84a235dd6f7a3a809ac782140c54bad950964a76bdcdd90168158eb53440b5d1",
    "l2_name": "Enhanced Lipschitz Embedding",
    "definition": "A method for learning latent representation spaces that integrate commonsense knowledge through Lipschitz-constrained embedding techniques.",
    "aliases": [
      "enhanced lipschitz embedding",
      "lipschitz embedding",
      "latent common feature space learning",
      "commonsense knowledge integration",
      "stochastic word embedding",
      "asynchronous keyword injection",
      "emotion embedding vectors"
    ]
  },
  {
    "topic_id": 11,
    "size": 43,
    "keywords": [
      "recurrent",
      "recurrent neural",
      "gated recurrent",
      "recurrent unit",
      "networks recurrent",
      "neural networks",
      "neural",
      "gated",
      "lstm recurrent",
      "networks"
    ],
    "examples": [
      "lstm recurrent neural networks",
      "multilayer restricted boltzmann machines",
      "restricted boltzmann machines",
      "recurrent neural networks",
      "lstm recurrent neural networks",
      "lstm recurrent neural networks",
      "restricted boltzmann machines",
      "lstm recurrent neural networks"
    ],
    "topic_fingerprint": "13946e543cea1778e68384ca783541dcad505589f0530b570b36cbb209b59d8f",
    "l2_name": "Recurrent Neural Networks",
    "definition": "A class of artificial neural networks designed to recognize patterns in sequences of data by utilizing internal memory states and recurrent connections.",
    "aliases": [
      "RNN",
      "recurrent neural network",
      "gated recurrent unit",
      "GRU",
      "LSTM",
      "long short-term memory",
      "bidirectional recurrent neural networks",
      "multidirectional recurrent neural networks"
    ]
  },
  {
    "topic_id": 12,
    "size": 42,
    "keywords": [
      "subspace",
      "subspace learning",
      "transductive",
      "transfer regression",
      "transfer",
      "subspace topology",
      "topology",
      "region selective",
      "selective transfer",
      "transfer subspace"
    ],
    "examples": [
      "transductive inference",
      "grassmannian manifold subspace modeling",
      "feature subspace projection",
      "self-training on subspaces",
      "transductive transfer linear discriminant analysis",
      "transductive transfer subspace learning",
      "grassmann manifold learning",
      "subspace topology clustering"
    ],
    "topic_fingerprint": "00dd058da905fd7e100ce4c784e123d2fb536940f35238f2f572eae2aa738ac5",
    "l2_name": "Subspace Transfer Learning",
    "definition": "A method that learns a shared or aligned low-dimensional subspace to facilitate knowledge transfer between domains, often incorporating transductive inference and topological constraints.",
    "aliases": [
      "Transfer Subspace Learning",
      "Transductive Transfer Subspace Learning",
      "Subspace Topology Learning",
      "Grassmannian Manifold Transfer",
      "Selective Transfer Subspace",
      "Transductive Subspace Inference",
      "Feature Subspace Projection for Transfer",
      "Region Selective Transfer"
    ]
  },
  {
    "topic_id": 13,
    "size": 41,
    "keywords": [
      "networks deep",
      "deep",
      "deep convolutional",
      "models deep",
      "learning models",
      "deep learning",
      "deep neural",
      "convolutional neural",
      "neural networks",
      "neural"
    ],
    "examples": [
      "au-inspired deep networks",
      "deep convolutional neural networks",
      "deep neural networks",
      "deep neural network learning",
      "deep convolutional neural networks",
      "deep neural network training",
      "deep convolutional neural networks",
      "deep learning models"
    ],
    "topic_fingerprint": "c62ab854ca2445ea1f5f93055ee85d16fc9fcd9cef4034098b7ab9fd184ddeab",
    "l2_name": "Deep Neural Networks",
    "definition": "A class of machine learning models utilizing multiple hidden layers of artificial neurons to learn hierarchical representations from data.",
    "aliases": [
      "DNN",
      "deep learning models",
      "deep neural network",
      "deep convolutional neural networks",
      "CNN",
      "convolutional neural networks",
      "deep networks"
    ]
  },
  {
    "topic_id": 14,
    "size": 40,
    "keywords": [
      "paradigm",
      "tasks",
      "task paradigm",
      "task",
      "visual",
      "paradigm visual",
      "paradigms",
      "recognition",
      "selective attention",
      "visual search"
    ],
    "examples": [
      "visual salience analysis",
      "old new recognition task",
      "visual marking paradigm",
      "visual search tasks",
      "implicit learning paradigms",
      "selective attention tasks",
      "visual search task paradigm",
      "name recognition test"
    ],
    "topic_fingerprint": "d62d490ef3b516ce1ed47701716d451969e4178fe1604bc97fa3a00ac40e4dc2",
    "l2_name": "Experimental Paradigm",
    "definition": "A standardized experimental procedure or task design used to investigate specific cognitive processes such as attention, recognition, or learning.",
    "aliases": [
      "task paradigm",
      "experimental task",
      "behavioral paradigm",
      "cognitive task",
      "test paradigm",
      "procedure"
    ]
  },
  {
    "topic_id": 15,
    "size": 38,
    "keywords": [
      "interaction",
      "interaction modeling",
      "multimodal interaction",
      "gating",
      "interaction analysis",
      "twoaspect information",
      "twoaspect",
      "crossmodal",
      "crossmodal gating",
      "analysis multimodal"
    ],
    "examples": [
      "modal tag integration",
      "interlocutor interaction strategies",
      "transformer-based interaction modeling",
      "intra-modal and cross-modal interactions",
      "multimodal behavior analysis",
      "multimodal interaction analysis",
      "visual guiding sub modules",
      "multimodal interaction modeling"
    ],
    "topic_fingerprint": "6445f6cbd32fb5e24342fe10b1d947b816f094b975825679dea271ea55d2837f",
    "l2_name": "Multimodal Interaction Modeling",
    "definition": "The methodological approach of analyzing and computationally representing the dynamic interplay, fusion, and gating mechanisms between different modalities such as text, audio, and vision.",
    "aliases": [
      "multimodal interaction analysis",
      "cross-modal interaction",
      "intra-modal interaction",
      "adaptive cross-modal gating",
      "interaction modeling",
      "multimodal behavior analysis",
      "crossmodal gating"
    ]
  },
  {
    "topic_id": 16,
    "size": 38,
    "keywords": [
      "multiscale",
      "residual",
      "cycleconsistent",
      "structured",
      "adversarial networks",
      "multiscale convolutional",
      "cycleconsistent adversarial",
      "networks multiscale",
      "multiscale structured",
      "cycleconsistency"
    ],
    "examples": [
      "operational definition refinement",
      "structured trajectory learning",
      "cycle-consistent adversarial networks",
      "multi-scale convolutional filters",
      "multi-level graph convolution",
      "cycle consistent adversarial learning",
      "deep residual network integration",
      "cyclic image generation"
    ],
    "topic_fingerprint": "73615da560c4c4960907f38cd6484b0229927686e548396f554eb0053b62905c",
    "l2_name": "Cycle-Consistent Adversarial Networks",
    "definition": "A deep learning method that integrates adversarial training with cycle-consistency constraints and multi-scale or residual architectures to enable structured trajectory learning and unpaired data translation.",
    "aliases": [
      "CycleGAN",
      "cycle-consistent adversarial learning",
      "multi-scale structured cycle-consistency",
      "residual cycle-consistent networks",
      "multiscale adversarial networks",
      "cycle consistent GANs"
    ]
  },
  {
    "topic_id": 17,
    "size": 37,
    "keywords": [
      "transformer",
      "transformer architecture",
      "vision transformer",
      "encoder",
      "transformer architectures",
      "architecture",
      "vision",
      "architecture transformer",
      "transformer encoder",
      "transformerbased"
    ],
    "examples": [
      "neural network encoding",
      "encoder-based neural networks",
      "transformer-based predictive coding",
      "transformer-based predictive coding",
      "multi-encoder embedding computation",
      "image transformer architectures",
      "image transformer architectures",
      "transformer architectures"
    ],
    "topic_fingerprint": "6abf670883b863bbaeabd76e26fdd2ce86be504d517dab0f4a1e6e6045e4d227",
    "l2_name": "Transformer Architecture",
    "definition": "A neural network design based on the self-attention mechanism, widely adapted for vision and encoding tasks.",
    "aliases": [
      "Vision Transformer",
      "ViT",
      "Transformer Encoder",
      "Transformer-based Architecture",
      "Encoder-only Transformer",
      "Image Transformer"
    ]
  },
  {
    "topic_id": 18,
    "size": 37,
    "keywords": [
      "semisupervised",
      "semisupervised learning",
      "learning semisupervised",
      "learning enhancement",
      "semisupervised ladder",
      "ladder",
      "techniques semisupervised",
      "enhancement semisupervised",
      "cotraining",
      "ladder networks"
    ],
    "examples": [
      "enhanced co-training algorithm",
      "enhanced co-training algorithm",
      "semi-supervised machine learning",
      "semi-supervised transfer learning",
      "weakly supervised deep learning",
      "semi-supervised ladder networks",
      "semi-supervised ladder networks",
      "semi-supervised learning strategy"
    ],
    "topic_fingerprint": "0fc914b789c0411623a791444623b2dae7cee1a1ca3881f9430150b43cf18f8f",
    "l2_name": "Semi-supervised Learning",
    "definition": "A machine learning paradigm that leverages both labeled and unlabeled data to improve model performance and generalization.",
    "aliases": [
      "semi-supervised learning",
      "semisupervised learning",
      "SSL",
      "semi-supervised machine learning",
      "weakly supervised deep learning",
      "co-training",
      "semi-supervised ladder networks",
      "semisupervised transfer learning"
    ]
  },
  {
    "topic_id": 19,
    "size": 36,
    "keywords": [
      "finetuning",
      "tuning",
      "instruction",
      "instruction tuning",
      "curriculum",
      "model training",
      "multigranularity model",
      "training",
      "parameter",
      "multigranularity"
    ],
    "examples": [
      "fine-tuning pre-trained models",
      "network fine-tuning strategy",
      "parameter tuning strategies",
      "strongly supervised fine tuning",
      "hybrid feature and fine-tuning",
      "hybrid feature and fine-tuning",
      "curriculum instance-level adaptation",
      "fine-tuning with annotated data"
    ],
    "topic_fingerprint": "ab1ef216517cba4f69564c3ebcfaafa9cd839cd05dd461799587c3f1b8551793",
    "l2_name": "Fine-tuning",
    "definition": "The process of adapting a pre-trained model to a specific task or domain by further training on targeted data, often involving parameter adjustments, instruction alignment, or curriculum strategies.",
    "aliases": [
      "tuning",
      "instruction tuning",
      "model fine-tuning",
      "parameter tuning",
      "network fine-tuning",
      "curriculum learning",
      "parameter efficient training",
      "multigranularity tuning"
    ]
  },
  {
    "topic_id": 20,
    "size": 36,
    "keywords": [
      "hypergraph",
      "hypergraph learning",
      "rolling",
      "multitask hypergraph",
      "rolling multitask",
      "multigraph",
      "learning rolling",
      "multihypergraph",
      "vertex",
      "multimodal hypergraph"
    ],
    "examples": [
      "multimodal hypergraph learning",
      "multi-graph learning framework",
      "multi-graph learning framework",
      "rolling multi-task hypergraph learning",
      "rolling multi-task hypergraph learning",
      "rolling multi-task hypergraph learning",
      "rolling multi-task hypergraph learning",
      "rolling multi-task hypergraph learning"
    ],
    "topic_fingerprint": "1d8110abb71fcf036fa08941683c7526d6967e2e22456fda395e12b9a8ccc87c",
    "l2_name": "Hypergraph Learning",
    "definition": "A machine learning methodology that utilizes hypergraphs to model and learn from complex high-order relationships among data points beyond pairwise connections.",
    "aliases": [
      "hypergraph learning framework",
      "multitask hypergraph learning",
      "rolling multitask hypergraph learning",
      "multimodal hypergraph learning",
      "multi-hypergraph learning",
      "multigraph learning",
      "hypergraph-based learning"
    ]
  },
  {
    "topic_id": 21,
    "size": 34,
    "keywords": [
      "machine classification",
      "classification support",
      "vector machine",
      "support vector",
      "support",
      "vector",
      "machine",
      "classification",
      "classification votingbased",
      "votingbased"
    ],
    "examples": [
      "support vector machine classification",
      "support vector machine classification",
      "support vector machine classification",
      "voting-based classification",
      "support vector machine classification",
      "support vector machine classification",
      "support vector machine classification",
      "support vector machine classification"
    ],
    "topic_fingerprint": "4a0f4df194c6e40c61c29405e66ab4a92b3432bc45b9ac3749fe789681283787",
    "l2_name": "Support Vector Machine",
    "definition": "A supervised learning model that analyzes data for classification and regression by constructing hyperplanes in a high-dimensional space.",
    "aliases": [
      "SVM",
      "support vector machine classification",
      "support vector machine classifier",
      "voting-based classification",
      "machine classification",
      "classification support"
    ]
  },
  {
    "topic_id": 22,
    "size": 34,
    "keywords": [
      "graph",
      "graph construction",
      "bayesian",
      "graph representation",
      "bayesian network",
      "inference",
      "network inference",
      "construction",
      "structure learning",
      "inference bayesian"
    ],
    "examples": [
      "synonymy graph propagation",
      "graph-based evidence modeling",
      "bayes error minimization",
      "bayesian inference based classification",
      "probabilistic logic inference",
      "fisher discriminant graph embedding",
      "probabilistic graphical models",
      "bayesian network inference"
    ],
    "topic_fingerprint": "e5fa10e6cf15c0cfb1e8597848d021237aac138a0698eaa1b7cb77d017b890e8",
    "l2_name": "Bayesian Graph Inference",
    "definition": "A methodological approach that combines probabilistic graphical models with graph construction techniques to infer network structures and perform statistical inference.",
    "aliases": [
      "Bayesian network inference",
      "graph-based Bayesian modeling",
      "probabilistic graph structure learning",
      "Bayesian graph representation",
      "inference on constructed graphs"
    ]
  },
  {
    "topic_id": 23,
    "size": 34,
    "keywords": [
      "extraction multimodal",
      "learning multimodal",
      "explanation",
      "multimodal",
      "multimodal feature",
      "multimodal explanation",
      "explanation generation",
      "generation multimodal",
      "multimodal deep",
      "feature extraction"
    ],
    "examples": [
      "multi-modality feature extraction",
      "multimodal system design",
      "multimodal feature extraction",
      "multi-channel feature extraction",
      "multimodal feature relevance learning",
      "multimodal feature extraction",
      "multimodal deep learning features",
      "multimodal deep feature extraction"
    ],
    "topic_fingerprint": "b8d179603231fc21955244d733e50bd9873e10e695cb9f509b532c5606188df6",
    "l2_name": "Multimodal Feature Extraction",
    "definition": "The process of deriving and integrating representative features from multiple distinct data modalities to support downstream learning or explanation tasks.",
    "aliases": [
      "multi-modality feature extraction",
      "multimodal deep feature extraction",
      "multi-channel feature extraction",
      "multimodal feature relevance learning",
      "extraction multimodal",
      "multimodal feature learning"
    ]
  },
  {
    "topic_id": 24,
    "size": 34,
    "keywords": [
      "prompting",
      "dialogue",
      "generative methods",
      "llmdriven",
      "llmdriven generative",
      "methods llmdriven",
      "dialogue modeling",
      "generative",
      "multiagent",
      "methods"
    ],
    "examples": [
      "constraint-based dialogue modeling",
      "artificial agent social interaction",
      "foundation model prompting",
      "assistant prediction mechanism",
      "adaptive context-aware prompting",
      "few-shot prompting strategies",
      "step-by-step reasoning chains",
      "interpretable dialogue modeling"
    ],
    "topic_fingerprint": "b7fee1b320815ca2072b7b1d1aea0ad9f7252f667ea99334a1ccb0531dbfb0e7",
    "l2_name": "Prompting",
    "definition": "A method involving the design and optimization of input instructions to guide large language models in generating desired outputs for tasks such as dialogue modeling and reasoning.",
    "aliases": [
      "prompt engineering",
      "foundation model prompting",
      "adaptive prompting",
      "few-shot prompting",
      "prompt masking",
      "LLM-driven prompting",
      "instruction tuning"
    ]
  },
  {
    "topic_id": 25,
    "size": 33,
    "keywords": [
      "networks convolutional",
      "convolutional neural",
      "convolutional",
      "neural networks",
      "neural",
      "networks",
      "coupled convolutional",
      "networks coupled",
      "regression networks",
      "coupled"
    ],
    "examples": [
      "convolutional neural network pooling",
      "convolutional max-pooling layers",
      "convolutional neural networks",
      "convolutional neural network features",
      "convolutional neural networks",
      "convolutional neural networks",
      "coupled convolutional networks",
      "super wide regression network"
    ],
    "topic_fingerprint": "3961788b19e03c40866522cb98d96b456b3f227eef8ca30041b9680b6235e7e4",
    "l2_name": "Convolutional Neural Networks",
    "definition": "A class of deep neural networks that apply convolution operations to process grid-like topology data such as images.",
    "aliases": [
      "CNN",
      "ConvNets",
      "convolutional neural network",
      "neural networks convolutional",
      "coupled convolutional networks",
      "regression networks"
    ]
  },
  {
    "topic_id": 26,
    "size": 32,
    "keywords": [
      "hierarchical",
      "networks hierarchical",
      "hierarchical spatial",
      "discriminators hierarchical",
      "discriminators",
      "domain discriminators",
      "swintransformer architecture",
      "hierarchical swintransformer",
      "hierarchical neural",
      "division scheme"
    ],
    "examples": [
      "hierarchical pca lda framework",
      "hierarchical classification structure",
      "hierarchical stress generation",
      "hierarchical spatial division scheme",
      "hierarchical spatial division scheme",
      "bi hemisphere neural networks",
      "global and local discriminators",
      "hierarchical spatial-temporal neural networks"
    ],
    "topic_fingerprint": "9fa8b52ad93ce668c81b752dd226398610758db2ed31e64352cbaf59abb741d9",
    "l2_name": "Hierarchical Architecture",
    "definition": "A methodological approach that organizes neural networks, spatial divisions, or classification structures into multiple levels of abstraction to capture features at varying scales.",
    "aliases": [
      "hierarchical networks",
      "hierarchical spatial division",
      "hierarchical discriminators",
      "hierarchical swintransformer",
      "hierarchical neural networks",
      "multi-level architecture",
      "hierarchical classification",
      "hierarchical domain adaptation",
      "hierarchical recurrent networks",
      "hierarchical spatial-temporal networks"
    ]
  },
  {
    "topic_id": 27,
    "size": 31,
    "keywords": [
      "multimodal attention",
      "attention",
      "attention fusion",
      "interactive attention",
      "interactive",
      "attention mechanisms",
      "adaptive interactive",
      "mechanisms multimodal",
      "attention feature",
      "multimodal"
    ],
    "examples": [
      "conditional attention fusion",
      "layout-driven multimodal attention",
      "multimodal attention feature fusion",
      "multimodal attention feature fusion",
      "multi-attention deep neural networks",
      "multimodal attention mechanisms",
      "multimodal attention mechanisms",
      "multimodal attention mechanisms"
    ],
    "topic_fingerprint": "b6fb980d8274cdfd4ff99a670de4243ff30897e1befb9dcf006bc279d397a6bb",
    "l2_name": "Multimodal Attention",
    "definition": "A method that employs attention mechanisms to dynamically align, fuse, and interact between features from different modalities.",
    "aliases": [
      "multimodal attention mechanisms",
      "attention fusion",
      "interactive attention",
      "adaptive interactive attention",
      "dual attention",
      "multi-attention",
      "cross-modal attention"
    ]
  },
  {
    "topic_id": 28,
    "size": 31,
    "keywords": [
      "support vector",
      "support",
      "vector",
      "vector regression",
      "vector machine",
      "machine support",
      "regression support",
      "machine",
      "vector machines",
      "machines"
    ],
    "examples": [
      "fuzzy support vector machine",
      "support vector machine fusion",
      "differential evolution svm",
      "support vector machine",
      "support vector machine integration",
      "support vector machines",
      "linear support vector machine",
      "support vector machine application"
    ],
    "topic_fingerprint": "d7ab345088f43abceea2d62c44fb3c3f36a193a289a2a51f099668966faa7f08",
    "l2_name": "Support Vector Machine",
    "definition": "A supervised learning method that uses hyperplanes in high-dimensional space to classify data or perform regression analysis.",
    "aliases": [
      "SVM",
      "Support Vector Machines",
      "Support Vector Regression",
      "SVR",
      "Vector Machine",
      "Kernel Support Vector Machine"
    ]
  },
  {
    "topic_id": 29,
    "size": 31,
    "keywords": [
      "facial expression",
      "expression",
      "facial",
      "expression recognition",
      "recognition facial",
      "expression processing",
      "recognition",
      "analysis facial",
      "facial analysis",
      "processing facial"
    ],
    "examples": [
      "longitudinal facial expression atlases",
      "facial expression manipulation",
      "emotional facial animation",
      "facial expression recognition",
      "facial expression pattern recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression processing"
    ],
    "topic_fingerprint": "bc6293b344980dd58655cda8a621f45dbc1eaad1a565b078dd220f81bf492d8f",
    "l2_name": "Facial Expression Analysis",
    "definition": "The computational processing, recognition, and manipulation of human facial movements to interpret emotions or generate animations.",
    "aliases": [
      "facial expression recognition",
      "facial analysis",
      "expression processing",
      "facial expression processing",
      "emotion recognition from face",
      "facial animation",
      "facial expression pattern recognition"
    ]
  },
  {
    "topic_id": 30,
    "size": 30,
    "keywords": [
      "autoencoder",
      "variational",
      "masked autoencoder",
      "masked",
      "autoencoder pretraining",
      "variational autoencoder",
      "pretraining",
      "selfsupervised masked",
      "autoencoders",
      "hierarchical contrastive"
    ],
    "examples": [
      "denoising autoencoder pre-training",
      "convolutional auto encoder",
      "bimodal deep autoencoder",
      "twin-cycle autoencoder architecture",
      "semi-parametric variational autoencoders",
      "attention autoencoders",
      "sparse variational scaling",
      "variational pathway reasoning"
    ],
    "topic_fingerprint": "37783cc18b59df9fcb139202feee5dbbc72b55d62fcb04b102157c14cb2e4a4f",
    "l2_name": "Autoencoder",
    "definition": "A neural network architecture that learns efficient data encodings by training to reconstruct its input from a compressed latent representation, often enhanced with variational inference or masking strategies for self-supervised pretraining.",
    "aliases": [
      "AE",
      "Variational Autoencoder",
      "VAE",
      "Masked Autoencoder",
      "MAE",
      "Denoising Autoencoder",
      "Convolutional Autoencoder",
      "Sparse Autoencoder",
      "Hierarchical Autoencoder",
      "Twin-Cycle Autoencoder",
      "Autoencoders"
    ]
  },
  {
    "topic_id": 31,
    "size": 30,
    "keywords": [
      "eeg",
      "signal analysis",
      "signal",
      "eeg analysis",
      "frequency",
      "neural signal",
      "electroencephalogram",
      "electrophysiological",
      "electrophysiological data",
      "eegassisted annotation"
    ],
    "examples": [
      "monogenic signal analysis",
      "monogenic signal analysis",
      "two-channel eeg recording",
      "electrophysiological data analysis",
      "spontaneous low frequency fluctuations analysis",
      "quantitative eeg analysis",
      "neural signal analysis",
      "eeg signal analysis"
    ],
    "topic_fingerprint": "f77a3c3c9835cf1defc1322e2636f738cb46ec78004f8346f88bc231a54be616",
    "l2_name": "EEG Signal Analysis",
    "definition": "The computational processing and interpretation of electroencephalogram data to extract neural features such as frequency, amplitude, and oscillatory patterns.",
    "aliases": [
      "EEG analysis",
      "electroencephalogram signal analysis",
      "neural signal analysis",
      "electrophysiological data analysis",
      "quantitative EEG",
      "QEEG",
      "EEG-assisted annotation",
      "monogenic signal analysis",
      "alpha oscillation analysis",
      "amplitude of low-frequency oscillations analysis"
    ]
  },
  {
    "topic_id": 32,
    "size": 30,
    "keywords": [
      "feature selection",
      "selection",
      "ranking",
      "selection techniques",
      "pairwise",
      "calibration",
      "selection methods",
      "selection pairwise",
      "methods feature",
      "selection feature"
    ],
    "examples": [
      "text feature selection methods",
      "feature selection methods",
      "feature selection techniques",
      "all-class feature selection",
      "pairwise-class feature selection",
      "feature selection algorithms",
      "object proposal ranking strategy",
      "objectness candidate selection"
    ],
    "topic_fingerprint": "c6b15015291f73950aa4631dbf9026cdb9e58e7e174fdee7ae3971dd4efb41db",
    "l2_name": "Feature Selection",
    "definition": "The process of identifying and selecting a subset of relevant features for use in model construction to improve performance and reduce complexity.",
    "aliases": [
      "feature selection methods",
      "feature selection techniques",
      "feature ranking",
      "variable selection",
      "attribute selection",
      "selection methods",
      "ranking methods",
      "pairwise feature selection"
    ]
  },
  {
    "topic_id": 33,
    "size": 30,
    "keywords": [
      "connectivity",
      "functional",
      "brain",
      "functional connectivity",
      "functional network",
      "brain functional",
      "brain network",
      "connectivity analysis",
      "analysis neural",
      "network systematic"
    ],
    "examples": [
      "neural correlate analysis",
      "salience network investigation",
      "functional connectivity assessment",
      "neural pathway analysis",
      "neuroscience data integration",
      "brain region mapping",
      "neural dynamics analysis",
      "functional connectivity analysis"
    ],
    "topic_fingerprint": "083f489d10f55a4638fecfbc74b29b67b7630e626a95c619bb1f98037548b60b",
    "l2_name": "Functional Connectivity Analysis",
    "definition": "A method for assessing statistical dependencies and temporal correlations between spatially distinct neurophysiological signals to characterize brain network organization.",
    "aliases": [
      "functional connectivity assessment",
      "brain functional connectivity analysis",
      "functional network analysis",
      "connectivity analysis",
      "neural connectivity mapping",
      "brain network analysis",
      "FC analysis"
    ]
  },
  {
    "topic_id": 34,
    "size": 29,
    "keywords": [
      "kernel",
      "multiple kernel",
      "kernel learning",
      "multiple",
      "discriminant",
      "discriminant analysis",
      "linear discriminant",
      "linear",
      "learning fusion",
      "density estimation"
    ],
    "examples": [
      "linear discriminant analysis",
      "kernel optimization algorithm",
      "kernel discriminant plane",
      "kernel fisher discriminant analysis",
      "fuzzy kernel discriminant analysis",
      "kernel fisher discriminant",
      "multiple kernel learning",
      "multiple kernel learning fusion"
    ],
    "topic_fingerprint": "b3f3ac9b57bea0ed849398161b65635ccf3191ee1e9f6cd59b0b24f616b8111c",
    "l2_name": "Multiple Kernel Learning",
    "definition": "A machine learning method that optimizes the combination of multiple kernel functions to improve performance in tasks such as classification, regression, and density estimation.",
    "aliases": [
      "MKL",
      "multiple kernel learning fusion",
      "two-layer multiple kernel learning",
      "kernel learning",
      "kernel optimization",
      "multiple kernel discriminant analysis",
      "kernel Fisher discriminant analysis"
    ]
  },
  {
    "topic_id": 35,
    "size": 29,
    "keywords": [
      "transfer learning",
      "transfer",
      "learning transfer",
      "application transfer",
      "knowledge transfer",
      "learning approach",
      "learning large",
      "components",
      "components learning",
      "learning application"
    ],
    "examples": [
      "transfer learning approach",
      "transfer learning with unlabeled data",
      "feature transfer learning",
      "transfer of learning techniques",
      "transfer learning from cnn models",
      "transfer learning strategy",
      "transfer learning approach",
      "transfer learning application"
    ],
    "topic_fingerprint": "61bc94451ed3a0e9bfcd62823d8779dc8ed8218e190b57e36d69b7f5d2057306",
    "l2_name": "Transfer Learning",
    "definition": "A machine learning method where a model developed for a task is reused as the starting point for a model on a second task.",
    "aliases": [
      "transfer learning approach",
      "knowledge transfer",
      "learning transfer",
      "feature transfer learning",
      "transfer of learning",
      "application transfer",
      "transfer learning strategy",
      "transfer learning techniques"
    ]
  },
  {
    "topic_id": 36,
    "size": 29,
    "keywords": [
      "dataset",
      "dataset construction",
      "construction",
      "dataset creation",
      "largescale",
      "creation",
      "multimodal dataset",
      "largescale dataset",
      "database construction",
      "construction multimodal"
    ],
    "examples": [
      "database construction and collection",
      "database construction",
      "large-scale dataset construction",
      "large-scale dataset construction",
      "interactive dataset construction",
      "multimodal emotion dataset creation",
      "dataset creation and labeling",
      "dataset description"
    ],
    "topic_fingerprint": "5941429193ab3b68602ee37d41061d45e5cf92615a94aae5c034a23e91e2fa8a",
    "l2_name": "Dataset Construction",
    "definition": "The process of collecting, curating, labeling, and organizing data to create structured datasets for research or application purposes.",
    "aliases": [
      "dataset creation",
      "database construction",
      "dataset collection",
      "dataset building",
      "dataset curation",
      "large-scale dataset construction",
      "multimodal dataset construction",
      "dataset release"
    ]
  },
  {
    "topic_id": 37,
    "size": 28,
    "keywords": [
      "multimodal feature",
      "fusion multimodal",
      "feature fusion",
      "multimodal",
      "fusion",
      "feature",
      "multimodal video",
      "fusion joint",
      "joint multimodal",
      "video fusion"
    ],
    "examples": [
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "multimodal feature fusion framework"
    ],
    "topic_fingerprint": "337a0e4473517b1181670fc51c9bef98496642f9c2f3ab6b954572091e72cda2",
    "l2_name": "Multimodal Feature Fusion",
    "definition": "A method that integrates complementary information from multiple data modalities by combining their feature representations to enhance model performance.",
    "aliases": [
      "multimodal feature fusion",
      "feature fusion",
      "multimodal fusion",
      "fusion multimodal",
      "joint multimodal fusion",
      "multimodal video fusion",
      "video fusion",
      "multimodal feature fusion strategies",
      "multimodal feature fusion framework"
    ]
  },
  {
    "topic_id": 38,
    "size": 27,
    "keywords": [
      "scale",
      "psychometric",
      "assessment",
      "scale measurement",
      "psychological",
      "assessment psychological",
      "scale application",
      "scale assessment",
      "standardized psychometric",
      "psychological scale"
    ],
    "examples": [
      "scale translation adaptation",
      "self-efficacy measurement",
      "emotional intelligence scale assessment",
      "big five personality assessment",
      "clinical neuropsychological assessment",
      "psychological scale measurement",
      "dysfunction attitudes scale usage",
      "hamilton scale application"
    ],
    "topic_fingerprint": "d96eb098e01244c05d80ae992b5aff3342abc815a0954697f82e607ea322f808",
    "l2_name": "Psychometric Scaling",
    "definition": "The methodological process of developing, validating, and applying standardized instruments to measure psychological constructs.",
    "aliases": [
      "psychometric assessment",
      "scale measurement",
      "psychological scaling",
      "standardized psychometric testing",
      "scale development",
      "psychometric evaluation"
    ]
  },
  {
    "topic_id": 39,
    "size": 27,
    "keywords": [
      "domain",
      "domain adaptation",
      "methods domain",
      "adaptation methods",
      "adaptation",
      "learning domain",
      "methods",
      "domain adaptive",
      "adaptation techniques",
      "domain regeneration"
    ],
    "examples": [
      "dominance based combination",
      "domain adaptation via synthesis",
      "domain adaptation via synthesis",
      "domain regeneration framework",
      "domain regenerator learning",
      "domain regeneration framework",
      "domain regenerator learning",
      "domain adaptation"
    ],
    "topic_fingerprint": "f8c740d10d2cefc8f97957fae3896c990db14efbcdf706c4bd176b663133fae0",
    "l2_name": "Domain Adaptation",
    "definition": "Domain adaptation refers to machine learning techniques that enable a model trained on a source domain to perform effectively on a different but related target domain.",
    "aliases": [
      "domain adaptive learning",
      "domain adaptation methods",
      "domain adaptation techniques",
      "domain regenerator learning",
      "domain regeneration framework",
      "adaptation methods",
      "DA"
    ]
  },
  {
    "topic_id": 40,
    "size": 26,
    "keywords": [
      "similarity",
      "distance",
      "geodesic distance",
      "distance estimation",
      "geodesic",
      "estimation geodesic",
      "distance alignment",
      "relative",
      "relative distance",
      "similarity metric"
    ],
    "examples": [
      "image similarity analysis",
      "elastic graph matching",
      "geodesic distance estimation",
      "geodesic distance estimation",
      "geodesic distance estimation",
      "distribution similarity measurement",
      "bibliometric analysis using citespace",
      "co-citation network visualization"
    ],
    "topic_fingerprint": "6ffbf85d7ee602f1a96f29fdf831f0925635c14aa98b17234426142b1cfb02ff",
    "l2_name": "Distance and Similarity Measurement",
    "definition": "Methods for quantifying the resemblance or separation between data points, structures, or distributions using metrics such as Euclidean, geodesic, or kernel-based distances.",
    "aliases": [
      "similarity analysis",
      "distance estimation",
      "geodesic distance",
      "similarity metric",
      "distance alignment",
      "relative distance",
      "distance-based alignment"
    ]
  },
  {
    "topic_id": 41,
    "size": 25,
    "keywords": [
      "multilevel",
      "multilevel feature",
      "extraction multilevel",
      "fusion multilevel",
      "duallevel",
      "duallevel feature",
      "restoration",
      "feature restoration",
      "higherlevel",
      "restoration duallevel"
    ],
    "examples": [
      "multi-scale grid feature extraction",
      "multi-level feature extraction",
      "multi-level feature extraction",
      "multi-level feature representation",
      "multi-level feature extraction",
      "multi-level feature extraction",
      "higher-level feature extraction",
      "higher-level feature extraction"
    ],
    "topic_fingerprint": "38bc974f9a318534f4e7c1e83e16c46a92411a6baa8eb24ab5423242b9ac4f18",
    "l2_name": "Multilevel Feature Extraction",
    "definition": "A method that extracts, fuses, or restores features from multiple hierarchical levels or scales to enhance representation capability.",
    "aliases": [
      "multilevel feature extraction",
      "multi-level feature extraction",
      "multiscale feature extraction",
      "dual-level feature extraction",
      "higher-level feature extraction",
      "low-to-high level feature fusion",
      "multilevel feature fusion",
      "feature restoration",
      "multilevel representation"
    ]
  },
  {
    "topic_id": 42,
    "size": 25,
    "keywords": [
      "mediation",
      "mediation analysis",
      "analysis mediation",
      "modeling mediation",
      "analysis modeling",
      "moderation",
      "moderated mediation",
      "mediation modeling",
      "moderated",
      "effect"
    ],
    "examples": [
      "mediation analysis",
      "modified mett paradigm",
      "mediation analysis modeling",
      "mediation statistical modeling",
      "mediation analysis modeling",
      "mediation effect statistical analysis",
      "mediation analysis",
      "mediation effect testing"
    ],
    "topic_fingerprint": "8abedad0d52ef86ac8962fdb094cc9f978f254f9b9e08a32fe4f2433dd18153a",
    "l2_name": "Mediation Analysis",
    "definition": "A statistical method used to examine the mechanism or process by which an independent variable influences a dependent variable through an intervening mediator variable.",
    "aliases": [
      "mediation",
      "mediation modeling",
      "mediated effect analysis",
      "moderated mediation",
      "mediation effect testing",
      "mediation mechanism modeling",
      "analysis of mediation",
      "statistical mediation"
    ]
  },
  {
    "topic_id": 43,
    "size": 25,
    "keywords": [
      "action",
      "action unit",
      "unit",
      "facial action",
      "coding",
      "action coding",
      "coding facial",
      "facial",
      "unit coding",
      "au"
    ],
    "examples": [
      "action unit based modeling",
      "action unit coding",
      "action unit coding",
      "facial action coding system",
      "facial action coding system",
      "facial action coding system",
      "facial action coding system regions",
      "facial action unit mapping"
    ],
    "topic_fingerprint": "f9bba37d86cccb025bd5f285673b7441919faf45ba491ed01f81450a0a05c32f",
    "l2_name": "Facial Action Coding",
    "definition": "A method for systematically categorizing and labeling facial movements based on the activation of specific action units.",
    "aliases": [
      "Action Unit Coding",
      "FACS",
      "Facial Action Coding System",
      "AU Coding",
      "Action Unit Labeling",
      "Facial Expression Coding"
    ]
  },
  {
    "topic_id": 44,
    "size": 25,
    "keywords": [
      "statistical",
      "correlation",
      "correlation analysis",
      "statistical correlation",
      "analysis statistical",
      "reliability",
      "analysis",
      "confusion matrix",
      "matrix analysis",
      "statistical analysis"
    ],
    "examples": [
      "reliability analysis",
      "correlational analysis",
      "large sample correlation study",
      "correlation analysis techniques",
      "statistical correlation analysis",
      "commonality statistical analysis",
      "statistical reliability estimation",
      "statistical correlation testing"
    ],
    "topic_fingerprint": "6dae89afe6cc0c3d55104f389686abbd9b8b943c6a6f9b6dd43bcf9dd1049ff2",
    "l2_name": "Statistical Correlation Analysis",
    "definition": "A methodological approach for quantifying the strength and direction of relationships between variables using statistical techniques such as correlation coefficients, reliability estimation, and confusion matrices.",
    "aliases": [
      "correlational analysis",
      "statistical correlation",
      "correlation analysis",
      "statistical reliability analysis",
      "confusion matrix analysis",
      "contingency relationship analysis",
      "statistical anomaly detection",
      "correlation testing"
    ]
  },
  {
    "topic_id": 45,
    "size": 25,
    "keywords": [
      "crossmodal",
      "crossmodal attention",
      "module crossmodal",
      "crossmodal alignment",
      "alignment module",
      "alignment",
      "attention fusion",
      "contrastive modality",
      "alignment crossmodal",
      "fusion crossmodal"
    ],
    "examples": [
      "cross-modal distribution matching",
      "cross-modal transformer encoder",
      "cross-modal feature association",
      "cross-modal prediction mechanism",
      "cross-modal feature learning",
      "auxiliary cross-modal relation detection",
      "cross-modal alignment module",
      "cross-modal alignment module"
    ],
    "topic_fingerprint": "cb327e978eaa2f43ee0771d5f76e64b8abed874f5fda6dc7d1e6d33214ca538f",
    "l2_name": "Cross-Modal Alignment",
    "definition": "A method that establishes correspondence and semantic consistency between features from different modalities using attention mechanisms, fusion modules, or distribution matching.",
    "aliases": [
      "crossmodal alignment",
      "cross-modal feature association",
      "cross-modal distribution matching",
      "cross-modal attention fusion",
      "modality alignment",
      "cross-modal feature learning"
    ]
  },
  {
    "topic_id": 46,
    "size": 24,
    "keywords": [
      "deep feature",
      "extraction deep",
      "deep",
      "features deep",
      "deep pattern",
      "recognition deep",
      "learning feature",
      "deep metric",
      "feature enhancement",
      "depth"
    ],
    "examples": [
      "deep neural network features",
      "deep cnn feature extraction",
      "deep feature extraction",
      "deep metric learning",
      "deep learning feature extraction",
      "deep semantic feature integration",
      "deep and hand-crafted features",
      "deep feature extraction"
    ],
    "topic_fingerprint": "cf27940d40882b32ac407447fd15dda42b18d4ee7f6031e3832c5160f8fb1f67",
    "l2_name": "Deep Feature Extraction",
    "definition": "The method of automatically learning and extracting hierarchical representations from raw data using deep neural networks for pattern recognition and metric learning tasks.",
    "aliases": [
      "deep feature learning",
      "deep representation learning",
      "deep CNN feature extraction",
      "deep semantic feature extraction",
      "deep pattern recognition",
      "deep metric learning",
      "feature enhancement via deep learning",
      "adaptive deep feature extraction"
    ]
  },
  {
    "topic_id": 47,
    "size": 24,
    "keywords": [
      "affective",
      "affective computing",
      "computing",
      "computing frameworks",
      "frameworks",
      "multimodal affective",
      "affective representation",
      "affective modeling",
      "embedding affective",
      "structural embedding"
    ],
    "examples": [
      "affective state evaluation",
      "linguistic affect interpretation",
      "ubiquitous computing frameworks",
      "affective computing frameworks",
      "affective state manipulation",
      "affective priming paradigm",
      "large-scale affective database creation",
      "affective concept incorporation"
    ],
    "topic_fingerprint": "686a697ed3c7c3ec5249a0fede572f8796a3e45637e2f483c7867ca0fb17ebac",
    "l2_name": "Affective Computing Frameworks",
    "definition": "Methodological approaches and structural systems designed to recognize, interpret, simulate, and influence human emotions through computational models and multimodal data integration.",
    "aliases": [
      "affective computing",
      "computing frameworks",
      "multimodal affective frameworks",
      "affective modeling",
      "affective representation",
      "structural embedding",
      "embedding affective",
      "affective state evaluation",
      "linguistic affect interpretation",
      "ubiquitous computing frameworks",
      "affective concept incorporation"
    ]
  },
  {
    "topic_id": 48,
    "size": 24,
    "keywords": [
      "multimodal fusion",
      "operations",
      "prefusion operations",
      "multimodal prefusion",
      "prefusion",
      "fusion strategies",
      "operations multimodal",
      "techniques multimodal",
      "multimodal",
      "fusion"
    ],
    "examples": [
      "multi-stream fused hidden markov model",
      "multi-cue fusion",
      "image fusion techniques",
      "multi-modal fusion strategies",
      "multimodal fusion technique",
      "modality reconstruction techniques",
      "multi-modal fusion strategies",
      "hybrid multimodal fusion strategy"
    ],
    "topic_fingerprint": "0d9b2a32230b1159a149095e5d41992be14f3f7eedc300ac0e69433637968502",
    "l2_name": "Multimodal Fusion",
    "definition": "The process of integrating information from multiple distinct data modalities to improve system performance or robustness.",
    "aliases": [
      "multimodal prefusion",
      "fusion strategies",
      "multi-cue fusion",
      "hybrid multimodal fusion",
      "multi-modal amalgamation",
      "modality reconstruction",
      "multimodal factorization"
    ]
  },
  {
    "topic_id": 49,
    "size": 23,
    "keywords": [
      "domain adversarial",
      "domain",
      "adversarial",
      "domain adaptation",
      "adversarial neural",
      "adaptation",
      "adversarial domain",
      "unsupervised",
      "adaptation domain",
      "adversarial training"
    ],
    "examples": [
      "unsupervised domain adaptation",
      "domain adversarial training",
      "bi-hemisphere domain adversarial training",
      "adversarial domain adaptation",
      "unsupervised adversarial domain adaptation",
      "domain adversarial neural networks",
      "domain adversarial neural networks",
      "multi-source domain adaptation"
    ],
    "topic_fingerprint": "7556f02622139615f54eda0621b3d03cddcf0854eb5a2496315b46724c1c72de",
    "l2_name": "Domain Adversarial Training",
    "definition": "A method that employs adversarial learning to train feature extractors to generate domain-invariant representations for unsupervised domain adaptation.",
    "aliases": [
      "Domain Adversarial Neural Networks",
      "DANN",
      "Adversarial Domain Adaptation",
      "Unsupervised Domain Adaptation via Adversarial Training",
      "Adversarial Domain Discrimination",
      "Bi-hemisphere Domain Adversarial Training",
      "Adversarial Dual Discriminator Network"
    ]
  },
  {
    "topic_id": 50,
    "size": 23,
    "keywords": [
      "voxelbased",
      "morphometry",
      "matter",
      "voxelbased morphometry",
      "volume measurement",
      "gray",
      "gray matter",
      "matter volume",
      "volume",
      "morphometry analysis"
    ],
    "examples": [
      "volumetric brain analysis",
      "regional gray matter volume measurement",
      "voxel-based morphometry analysis",
      "regional gray matter volume measurement",
      "voxel-based morphometry analysis",
      "voxel-based morphometry meta-analysis",
      "amygdala volume measurement",
      "gray matter volume analysis"
    ],
    "topic_fingerprint": "0702dc3c9700bdac5b4c2184764fb49a38009bf318f4f6b66ae6ad12f56449e2",
    "l2_name": "Voxel-Based Morphometry",
    "definition": "A neuroimaging analysis technique that investigates focal differences in brain anatomy using voxel-wise statistical comparison of local concentrations of gray or white matter.",
    "aliases": [
      "VBM",
      "voxelbased morphometry",
      "voxel-based morphometry analysis",
      "voxelwise morphometry",
      "gray matter volumetry",
      "regional gray matter volume measurement",
      "matter volume analysis"
    ]
  },
  {
    "topic_id": 51,
    "size": 23,
    "keywords": [
      "graph convolutional",
      "networks graph",
      "graph",
      "convolutional networks",
      "convolutional",
      "networks",
      "residual graph",
      "integration graph",
      "graph convolution",
      "convolutional neural"
    ],
    "examples": [
      "graph-based convolutional neural networks",
      "graph convolutional neural networks",
      "graph convolutional neural networks",
      "graph convolutional network integration",
      "graph convolutional networks",
      "graph convolutional networks",
      "graph-embedded convolutional neural networks",
      "probabilistic graph convolution"
    ],
    "topic_fingerprint": "0c134262edb11a3266ddf120b04051103187ccb250b8cef959d16cf1c50cfa31",
    "l2_name": "Graph Convolutional Networks",
    "definition": "A class of deep learning methods designed to perform convolution operations directly on graph-structured data by aggregating information from neighboring nodes.",
    "aliases": [
      "GCN",
      "graph convolutional network",
      "graph-based convolutional neural networks",
      "graph-embedded convolutional neural networks",
      "residual graph convolutional networks",
      "probabilistic graph convolution",
      "graph convolution"
    ]
  },
  {
    "topic_id": 52,
    "size": 23,
    "keywords": [
      "attention mechanism",
      "mechanism attention",
      "mechanism",
      "attention",
      "mechanism integration",
      "mechanisms roibased",
      "taskspecific attention",
      "sync attention",
      "sync",
      "accumulation"
    ],
    "examples": [
      "soft attention mechanism",
      "attention mechanism integration",
      "task-specific attention mechanism",
      "region-attention mechanisms",
      "roi-based attention mechanism",
      "extended self-attention integration",
      "learned attention map visualization",
      "motion attention mechanism"
    ],
    "topic_fingerprint": "cf997cb8e0600b9d1785aaaa8f167e837ac1368398f63d92d6a1b700aca26577",
    "l2_name": "Attention Mechanism",
    "definition": "A computational method that dynamically assigns varying levels of importance to different parts of the input data to improve model focus and performance on specific tasks.",
    "aliases": [
      "attention mechanism",
      "mechanism attention",
      "task-specific attention",
      "roi-based attention",
      "region-attention",
      "soft attention",
      "self-attention integration",
      "motion attention",
      "scene-based attention",
      "frame attention",
      "sync attention",
      "mechanism integration"
    ]
  },
  {
    "topic_id": 53,
    "size": 23,
    "keywords": [
      "multimodal data",
      "data fusion",
      "data",
      "fusion multimodal",
      "multimodal",
      "integration multimodal",
      "sensor",
      "multimodal information",
      "multimodal sensor",
      "sensor integration"
    ],
    "examples": [
      "multimodal information processing",
      "multi-modal sensor fusion",
      "multi-modal data synthesis",
      "multimodal data fusion",
      "multi-channel data fusion",
      "multimodal information fusion",
      "multimodal information fusion",
      "multimodal data fusion techniques"
    ],
    "topic_fingerprint": "8c19abcc25f2f7c23f462f6109852b345f111e1ff8198731e93b3e684e2ebc7b",
    "l2_name": "Multimodal Data Fusion",
    "definition": "The method of integrating and processing data from multiple distinct sources or sensor modalities to create a unified representation.",
    "aliases": [
      "multimodal information fusion",
      "multi-modal sensor fusion",
      "multimodal data integration",
      "sensor fusion",
      "data fusion",
      "multimodal information processing",
      "multi-channel data fusion",
      "multimodal metadata integration"
    ]
  },
  {
    "topic_id": 54,
    "size": 23,
    "keywords": [
      "sparse",
      "techniques sparse",
      "approximation",
      "sparse approximation",
      "sparse representation",
      "optimization sparse",
      "approximation techniques",
      "representation sparse",
      "generation sparse",
      "sparse coding"
    ],
    "examples": [
      "sparse feature subset generation",
      "sparse approximation",
      "sparse approximation techniques",
      "sparse representation classification",
      "sparse representation optimization",
      "sparse coding technique",
      "sparse projection regularization",
      "sparse approximation techniques"
    ],
    "topic_fingerprint": "163dd9b11601d7ddd82e8e8a85703b6893b70934e2805cfa30324c7f39899892",
    "l2_name": "Sparse Approximation",
    "definition": "A methodological approach that seeks to represent data or signals using a minimal number of non-zero coefficients from an overcomplete dictionary or basis set.",
    "aliases": [
      "sparse representation",
      "sparse coding",
      "sparse approximation techniques",
      "optimization sparse",
      "representation sparse",
      "sparse feature subset generation",
      "sparse projection regularization"
    ]
  },
  {
    "topic_id": 55,
    "size": 23,
    "keywords": [
      "measurement",
      "response",
      "time",
      "time measurement",
      "signbased measurement",
      "measurement signbased",
      "signbased",
      "response measurement",
      "sensorbased",
      "sensorbased measurement"
    ],
    "examples": [
      "points registration",
      "reaction time measurement",
      "response pattern consistency analysis",
      "time allocation measurement",
      "prescriptive measure formulation",
      "response time measurement",
      "pupillary response analysis",
      "real-time response measurement"
    ],
    "topic_fingerprint": "a9b9893f689b251ce3a9d61d64fe96a3bbdd728338520f041372e3154fa40a86",
    "l2_name": "Response Time Measurement",
    "definition": "The methodological quantification of the temporal interval between a stimulus presentation and the corresponding behavioral or physiological response.",
    "aliases": [
      "reaction time measurement",
      "response measurement",
      "time measurement",
      "sign-based measurement",
      "sensor-based measurement",
      "real-time response measurement",
      "behavioral response measurement",
      "pupillary response analysis",
      "analysis of time processing stages"
    ]
  },
  {
    "topic_id": 56,
    "size": 23,
    "keywords": [
      "semantic",
      "semantic analysis",
      "modeling semantic",
      "contextual semantic",
      "contextual",
      "context",
      "adjectivenoun",
      "analysis contextual",
      "semanticrich context",
      "interpretable semantic"
    ],
    "examples": [
      "microblog semantic analysis",
      "semantic differential method",
      "semantic evaluation benchmarking",
      "semantic feature extraction",
      "contextual semantic analysis",
      "contextual semantic analysis",
      "contextual semantic analysis",
      "interpretable semantic features"
    ],
    "topic_fingerprint": "2f9813497d50abc32d033e4beb4dd0a2340bf5ca3fc3b3f778c82c486f85bb2b",
    "l2_name": "Semantic Analysis",
    "definition": "A method for extracting and interpreting meaning from text by modeling semantic features, contextual relationships, and lexical structures such as adjective-noun pairs.",
    "aliases": [
      "semantic analysis",
      "contextual semantic analysis",
      "semantic feature extraction",
      "interpretable semantic analysis",
      "lexical semantic clustering",
      "semantic differential method",
      "semantic evaluation",
      "semantic modeling"
    ]
  },
  {
    "topic_id": 57,
    "size": 23,
    "keywords": [
      "joint",
      "learning joint",
      "joint learning",
      "joint representation",
      "joint regression",
      "globallocal joint",
      "representation joint",
      "representation learning",
      "regression model",
      "model learning"
    ],
    "examples": [
      "vertical-aware learning prediction",
      "joint classifier optimization",
      "joint block-weighted collaborative representation",
      "joint visual-textual learning",
      "joint modeling approach",
      "joint expression and pose learning",
      "joint regression model learning",
      "joint regression model learning"
    ],
    "topic_fingerprint": "42694c2784d424fb32523ea03281d7731ac52330931e675bd3428669418fcbeb",
    "l2_name": "Joint Learning",
    "definition": "A methodological approach that simultaneously optimizes multiple related tasks, representations, or data modalities within a unified framework to leverage shared information and improve overall performance.",
    "aliases": [
      "joint representation learning",
      "joint regression",
      "joint modeling",
      "shared representation learning",
      "multi-task joint learning",
      "end-to-end joint learning",
      "joint optimization"
    ]
  },
  {
    "topic_id": 58,
    "size": 22,
    "keywords": [
      "sentiment",
      "sentiment analysis",
      "social media",
      "media",
      "social",
      "extraction sentiment",
      "fewshot sentiment",
      "media data",
      "sentiment classification",
      "fewshot"
    ],
    "examples": [
      "sentiment sentence compression",
      "lexical emotion vector modeling",
      "perception vector construction",
      "computational sentiment modeling",
      "microblog trend tracking system",
      "social media sentiment analysis",
      "fuzzy sentiment word framework",
      "word polarity mapping"
    ],
    "topic_fingerprint": "daff9bc98187718b6f974164cbfa4a6e5f8f5c8c87efb10b9e341f5dd854ea3e",
    "l2_name": "Sentiment Analysis",
    "definition": "The computational method of identifying, extracting, and classifying subjective opinions, emotions, and attitudes from text data, particularly within social media contexts.",
    "aliases": [
      "Opinion Mining",
      "Sentiment Classification",
      "Emotion Analysis",
      "Polarity Detection",
      "Sentiment Extraction",
      "Affect Analysis"
    ]
  },
  {
    "topic_id": 59,
    "size": 22,
    "keywords": [
      "signal",
      "multimodal signal",
      "signal processing",
      "signal fusion",
      "processing multimodal",
      "processing",
      "signal integration",
      "intelligent signal",
      "intelligent",
      "control"
    ],
    "examples": [
      "frequency-dependent signal processing",
      "multimodal signal integration",
      "multimodal signal integration",
      "intelligent signal processing techniques",
      "intelligent signal processing",
      "intelligent signal processing",
      "multi-channel signal processing",
      "multimodal signal integration"
    ],
    "topic_fingerprint": "a9f11ae5d4b28028d78631c955fb796c43b1661b9c11c199f934bb60a55635ca",
    "l2_name": "Multimodal Signal Processing",
    "definition": "The computational analysis, integration, and fusion of diverse signal types to extract intelligent insights or generate control outputs.",
    "aliases": [
      "signal processing",
      "multimodal signal fusion",
      "signal integration",
      "intelligent signal processing",
      "processing multimodal signals",
      "multi-channel signal processing",
      "social signal processing",
      "time-series signal processing",
      "frequency-dependent signal processing",
      "multi-grained control signals"
    ]
  },
  {
    "topic_id": 60,
    "size": 22,
    "keywords": [
      "gesture",
      "microgesture",
      "gesture recognition",
      "sequence integration",
      "online",
      "online gesture",
      "microgesture sequence",
      "classification online",
      "gaze",
      "automatic"
    ],
    "examples": [
      "eye movement tracking",
      "recognition algorithm suggestions",
      "recognition framework suggestions",
      "gaze tracking analysis",
      "automatic recognition tool development",
      "eye-tracking measurement techniques",
      "gaze direction manipulation",
      "gaze-au-pose feature extraction"
    ],
    "topic_fingerprint": "1efcbd8123e3b4ef39bb7fb0e045da39054e53e62239cfb89fc59775c703d821",
    "l2_name": "Online Gesture Recognition",
    "definition": "The real-time detection, classification, and sequence integration of micro-gestures and gaze patterns using automated algorithms.",
    "aliases": [
      "online gesture",
      "microgesture recognition",
      "automatic gesture classification",
      "real-time gesture analysis",
      "gaze-based gesture recognition",
      "micro-gesture sequence integration"
    ]
  },
  {
    "topic_id": 61,
    "size": 22,
    "keywords": [
      "multiview",
      "lstm training",
      "multiview lstm",
      "training multiview",
      "lstm",
      "training",
      "learning multiview",
      "gradientfriendly multiview",
      "architecture trainable",
      "multiview transformer"
    ],
    "examples": [
      "multi-view subspace learning",
      "multi-viewpoint experimental design",
      "multi-view convolutional neural networks",
      "multi-view deep neural networks",
      "multi-view lstm training",
      "multi-view lstm training",
      "multi-view lstm training",
      "multi-view lstm training"
    ],
    "topic_fingerprint": "a96d19596afa80815e74b8dc1be3de594e8a28434310ed9bf01dccff60599899",
    "l2_name": "Multi-view LSTM Training",
    "definition": "A method for training Long Short-Term Memory networks to process and integrate features from multiple distinct views or representations of sequential data.",
    "aliases": [
      "multiview lstm training",
      "multi-view lstm",
      "mv-lstm training",
      "training multiview lstm",
      "multi-view recurrent learning",
      "gradient-friendly multiview lstm",
      "multiview transformer lstm"
    ]
  },
  {
    "topic_id": 62,
    "size": 22,
    "keywords": [
      "multilabel",
      "multilabel learning",
      "learning multilabel",
      "label",
      "multilabel coregularization",
      "loss multilabel",
      "labelefficient learning",
      "labelefficient",
      "learning methods",
      "coregularization"
    ],
    "examples": [
      "university group labeling",
      "multi-label learning",
      "multi-label residual learning",
      "multi-label label propagation",
      "multi-label co-regularization loss",
      "multi-label co-regularization",
      "multi-label learning",
      "multi-label learning"
    ],
    "topic_fingerprint": "d343a3c1e6306318e215f4b7647daa98b2529386b60d1b64e2c157d3cf3ca5e5",
    "l2_name": "Multi-label Learning",
    "definition": "A machine learning paradigm where each instance is associated with multiple labels simultaneously rather than a single class.",
    "aliases": [
      "multilabel learning",
      "multi-label classification",
      "multilabel classification",
      "label-efficient learning",
      "multi-label co-regularization",
      "multi-label residual learning",
      "multi-label label propagation"
    ]
  },
  {
    "topic_id": 63,
    "size": 22,
    "keywords": [
      "spatiotemporal local",
      "local binary",
      "binary",
      "local",
      "binary pattern",
      "patterns",
      "spatiotemporal",
      "binary patterns",
      "patterns spatiotemporal",
      "pattern discriminative"
    ],
    "examples": [
      "spatiotemporal local texture descriptors",
      "spatiotemporal local texture descriptors",
      "spatiotemporal local binary patterns",
      "spatiotemporal local binary patterns",
      "spatiotemporal local monogenic binary pattern",
      "3d local binary patterns",
      "spatiotemporal local binary patterns",
      "volume local binary patterns"
    ],
    "topic_fingerprint": "d676d0b3f681002be5cbb05c5536ca58a04103296283e6789183347d041ce666",
    "l2_name": "Spatiotemporal Local Binary Patterns",
    "definition": "A texture descriptor method that extends local binary patterns to three dimensions to capture spatiotemporal features in video data.",
    "aliases": [
      "STLBP",
      "spatiotemporal local binary pattern",
      "3D local binary patterns",
      "volume local binary patterns",
      "spatiotemporal local texture descriptors",
      "spatiotemporal local monogenic binary pattern",
      "spatiotemporal completed local quantized patterns"
    ]
  },
  {
    "topic_id": 64,
    "size": 21,
    "keywords": [
      "architecture search",
      "neural architecture",
      "search",
      "siamese",
      "search neural",
      "architecture",
      "twostream",
      "twostream neural",
      "siamese representation",
      "search twostream"
    ],
    "examples": [
      "independent shallow network streams",
      "neural architecture search strategy",
      "siamese convolutional neural network",
      "enhanced broad siamese network",
      "enhanced siamese network architecture",
      "neural architecture search",
      "transformer neural architecture search",
      "siamese representation learning"
    ],
    "topic_fingerprint": "bf12433a8fb3b6be48d67deebd3cf5a338f3f030730145aae72991e617d352f7",
    "l2_name": "Neural Architecture Search",
    "definition": "A method for automatically designing optimal neural network architectures using search strategies, often applied to specialized structures like siamese or two-stream networks.",
    "aliases": [
      "NAS",
      "neural architecture search strategy",
      "architecture search",
      "search neural",
      "two-stream neural architecture search",
      "siamese neural architecture search"
    ]
  },
  {
    "topic_id": 65,
    "size": 21,
    "keywords": [
      "fusion strategy",
      "fusion",
      "strategy",
      "multiclassifier",
      "multiclassifier fusion",
      "featurelevel fusion",
      "feature orthogonal",
      "multifeature fusion",
      "orthogonal purification",
      "purification"
    ],
    "examples": [
      "multi-classifier fusion strategy",
      "multi-classifier fusion strategy",
      "weight-based feature fusion",
      "kernel-level feature fusion",
      "multi-source feature fusion",
      "virtual rating fusion algorithm",
      "bow and evector fusion",
      "multi-clue feature fusion"
    ],
    "topic_fingerprint": "8b6c39c94b832e01d5ecfdf06c7873dafd694e6b1dca875a2ba3948f07629226",
    "l2_name": "Feature Fusion Strategy",
    "definition": "A methodological approach that combines multiple features, classifiers, or data sources to enhance model performance through techniques such as feature-level integration, orthogonal purification, or weighted aggregation.",
    "aliases": [
      "fusion strategy",
      "multifeature fusion",
      "feature-level fusion",
      "multi-classifier fusion",
      "multiclassifier fusion strategy",
      "feature fusion strategies",
      "orthogonal purification",
      "weight-based feature fusion",
      "kernel-level feature fusion",
      "multi-source feature fusion"
    ]
  },
  {
    "topic_id": 66,
    "size": 21,
    "keywords": [
      "loss",
      "loss optimization",
      "focal loss",
      "focal",
      "optimization focal",
      "optimization",
      "loss function",
      "adaptive loss",
      "compact",
      "function"
    ],
    "examples": [
      "epsilon-insensitive loss optimization",
      "focal loss optimization",
      "balanced loss optimization",
      "island loss function",
      "deviation enhancement loss function",
      "ccc and f1 loss",
      "minimum class confusion loss",
      "kl divergence optimization"
    ],
    "topic_fingerprint": "1de2e95b3d36e409ffb9ee7cbe8219b264e7ea1dbaf61f90c21ecbf73f039534",
    "l2_name": "Loss Function Optimization",
    "definition": "The design, adaptation, and mathematical refinement of objective functions to improve model training performance, convergence, or specific metric outcomes.",
    "aliases": [
      "loss optimization",
      "objective function optimization",
      "loss function design",
      "adaptive loss",
      "focal loss",
      "epsilon-insensitive loss",
      "minimum class confusion loss",
      "kl divergence optimization",
      "compact variation loss"
    ]
  },
  {
    "topic_id": 67,
    "size": 21,
    "keywords": [
      "physiological",
      "physiological signal",
      "signal",
      "database creation",
      "signal processing",
      "noncontact physiological",
      "creation physiological",
      "signal database",
      "processing physiological",
      "signal acquisition"
    ],
    "examples": [
      "physiological signal analysis",
      "review of neurophysiological evidence",
      "physiological signal feature extraction",
      "non-contact physiological sensing",
      "non-contact physiological signal analysis",
      "physiological signal processing",
      "synthetic occlusion database creation",
      "physiological signal analysis"
    ],
    "topic_fingerprint": "fbe29f755ce2f30bc76222075e1d7a8b730e3e6cdf9b47d3670ec96819487a3f",
    "l2_name": "Physiological Signal Processing",
    "definition": "The acquisition, creation of databases, and computational analysis of biological signals using both contact and non-contact methods.",
    "aliases": [
      "physiological signal analysis",
      "bio-signal processing",
      "non-contact physiological sensing",
      "physiological signal acquisition",
      "biological signal recording",
      "physiological feature extraction"
    ]
  },
  {
    "topic_id": 68,
    "size": 21,
    "keywords": [
      "data augmentation",
      "augmentation",
      "data",
      "4d",
      "augmentation techniques",
      "augmentation strategies",
      "techniques data",
      "overlapping",
      "overlapping sample",
      "augmentation 4d"
    ],
    "examples": [
      "multi-granularity data augmentation",
      "expression retargeting augmentation",
      "overlapping sample data augmentation",
      "overlapping sample data augmentation",
      "4d data augmentation",
      "4d data augmentation",
      "temporal data augmentation",
      "flipping-based data enhancement"
    ],
    "topic_fingerprint": "d06c0df60d82ca8bb5fe8088428d1c5c1f1f2ff8f6adefd842a491bec07d3c48",
    "l2_name": "Data Augmentation",
    "definition": "A method that artificially expands training datasets by applying transformations such as overlapping, temporal shifts, or dimension-specific modifications to improve model generalization.",
    "aliases": [
      "augmentation",
      "data augmentation techniques",
      "augmentation strategies",
      "multi-granularity data augmentation",
      "4d data augmentation",
      "temporal data augmentation",
      "flipping-based data enhancement",
      "overlapping sample data augmentation"
    ]
  },
  {
    "topic_id": 69,
    "size": 20,
    "keywords": [
      "computer vision",
      "computer",
      "vision",
      "vision techniques",
      "analysis computer",
      "vision algorithms",
      "algorithms computer",
      "algorithms",
      "techniques computer",
      "vision analysis"
    ],
    "examples": [
      "computer vision analysis",
      "computer vision algorithms",
      "computer science algorithms",
      "computer vision algorithms",
      "computer vision techniques",
      "computer vision based analysis",
      "computer vision detection systems",
      "computer vision techniques"
    ],
    "topic_fingerprint": "951b1e2a24c80fb4ecd6eec06c0449d4b6a7631c254931bd7af4bde4ea2192f8",
    "l2_name": "Computer Vision",
    "definition": "Computer vision is a field of artificial intelligence that enables computers to derive meaningful information from digital images, videos, and other visual inputs.",
    "aliases": [
      "CV",
      "machine vision",
      "computer vision analysis",
      "computer vision algorithms",
      "computer vision techniques",
      "vision algorithms",
      "image analysis",
      "visual computing"
    ]
  },
  {
    "topic_id": 70,
    "size": 20,
    "keywords": [
      "principle",
      "modeling artificial",
      "artistic principle",
      "principle based",
      "modeling artistic",
      "artistic",
      "artificial intelligence",
      "intelligence",
      "based modeling",
      "artificial"
    ],
    "examples": [
      "component-based pattern recognition",
      "blogger modeling method",
      "component-based pattern modeling",
      "artistic principle based modeling",
      "artistic principle based modeling",
      "artistic principle based modeling",
      "artificial intelligence integration",
      "computer science methodologies"
    ],
    "topic_fingerprint": "efb6d2f9c30ec3e111b97bcda790df3749ead3c6f1159299cda2d1ecde19bc3f",
    "l2_name": "Principle-Based Modeling",
    "definition": "A methodology that constructs artificial or artistic systems by adhering to foundational theoretical principles rather than purely data-driven patterns.",
    "aliases": [
      "principle based modeling",
      "artistic principle based modeling",
      "modeling based on principles",
      "principle-driven modeling",
      "foundational principle modeling"
    ]
  },
  {
    "topic_id": 71,
    "size": 20,
    "keywords": [
      "3d convolutional",
      "3d",
      "networks 3d",
      "convolutional",
      "convolutional networks",
      "networks threestream",
      "3dshift",
      "threestream convolutional",
      "3dshift graph",
      "threestream"
    ],
    "examples": [
      "3d convolutional networks",
      "3d convolutional networks",
      "3d convolutional networks",
      "deep spatial-convolutional networks",
      "three dimensional convolutional neural networks",
      "three-stream convolutional neural network",
      "3d convolutional networks",
      "three-stream convolutional neural network"
    ],
    "topic_fingerprint": "3c56dd98ab6231be3d0b73dd517edd64229937a131c620f82d08d40b606ac055",
    "l2_name": "3D Convolutional Networks",
    "definition": "Deep learning architectures that utilize three-dimensional convolutional operations to extract spatiotemporal features from volumetric data or video sequences.",
    "aliases": [
      "3D CNN",
      "3D convolutional neural networks",
      "three-dimensional convolutional networks",
      "3D convnets",
      "3DShift",
      "Three-stream convolutional networks",
      "3D-inception-resnet",
      "deep spatial-convolutional networks"
    ]
  },
  {
    "topic_id": 72,
    "size": 20,
    "keywords": [
      "conditional random",
      "random",
      "conditional",
      "hidden",
      "random fields",
      "fields",
      "random field",
      "field",
      "field modeling",
      "fields hidden"
    ],
    "examples": [
      "conditional random field model",
      "conditional random fields",
      "hidden semi-crf application",
      "hidden semi-crf architecture",
      "continuous hidden markov models",
      "hidden dynamic conditional random fields",
      "hidden dynamic conditional random fields",
      "hidden conditional random fields"
    ],
    "topic_fingerprint": "c4e71971b8434480e91739770591943f054b00a6765076930065445d066b854f",
    "l2_name": "Conditional Random Fields",
    "definition": "Conditional Random Fields are discriminative probabilistic models used for labeling and segmenting sequential data by modeling the conditional probability of label sequences given input observations.",
    "aliases": [
      "CRF",
      "conditional random field",
      "hidden conditional random fields",
      "HCRF",
      "hidden semi-CRF",
      "dynamic conditional random fields",
      "field modeling"
    ]
  },
  {
    "topic_id": 73,
    "size": 19,
    "keywords": [
      "syntactic",
      "constraint",
      "constraints",
      "constraint local",
      "local model",
      "domain constraints",
      "constraints nodewise",
      "syntactic constraint",
      "constraint integration",
      "syntactic dependency"
    ],
    "examples": [
      "automatic syntactic pattern construction",
      "syntactic path analysis",
      "local constraint linear coding",
      "syntactic representation learning",
      "syntactic constraint integration",
      "syntactic constraint integration",
      "syntactic constraints integration",
      "constraint local model"
    ],
    "topic_fingerprint": "7dea86385f8c40234b05ad7e8246b1add1b127ddab728bf0946e7e2061bdbd18",
    "l2_name": "Syntactic Constraint Modeling",
    "definition": "A method that integrates syntactic structures and domain-specific constraints into local models to guide representation learning or pattern construction.",
    "aliases": [
      "syntactic constraint integration",
      "local constraint modeling",
      "syntactic dependency tree modeling",
      "constraint local model",
      "syntactic pattern construction",
      "nodewise constraint modeling",
      "domain constraint integration"
    ]
  },
  {
    "topic_id": 74,
    "size": 19,
    "keywords": [
      "broad learning",
      "broad",
      "integration broad",
      "learning integration",
      "learning broad",
      "learning completenessinduced",
      "stacked broad",
      "completenessinduced",
      "completenessinduced adaptive",
      "adaptive broad"
    ],
    "examples": [
      "broad learning system",
      "broad learning system",
      "broad learning system integration",
      "broad learning system integration",
      "broad learning system integration",
      "broad learning system integration",
      "broad learning system mapping",
      "broad learning system integration"
    ],
    "topic_fingerprint": "9587f1a21451d12ca635e2041f52d75696346fb644c83bde640636da50b6c730",
    "l2_name": "Broad Learning System",
    "definition": "A flat neural network architecture that constructs feature and enhancement nodes mapped directly to output weights without deep hierarchical stacking.",
    "aliases": [
      "BLS",
      "broad learning",
      "broad learning system integration",
      "stacked broad learning",
      "completeness-induced broad learning",
      "adaptive broad learning"
    ]
  },
  {
    "topic_id": 75,
    "size": 19,
    "keywords": [
      "literature",
      "review",
      "systematic",
      "metaanalysis",
      "systematic literature",
      "synthesis systematic",
      "review synthesis",
      "synthesis",
      "literature review",
      "metaanalysis synthesis"
    ],
    "examples": [
      "conference proceeding compilation",
      "theoretical framework synthesis",
      "systematic literature search",
      "literature review synthesis",
      "specific quantitative analysis",
      "quantitative meta-analysis",
      "literature classification framework",
      "comprehensive literature survey"
    ],
    "topic_fingerprint": "a49448aa010b1de32dceb7a911b6e7f436280cba3f29defea766b44b114fd574",
    "l2_name": "Systematic Review and Meta-Analysis",
    "definition": "A rigorous research method that systematically identifies, selects, appraises, and synthesizes all relevant empirical evidence to answer a specific research question, often incorporating statistical meta-analysis.",
    "aliases": [
      "systematic literature review",
      "meta-analysis",
      "systematic review",
      "literature synthesis",
      "quantitative meta-analysis",
      "systematic literature search",
      "review synthesis",
      "comprehensive literature survey",
      "meta-analysis synthesis",
      "systematic review protocol"
    ]
  },
  {
    "topic_id": 76,
    "size": 19,
    "keywords": [
      "controlled",
      "experimental design",
      "experimental",
      "design",
      "randomized",
      "experimentation",
      "crosscultural",
      "trial",
      "perception experiment",
      "design randomized"
    ],
    "examples": [
      "cross-cultural experimental design",
      "controlled perception experiment",
      "perception experiment design",
      "psychological experimentation",
      "controlled behavioral experiments",
      "randomized experimental design",
      "large-scale subject experimentation",
      "within-subject experimental design"
    ],
    "topic_fingerprint": "09f02d23b858af9fff54ba7ca33e374244d5f5b93e3ca4098460f2f7cf22e92c",
    "l2_name": "Experimental Design",
    "definition": "The structured methodology for planning and conducting controlled or randomized experiments to test hypotheses and measure causal effects.",
    "aliases": [
      "experimental design",
      "controlled experimental design",
      "randomized experimental design",
      "experimentation",
      "controlled trial",
      "randomized controlled trial",
      "perception experiment design",
      "cross-cultural experimental design",
      "within-subject design",
      "behavioral experiment design"
    ]
  },
  {
    "topic_id": 77,
    "size": 19,
    "keywords": [
      "hybrid",
      "hybrid deep",
      "models hybrid",
      "hybrid machine",
      "model hybrid",
      "learning models",
      "learning architecture",
      "deep",
      "deep learning",
      "zeroinitialized"
    ],
    "examples": [
      "hybrid machine learning models",
      "hybrid modeling with support vector machine",
      "hybrid dbn-svm model",
      "hybrid deep learning architecture",
      "fusion neural network model",
      "hybrid deep shallow fusion",
      "regularized deep fusion framework",
      "hybrid deep learning architecture"
    ],
    "topic_fingerprint": "50fa4b8dfda6c829c497641427e9ea041feca91e68f64b5b54480cfffffb89c2",
    "l2_name": "Hybrid Deep Learning",
    "definition": "A methodological approach that integrates deep learning architectures with other machine learning techniques or shallow models to leverage complementary strengths for improved performance.",
    "aliases": [
      "hybrid deep learning models",
      "hybrid deep learning architecture",
      "deep shallow fusion",
      "hybrid neural architecture",
      "fusion neural network",
      "hybrid machine learning models",
      "hybrid AI systems",
      "regularized deep fusion",
      "hybrid DBN-SVM",
      "zero-initialized hybrid models"
    ]
  },
  {
    "topic_id": 78,
    "size": 18,
    "keywords": [
      "information integration",
      "integration",
      "information",
      "crossdomain",
      "integration information",
      "multidisciplinary integration",
      "opinion",
      "images crossdomain",
      "privileged",
      "opinion integration"
    ],
    "examples": [
      "multidisciplinary integration frameworks",
      "interdisciplinary concept integration",
      "reference data integration",
      "side information integration",
      "interdisciplinary research integration",
      "cross-domain dynamic images",
      "cross-domain dynamic images",
      "cross-domain perspective integration"
    ],
    "topic_fingerprint": "7465b236cfcdacdbbb740fdc38acab0baadd8dfd94f1ba94006136e69b482544",
    "l2_name": "Information Integration",
    "definition": "The process of combining data, knowledge, or perspectives from multiple sources, domains, or disciplines to create a unified and coherent view.",
    "aliases": [
      "data integration",
      "cross-domain integration",
      "multidisciplinary integration",
      "interdisciplinary integration",
      "information fusion",
      "side information integration",
      "opinion integration",
      "privileged information integration",
      "full information integration"
    ]
  },
  {
    "topic_id": 79,
    "size": 18,
    "keywords": [
      "independent color",
      "tensor independent",
      "color space",
      "color",
      "space tensor",
      "lbptop feature",
      "lbptop",
      "independent",
      "tensor",
      "space"
    ],
    "examples": [
      "lbp-top feature representation",
      "lbp-top feature extraction",
      "lbp-top feature extraction",
      "lbp-top feature extraction",
      "lbp-top feature extraction",
      "tensor independent color space",
      "tensor independent color space",
      "tensor independent color space"
    ],
    "topic_fingerprint": "07bdb2293b0049e01ee84bf6d51195fc4c42b9ae1c232717b3b44f8ffd8c31fe",
    "l2_name": "LBP-TOP Feature Extraction",
    "definition": "A method for extracting texture features from video sequences by applying Local Binary Patterns on three orthogonal planes within a tensor independent color space.",
    "aliases": [
      "LBP-TOP",
      "Local Binary Patterns on Three Orthogonal Planes",
      "LBPTOP feature representation",
      "tensor independent color space LBP-TOP",
      "LBP-TOP feature extraction"
    ]
  },
  {
    "topic_id": 80,
    "size": 18,
    "keywords": [
      "adaboost",
      "boosting",
      "classification regression",
      "regression trees",
      "trees",
      "tree",
      "adaboost classifier",
      "boosting machine",
      "adaboost learning",
      "learning adaboost"
    ],
    "examples": [
      "boosting machine learning",
      "adaboost ensemble learning",
      "adaboost ensemble learning",
      "boosting tree classifier",
      "classification and regression trees",
      "adaboost classifier training",
      "adaboost classifier ensemble",
      "adaboost classification"
    ],
    "topic_fingerprint": "99d5ee70eeabf395a7e34cac17be9a66ee54788af9501acfa8c7b249e9ce8e4e",
    "l2_name": "AdaBoost",
    "definition": "AdaBoost is an ensemble learning method that combines multiple weak classifiers, typically decision trees, into a strong classifier through iterative boosting.",
    "aliases": [
      "Adaptive Boosting",
      "AdaBoost Classifier",
      "AdaBoost Learning",
      "Boosting Machine",
      "AdaBoost Ensemble",
      "Improved AdaBoost"
    ]
  },
  {
    "topic_id": 81,
    "size": 18,
    "keywords": [
      "distillation",
      "knowledge distillation",
      "knowledge",
      "selfdistillation",
      "knowledge learning",
      "personalized knowledge",
      "distillation framework",
      "personalized",
      "selfdistillation framework",
      "loss selfknowledge"
    ],
    "examples": [
      "adaptive modality distillation",
      "multi-level knowledge distillation",
      "similarity-preserving knowledge distillation",
      "self-distillation framework",
      "decoupled knowledge distillation",
      "intensity distillation loss",
      "self-knowledge distillation model",
      "data distillation framework"
    ],
    "topic_fingerprint": "e318025ddd2fd6e44c97c327aee94832bcae65c05a91eab47bfce19a8bd4600f",
    "l2_name": "Knowledge Distillation",
    "definition": "A method for transferring knowledge from a large teacher model to a smaller student model or within the same model to improve efficiency and performance.",
    "aliases": [
      "distillation",
      "knowledge learning",
      "self-distillation",
      "self-knowledge distillation",
      "personalized knowledge distillation",
      "data distillation",
      "KD"
    ]
  },
  {
    "topic_id": 82,
    "size": 18,
    "keywords": [
      "survey",
      "survey design",
      "crosssectional survey",
      "crosssectional",
      "questionnaire",
      "design",
      "questionnaire survey",
      "study design",
      "study",
      "design questionnaire"
    ],
    "examples": [
      "cross-sectional survey design",
      "case-control study design",
      "questionnaire survey analysis",
      "survey data collection",
      "questionnaire survey method",
      "cross-cultural survey analysis",
      "feasibility study design",
      "questionnaire survey method"
    ],
    "topic_fingerprint": "4d382831e7ae87f729c8b64211033e524557435e51d5cd173b0795b6e4e77f3b",
    "l2_name": "Survey Design",
    "definition": "The methodological framework for planning and structuring surveys, including questionnaire development, sampling strategies, and data collection procedures.",
    "aliases": [
      "survey methodology",
      "questionnaire design",
      "cross-sectional survey",
      "study design",
      "survey research design",
      "questionnaire survey",
      "design of surveys",
      "survey instrument design"
    ]
  },
  {
    "topic_id": 83,
    "size": 18,
    "keywords": [
      "learning classification",
      "machine learning",
      "machine",
      "classification machine",
      "classification",
      "learning machine",
      "extreme",
      "extreme learning",
      "learning algorithm",
      "classification random"
    ],
    "examples": [
      "extreme learning machine classifier",
      "extreme learning machine classifier",
      "classification accuracy verification",
      "speeded classification task",
      "machine learning classification",
      "random forest classification",
      "deep learning classification",
      "machine learning algorithm comparison"
    ],
    "topic_fingerprint": "2051863dacb0fa6aea939dac18105b6818051b7838ffb6acb74fe9f473564aea",
    "l2_name": "Machine Learning Classification",
    "definition": "The application of machine learning algorithms to categorize data into predefined classes or labels.",
    "aliases": [
      "ML classification",
      "classification machine learning",
      "machine learning classifier",
      "learning classification",
      "classification algorithm",
      "supervised classification"
    ]
  },
  {
    "topic_id": 84,
    "size": 18,
    "keywords": [
      "emotion modeling",
      "emotion",
      "usercentric",
      "modeling dimensional",
      "dimensional emotion",
      "auemotion",
      "auemotion mapping",
      "usercentric emotion",
      "dimensional",
      "emotion analysis"
    ],
    "examples": [
      "rule-based emotion modeling",
      "dimensional emotion modeling",
      "dimensional emotion modeling",
      "emotion regression analysis",
      "fake emotion identification",
      "context-dependent emotion labeling",
      "user-centric emotion modeling",
      "user-centric emotion modeling"
    ],
    "topic_fingerprint": "f5e1f259c3acdfa61a6c93644b9544636e6c9402a282065fa7a4a1b3ccc6283f",
    "l2_name": "Dimensional Emotion Modeling",
    "definition": "A methodological approach that represents and analyzes human emotions using continuous multi-dimensional spaces, such as valence and arousal, often incorporating user-centric contexts or facial action unit mappings.",
    "aliases": [
      "dimensional emotion modeling",
      "emotion modeling",
      "user-centric emotion modeling",
      "au-emotion mapping",
      "dimensional emotion analysis",
      "emotion regression analysis",
      "context-dependent emotion labeling",
      "fake emotion identification",
      "emotion-activity mapping",
      "interactive emotion space visualization"
    ]
  },
  {
    "topic_id": 85,
    "size": 18,
    "keywords": [
      "restingstate",
      "restingstate functional",
      "fmri",
      "state fmri",
      "resting",
      "resting state",
      "functional",
      "state",
      "functional mri",
      "fmri resting"
    ],
    "examples": [
      "resting-state functional connectivity",
      "resting-state functional mri",
      "resting-state brain activity measurement",
      "head-down bed rest",
      "resting-state functional magnetic resonance imaging",
      "resting-state functional magnetic resonance imaging",
      "resting state fmri",
      "resting state fmri"
    ],
    "topic_fingerprint": "44cbae4a485b72bf412e9c3ad4389ae8e8f8ce8f878ff92d5308f8e49a7e160f",
    "l2_name": "Resting-state fMRI",
    "definition": "A neuroimaging method that measures spontaneous brain activity and functional connectivity while the subject is not performing an explicit task.",
    "aliases": [
      "resting state fmri",
      "rs-fmri",
      "resting-state functional magnetic resonance imaging",
      "resting-state functional mri",
      "resting state functional connectivity",
      "resting-state brain activity measurement",
      "functional mri resting state"
    ]
  },
  {
    "topic_id": 86,
    "size": 17,
    "keywords": [
      "eventrelated",
      "eventrelated potential",
      "potential",
      "potential recording",
      "recording eventrelated",
      "recording",
      "analysis eventrelated",
      "potential analysis",
      "eventrelated analysis",
      "analysis latent"
    ],
    "examples": [
      "event-related potential recording",
      "event-related potential recording",
      "event-related potential recording",
      "event-related potential analysis",
      "event-related potential recording",
      "event-related potential recording",
      "event-related potential recording",
      "event-related potential recording"
    ],
    "topic_fingerprint": "a5ba9e80c879dcfc6bf4c176b35993e4a1f9cdaa37ce336ad13c26a110971fe4",
    "l2_name": "Event-Related Potential Analysis",
    "definition": "A method involving the recording and statistical analysis of brain electrical activity time-locked to specific sensory, cognitive, or motor events.",
    "aliases": [
      "ERP recording",
      "event-related potential recording",
      "potential analysis",
      "latent profile analysis",
      "event-related analysis",
      "ERP analysis"
    ]
  },
  {
    "topic_id": 87,
    "size": 17,
    "keywords": [
      "flow",
      "optical",
      "optical flow",
      "opticalflowdriven",
      "flow feature",
      "mean optical",
      "opticalflowdriven frame",
      "directional mean",
      "frame alignment",
      "flow opticalflowdriven"
    ],
    "examples": [
      "optical flow vector integration",
      "main directional mean optical flow",
      "optical-flow-driven frame alignment",
      "main directional mean optical flow",
      "optical-flow-driven frame alignment",
      "main directional mean optical flow",
      "optical-flow-driven frame alignment",
      "optical flow sequence input"
    ],
    "topic_fingerprint": "8105801dc8886035cbd155af8fbe675c0878fc1050c80d9fe1e7bdcb3068d7f9",
    "l2_name": "Optical Flow",
    "definition": "A computer vision technique that estimates the motion of objects between consecutive video frames by analyzing pixel intensity changes.",
    "aliases": [
      "opticalflowdriven",
      "flow feature",
      "mean optical flow",
      "directional mean optical flow",
      "optical flow vector integration",
      "optical-flow-driven frame alignment",
      "optical flow sequence input",
      "optical flow disentanglement",
      "optical flow feature extraction",
      "rgb-d flow algorithm",
      "optical flow based representation"
    ]
  },
  {
    "topic_id": 88,
    "size": 17,
    "keywords": [
      "multimodal feature",
      "fusion multimodal",
      "feature fusion",
      "multimodal",
      "fusion",
      "multimodal depth",
      "architecture aligned",
      "space fusion",
      "set integration",
      "bimodality feature"
    ],
    "examples": [
      "multi-modal feature fusion",
      "multi-modal feature fusion",
      "multi-modal feature fusion",
      "multi-modal feature fusion",
      "multi-modal feature fusion",
      "multi-modal feature fusion",
      "multimodal feature aggregation",
      "multi-modal feature fusion"
    ],
    "topic_fingerprint": "9fc402c0fdd20aa65acf100f819a78f0cc27ac3855257a550a81b41e41b0d36e",
    "l2_name": "Multimodal Feature Fusion",
    "definition": "The method of integrating and combining features from multiple distinct data modalities to create a unified representation for improved model performance.",
    "aliases": [
      "multi-modal feature fusion",
      "feature fusion",
      "multimodal fusion",
      "fusion multimodal",
      "multimodal feature aggregation",
      "bi-modality feature fusion",
      "space fusion",
      "set integration",
      "multimodal depth integration",
      "architecture aligned fusion"
    ]
  },
  {
    "topic_id": 89,
    "size": 17,
    "keywords": [
      "annotation",
      "agreement",
      "annotation scheme",
      "agreement analysis",
      "manual",
      "scheme",
      "corpus",
      "manual term",
      "discrete",
      "multiannotation corpus"
    ],
    "examples": [
      "structured annotation schema",
      "automatic glossary orientation annotation",
      "annotation scheme design",
      "in-depth corpus analysis",
      "native speaker annotation",
      "annotator agreement analysis",
      "manual term categorization",
      "manual stress annotation scheme"
    ],
    "topic_fingerprint": "122b655a23f53cdf2310b6b6a2dc5d40d756d018bbe1712d76181a0c8f16e25c",
    "l2_name": "Annotation Methodology",
    "definition": "The systematic design, implementation, and evaluation of manual or semi-automatic schemes for labeling linguistic data, including the analysis of annotator agreement.",
    "aliases": [
      "annotation scheme",
      "manual annotation",
      "annotator agreement analysis",
      "data annotation strategies",
      "corpus annotation",
      "labeling methodology",
      "annotation protocol"
    ]
  },
  {
    "topic_id": 90,
    "size": 17,
    "keywords": [
      "decision",
      "decision level",
      "level",
      "level fusion",
      "decisionlevel fusion",
      "decisionlevel",
      "decision fusion",
      "fusion decisionlevel",
      "fusion decision",
      "fusion"
    ],
    "examples": [
      "decision level fusion",
      "random forests decision fusion",
      "decision level classifier fusion",
      "decision fusion strategy",
      "todim decision making method",
      "decision-level fusion",
      "decision-level fusion approach",
      "decision level fusion strategy"
    ],
    "topic_fingerprint": "7b6cb6a55133f98f6e16fa19228938f1fdf1c93e9e823ee715141f9944507ec5",
    "l2_name": "Decision Level Fusion",
    "definition": "A method that combines the final outputs or decisions of multiple classifiers or models to produce a unified result.",
    "aliases": [
      "decision fusion",
      "decision-level fusion",
      "decision level classifier fusion",
      "fusion at decision level",
      "late fusion"
    ]
  },
  {
    "topic_id": 91,
    "size": 16,
    "keywords": [
      "architectures",
      "architectures deep",
      "architecture deep",
      "learning architectures",
      "deep learning",
      "learning architecture",
      "deep neural",
      "neural architectures",
      "architecture",
      "deep"
    ],
    "examples": [
      "mixed model architecture",
      "two-layer modeling architecture",
      "deep learning architectures",
      "deep learning architecture",
      "deep neural network architectures",
      "deep neural architectures",
      "deep neural architectures",
      "small-footprint model architecture"
    ],
    "topic_fingerprint": "cda0e3dc80ca718ab0aa5416a1c01e882bba1a1ad3f87066b1c5d61fd50a2580",
    "l2_name": "Deep Learning Architecture",
    "definition": "The structural design and configuration of deep neural networks used for machine learning tasks.",
    "aliases": [
      "deep learning architectures",
      "deep neural architectures",
      "neural architectures",
      "deep neural network architectures",
      "learning architectures",
      "architecture deep",
      "architectures deep",
      "deep learning architecture",
      "learning architecture",
      "mixed model architecture",
      "two-layer modeling architecture",
      "small-footprint model architecture",
      "distributed training architecture"
    ]
  },
  {
    "topic_id": 92,
    "size": 16,
    "keywords": [
      "endtoend",
      "endtoend deep",
      "learning endtoend",
      "networks endtoend",
      "endtoend architecture",
      "endtoend convolutional",
      "architecture endtoend",
      "design endtoend",
      "architecture design",
      "deep learning"
    ],
    "examples": [
      "end-to-end deep neural networks",
      "end-to-end optimization",
      "end-to-end deep learning",
      "end-to-end convolutional neural networks",
      "end-to-end convolutional neural networks",
      "end-to-end deep learning architecture",
      "end-to-end architecture design",
      "end-to-end architecture design"
    ],
    "topic_fingerprint": "9f781e4380cd6fb01f8f37a9366ec2561ebb12f99bf6098af8f59a5981bed2de",
    "l2_name": "End-to-End Learning",
    "definition": "A method where deep neural networks are trained to map raw inputs directly to desired outputs without manual feature engineering or intermediate task-specific modules.",
    "aliases": [
      "end-to-end deep learning",
      "end-to-end optimization",
      "end-to-end architecture",
      "end-to-end CNN",
      "end-to-end deep network",
      "data-driven end-to-end learning",
      "end-to-end design"
    ]
  },
  {
    "topic_id": 93,
    "size": 16,
    "keywords": [
      "graph attention",
      "attention networks",
      "adjacency",
      "adjacency matrix",
      "graph",
      "adjacencyexplainable",
      "adjacencyexplainable graph",
      "networks adjacencyexplainable",
      "mechanisms graph",
      "layerwise adjacency"
    ],
    "examples": [
      "dynamic adjacency matrix learning",
      "graph attention network integration",
      "graph attention network",
      "graph attention networks",
      "graph attention networks",
      "graph attention networks",
      "layerwise adjacency matrix utilization",
      "layerwise adjacency matrix utilization"
    ],
    "topic_fingerprint": "96f218a6be5d476e4e19d5e32611f3fa2b408368fc6c004758d3f5db36de4109",
    "l2_name": "Graph Attention Networks",
    "definition": "A method that employs attention mechanisms to dynamically learn and weight adjacency relationships within graph neural networks.",
    "aliases": [
      "GAT",
      "graph attention network",
      "graph attention mechanisms",
      "dynamic adjacency matrix learning",
      "adjacency-explainable graph neural networks",
      "layerwise adjacency matrix utilization"
    ]
  },
  {
    "topic_id": 94,
    "size": 16,
    "keywords": [
      "data collection",
      "collection",
      "data",
      "collection multimodal",
      "multimodal data",
      "camera",
      "collection macroexpression",
      "macroexpression data",
      "collection highspeed",
      "highspeed camera"
    ],
    "examples": [
      "audio-visual data collection",
      "high-speed camera data collection",
      "high-speed camera data collection",
      "macro-expression data collection",
      "macro-expression data collection",
      "audio-video data collection",
      "multimodal physiological data collection",
      "multimodal data collection"
    ],
    "topic_fingerprint": "b53928efcf8d689487e28f539f25079c4e0e8e0aa3b1c0389d7a84353e6c2438",
    "l2_name": "Data Collection",
    "definition": "The systematic process of gathering and measuring information on variables of interest, often utilizing specific modalities such as high-speed cameras or multimodal sensors to capture macro-expressions and other targeted data.",
    "aliases": [
      "data gathering",
      "information collection",
      "multimodal data collection",
      "high-speed camera data collection",
      "macro-expression data collection",
      "audio-visual data collection",
      "dataset creation",
      "data acquisition"
    ]
  },
  {
    "topic_id": 95,
    "size": 16,
    "keywords": [
      "maximum",
      "maximum mean",
      "mean discrepancy",
      "discrepancy",
      "mean",
      "main",
      "maximal difference",
      "maximal",
      "mutual information",
      "directional maximal"
    ],
    "examples": [
      "maximum entropy model",
      "maximum entropy principle optimization",
      "maximum mutual information criterion",
      "maximum mean discrepancy measurement",
      "anisotropic effect-size signed differential mapping",
      "maximum mean discrepancy minimization",
      "main directional maximal difference analysis",
      "main directional maximal difference"
    ],
    "topic_fingerprint": "0006fc23627a0b286f68d587e35660ae0b09668643cec7c50ff96df69255e0bb",
    "l2_name": "Maximum Mean Discrepancy",
    "definition": "A statistical test that quantifies the difference between two probability distributions by computing the maximum difference in expectations over a unit ball in a reproducing kernel Hilbert space.",
    "aliases": [
      "MMD",
      "maximum mean discrepancy measurement",
      "maximum mean discrepancy minimization",
      "maximum mean discrepancy alignment",
      "maximum mean discrepancy loss",
      "main directional maximal difference",
      "main directional maximal difference analysis",
      "maximal difference",
      "directional maximal"
    ]
  },
  {
    "topic_id": 96,
    "size": 15,
    "keywords": [
      "selfsupervised",
      "selfsupervised pretraining",
      "pretraining",
      "videomae",
      "videomae selfsupervised",
      "pretraining selfsupervised",
      "dualmodal",
      "pretraining videomae",
      "selfsupervised representation",
      "dualmodal selfsupervised"
    ],
    "examples": [
      "self-supervised learning approach",
      "self-supervised pre-training",
      "self-supervised representation learning",
      "self-supervised pre-training with unlabeled data",
      "self-supervised learning assistance",
      "videomae self-supervised pre-training",
      "videomae self-supervised pre-training",
      "videomae self-supervised pre-training"
    ],
    "topic_fingerprint": "65a9846f94272cc39d7eba51760dd35d73eb6c88d5b39ba9383d204b533ed8dc",
    "l2_name": "Self-Supervised Pretraining",
    "definition": "A method that learns data representations by solving pretext tasks on unlabeled data before fine-tuning for downstream applications.",
    "aliases": [
      "self-supervised learning",
      "SSL",
      "self-supervised representation learning",
      "pretraining",
      "self-supervised pre-training",
      "unlabeled pretraining"
    ]
  },
  {
    "topic_id": 97,
    "size": 15,
    "keywords": [
      "sparse learning",
      "shared sparse",
      "shared",
      "sparse",
      "learning shared",
      "learning model",
      "dynamic segmented",
      "data shrinking",
      "bilateral sparse",
      "analysis shared"
    ],
    "examples": [
      "incomplete sparse least square regression",
      "shared sparse learning optimization",
      "shared sparse learning",
      "double sparse learning model",
      "sparse linear discriminant analysis",
      "shared sparse learning",
      "shared sparse learning",
      "shared sparse learning"
    ],
    "topic_fingerprint": "cafe0a482631f76a948611a7b7da51b4b8a4e30784b03a8ef3fcf96ce4c25c74",
    "l2_name": "Shared Sparse Learning",
    "definition": "A machine learning methodology that simultaneously enforces sparsity constraints and shares structural information or parameters across multiple related tasks or data segments.",
    "aliases": [
      "shared sparse learning optimization",
      "double sparse learning model",
      "bilateral sparse learning",
      "sparse learning with shared structure",
      "shared sparse regression",
      "incomplete sparse least square regression",
      "dynamic segmented sparse learning"
    ]
  },
  {
    "topic_id": 98,
    "size": 15,
    "keywords": [
      "memory",
      "long",
      "shortterm memory",
      "shortterm",
      "long shortterm",
      "memory networks",
      "networks long",
      "memory long",
      "long short",
      "term memory"
    ],
    "examples": [
      "long short term memory",
      "long short-term memory networks",
      "long short-term memory networks",
      "long short-term memory networks",
      "attention-long short-term memory",
      "long short term memory networks",
      "long short-term memory networks",
      "long short-term memory networks"
    ],
    "topic_fingerprint": "c86168c09c9472ea41277af1099733a24a43b506f4cc9e136d003effbf350ef7",
    "l2_name": "Long Short-Term Memory",
    "definition": "A recurrent neural network architecture designed to learn long-term dependencies by utilizing memory cells and gating mechanisms.",
    "aliases": [
      "LSTM",
      "long short term memory",
      "long short-term memory networks",
      "LSTM networks",
      "memory networks",
      "attention-long short-term memory",
      "graph long short-term memory",
      "long short-term memory modeling"
    ]
  },
  {
    "topic_id": 99,
    "size": 15,
    "keywords": [
      "microexpression",
      "recognition test",
      "test",
      "computational microexpression",
      "analysis microexpression",
      "microexpression analysis",
      "microexpression recognition",
      "automatic microexpression",
      "microexpression generation",
      "synthesized"
    ],
    "examples": [
      "micro-expression video clip elicitation",
      "micro-expression database construction",
      "micro-expression recognition measurement",
      "micro-expression training tools",
      "synthesized micro-expression stimuli",
      "brief expression recognition test",
      "macro-expression recognition test",
      "micro-expression recognition test"
    ],
    "topic_fingerprint": "f80e36b5b59e721c45295c44703e1430f8219bf2899efd5809b2d27e00cc803f",
    "l2_name": "Microexpression Recognition and Analysis",
    "definition": "The computational and experimental methodology for detecting, generating, synthesizing, and evaluating brief involuntary facial expressions through automated processing and recognition tests.",
    "aliases": [
      "microexpression recognition",
      "microexpression analysis",
      "automatic microexpression processing",
      "computational microexpression analysis",
      "microexpression generation",
      "synthesized microexpressions",
      "microexpression recognition test",
      "brief expression recognition",
      "ME recognition",
      "ME analysis"
    ]
  },
  {
    "topic_id": 100,
    "size": 15,
    "keywords": [
      "joint distribution",
      "joint",
      "distribution adaptation",
      "adaptation",
      "distribution",
      "adaptation mechanism",
      "adaptation marginal",
      "conditional adaptation",
      "conflict",
      "optimization framework"
    ],
    "examples": [
      "joint factor optimization",
      "joint factor optimization",
      "joint optimization framework",
      "joint optimization framework",
      "joint distribution adaptive regression",
      "dynamic joint distribution adaptation",
      "marginal and conditional adaptation",
      "emotion-fact coordinated optimization"
    ],
    "topic_fingerprint": "2fd24354f8b2b3d471828e3b9e83202b9fe8600047c2e9ca1ae2ed7e7fd207b1",
    "l2_name": "Joint Distribution Adaptation",
    "definition": "A method that simultaneously aligns both marginal and conditional distributions between source and target domains to reduce domain shift.",
    "aliases": [
      "JDA",
      "joint distribution adaptive regression",
      "dynamic joint distribution adaptation",
      "marginal and conditional adaptation",
      "joint factor optimization",
      "joint optimization framework"
    ]
  },
  {
    "topic_id": 101,
    "size": 15,
    "keywords": [
      "graph neural",
      "causal",
      "networks graph",
      "graph",
      "networks causal",
      "deep nodegraph",
      "nodegraph",
      "neural networks",
      "neural",
      "causal aware"
    ],
    "examples": [
      "graph neural network architectures",
      "graph neural networks",
      "graph neural networks",
      "graph neural networks",
      "causal aware interaction network",
      "graph neural networks",
      "causal directed acyclic graph",
      "graph neural network encoding"
    ],
    "topic_fingerprint": "3f6fdf93de798731385948f566b306585d8077e389bb659330fc4e6e4d3fda2b",
    "l2_name": "Causal Graph Neural Networks",
    "definition": "A methodological approach that integrates causal inference principles with graph neural network architectures to learn robust representations and identify causal relationships within graph-structured data.",
    "aliases": [
      "causal GNN",
      "causal-aware graph neural networks",
      "deep node-graph learning",
      "causal directed acyclic graph networks",
      "genetic causal inference with GNNs",
      "causal interaction networks"
    ]
  },
  {
    "topic_id": 102,
    "size": 15,
    "keywords": [
      "unsupervised",
      "learning unsupervised",
      "unsupervised emotion",
      "image reconstruction",
      "unsupervised representation",
      "unsupervised latent",
      "representation learning",
      "emotion learning",
      "latent representation",
      "reconstruction"
    ],
    "examples": [
      "unsupervised feature learning",
      "image resolution enhancement",
      "unsupervised representation learning",
      "unsupervised representation learning",
      "image reconstruction evaluation",
      "unsupervised latent representation learning",
      "unsupervised latent representation learning",
      "unsupervised latent representation learning"
    ],
    "topic_fingerprint": "f18c3d63759d279e4643f7079332d9091153f2e10b8bf16e4ab9aaa921bfdf1d",
    "l2_name": "Unsupervised Representation Learning",
    "definition": "A machine learning method that automatically discovers meaningful patterns, latent structures, or feature representations from unlabeled data without explicit supervision.",
    "aliases": [
      "unsupervised learning",
      "unsupervised feature learning",
      "unsupervised latent representation learning",
      "deep unsupervised representation learning",
      "representation learning",
      "latent representation learning",
      "unsupervised emotion learning",
      "unsupervised image reconstruction"
    ]
  },
  {
    "topic_id": 103,
    "size": 15,
    "keywords": [
      "auxiliary",
      "supervision",
      "unsupervised cost",
      "auxiliary supervision",
      "modality selection",
      "supervision module",
      "cost",
      "auxiliary set",
      "auxiliary information",
      "cost function"
    ],
    "examples": [
      "auxiliary unsupervised cost function",
      "auxiliary unsupervised cost function",
      "auxiliary set selection model",
      "auxiliary set selection model",
      "multimodal network structure",
      "missing modality imagination network",
      "auxiliary distribution supervision",
      "data-dependent auxiliary information module"
    ],
    "topic_fingerprint": "0a098871e5bf6a0ca60f8406a6ccd2171877e0ca895d3840d583dffd8776e93c",
    "l2_name": "Auxiliary Supervision",
    "definition": "A method that leverages auxiliary information, sets, or modalities to construct unsupervised cost functions or supervision modules for guiding model training.",
    "aliases": [
      "auxiliary unsupervised cost function",
      "auxiliary set selection model",
      "auxiliary distribution supervision",
      "data-dependent auxiliary information module",
      "main-auxiliary modality selection",
      "auxiliary supervision module",
      "unsupervised cost with auxiliary info",
      "modality selection with auxiliary supervision"
    ]
  },
  {
    "topic_id": 104,
    "size": 15,
    "keywords": [
      "facial feature",
      "prior",
      "facial prior",
      "facial",
      "face",
      "integration facial",
      "prior integration",
      "landmark",
      "facial landmark",
      "finetuning facial"
    ],
    "examples": [
      "facial feature smoothing",
      "face graphical rendering",
      "controlled facial feature matching",
      "morphology based face cropping",
      "vgg-face network fine-tuning",
      "facial landmark extraction",
      "facial prior knowledge fusion",
      "facial feature decoupling"
    ],
    "topic_fingerprint": "282753ce362a5b0a0be1ab1a520b02ab08f6cd95d0cbb7b974277093aded7f35",
    "l2_name": "Facial Prior Integration",
    "definition": "The method of incorporating pre-existing facial knowledge, such as landmarks, shapes, or feature distributions, into models to guide generation, reconstruction, or analysis tasks.",
    "aliases": [
      "facial prior",
      "prior integration",
      "facial prior knowledge fusion",
      "facial prior integration",
      "aesthetic prior model",
      "3d face shape features",
      "facial feature decoupling",
      "facial landmark calibration"
    ]
  },
  {
    "topic_id": 105,
    "size": 14,
    "keywords": [
      "model adaptation",
      "target sample",
      "experts",
      "target",
      "adapter",
      "statictodynamic",
      "sample regeneration",
      "mixture adapter",
      "adapter experts",
      "statictodynamic model"
    ],
    "examples": [
      "pad emotion model",
      "target sample re-generation",
      "target sample re-generation",
      "nested alternating optimization",
      "residual adapter integration",
      "pretrained model adaptation",
      "target sample reconstruction",
      "enrolment-based model adaptation"
    ],
    "topic_fingerprint": "6ff7bdf7d3d8de0df22271b7d9bdb9e3e226fab542cddd0a19a9dd3cd6128bbb",
    "l2_name": "Target-Specific Model Adaptation",
    "definition": "A method that adapts a static source model to a specific target domain or sample using techniques such as adapter modules, expert mixtures, or sample regeneration.",
    "aliases": [
      "target sample adaptation",
      "static-to-dynamic adaptation",
      "mixture of adapter experts",
      "target sample re-generation",
      "pretrained model adaptation",
      "adapter-based adaptation",
      "sample-specific model tuning"
    ]
  },
  {
    "topic_id": 106,
    "size": 14,
    "keywords": [
      "cognitive",
      "analysis cognitive",
      "psychology analysis",
      "cognitive psychology",
      "psychology",
      "mechanisms brain",
      "driven mechanisms",
      "driven",
      "mechanisms",
      "reasoning"
    ],
    "examples": [
      "cognitive psychology analysis",
      "cognitive psychology analysis",
      "cognitive task analysis",
      "cognitive mechanism analysis",
      "cognitive bias experimental analysis",
      "cognitive psychology analysis",
      "cognitive science integration",
      "cognitive load measurement"
    ],
    "topic_fingerprint": "f64ad9beb1e397a616e6e399302d9874ee7b1b806042ad5da63140d7e16dfe8a",
    "l2_name": "Cognitive Analysis",
    "definition": "The systematic examination of mental processes such as reasoning, memory, and perception using psychological and neuroscientific methods.",
    "aliases": [
      "cognitive psychology analysis",
      "cognitive task analysis",
      "cognitive mechanism analysis",
      "cognitive bias experimental analysis",
      "cognitive science integration",
      "cognitive load measurement",
      "brain-cognitive driven mechanisms",
      "brain cognition-driven mechanisms",
      "psychology analysis",
      "reasoning analysis"
    ]
  },
  {
    "topic_id": 107,
    "size": 14,
    "keywords": [
      "diffusion",
      "diffusion model",
      "generation diffusion",
      "generation",
      "intermediate model",
      "model generation",
      "intermediate",
      "model analysis",
      "model",
      "textconditioned generation"
    ],
    "examples": [
      "diffusion model analysis",
      "intermediate model space generation",
      "diffusion model analysis",
      "set model memory stage analysis",
      "constraint-based generation modeling",
      "denoising diffusion probabilistic models",
      "text-conditioned generation",
      "conditional diffusion language model"
    ],
    "topic_fingerprint": "1c540dc1b2f42cbbca409bf3f0c0fec2a9d1620b4d224aa1a9e507262ea931af",
    "l2_name": "Diffusion Models",
    "definition": "Generative modeling techniques that synthesize data by iteratively denoising samples from a Gaussian distribution, often conditioned on text or other modalities.",
    "aliases": [
      "diffusion model",
      "denoising diffusion probabilistic models",
      "DDPM",
      "text-conditioned generation",
      "conditional diffusion",
      "intermediate model generation",
      "semantic-constrained bidirectional generation",
      "au-conditioned diffusion modeling"
    ]
  },
  {
    "topic_id": 108,
    "size": 14,
    "keywords": [
      "selfattention",
      "selfattention mechanism",
      "gru",
      "gru selfattention",
      "mechanism application",
      "mechanisms selfattention",
      "application selfattention",
      "mechanism selfattention",
      "based gru",
      "selfattention based"
    ],
    "examples": [
      "self-attention based gru",
      "self-attention based gru",
      "self-attention and convolutional networks",
      "self-attention mechanisms",
      "self-attention mechanisms",
      "self-attention mechanism application",
      "self-attention mechanism application",
      "self-attention mechanism application"
    ],
    "topic_fingerprint": "01ef43f5eecc06d49ad0ae56effbd2d471067e077fc1dbf6fb1d60338712d8a0",
    "l2_name": "Self-Attention GRU",
    "definition": "A hybrid neural network architecture that integrates self-attention mechanisms with Gated Recurrent Units to enhance sequence modeling by dynamically weighting input features.",
    "aliases": [
      "self-attention based GRU",
      "GRU with self-attention",
      "self-attention mechanism application in GRU",
      "bi-directional GRU with attention",
      "self-attention GRU mechanism"
    ]
  },
  {
    "topic_id": 109,
    "size": 14,
    "keywords": [
      "adversarial",
      "binary qa",
      "adversarial binary",
      "qa",
      "qa framework",
      "framework adversarial",
      "affective adversarial",
      "adversarial constraint",
      "learning adversarial",
      "adversarial networks"
    ],
    "examples": [
      "adversarial learning framework",
      "affective adversarial constraint",
      "affective adversarial constraint",
      "adversarial system training",
      "multi-scale adversarial networks",
      "adversarial feature learning",
      "adversarial network training",
      "adversarial networks"
    ],
    "topic_fingerprint": "09fef269f84c06ab690bc2b0f537be00f0ec9b85acdb49de35796955e8f6b443",
    "l2_name": "Adversarial Learning",
    "definition": "A machine learning methodology that employs adversarial networks or constraints to improve model robustness, generate data, or solve specific tasks such as binary question answering.",
    "aliases": [
      "adversarial networks",
      "adversarial training",
      "adversarial framework",
      "GANs",
      "generative adversarial networks",
      "adversarial constraint learning",
      "modal-adversarial learning"
    ]
  },
  {
    "topic_id": 110,
    "size": 14,
    "keywords": [
      "gaussian mixture",
      "mixture",
      "gaussian",
      "mixture model",
      "model estimation",
      "estimation gaussian",
      "estimation",
      "mixture models",
      "models gaussian",
      "model"
    ],
    "examples": [
      "gaussian mixture models",
      "gaussian mixture model supervectors",
      "gaussian mixture model estimation",
      "gaussian mixture model estimation",
      "gaussian mixture model classification",
      "gaussian mixture models",
      "gaussian mixture model clustering",
      "gaussian mixture model"
    ],
    "topic_fingerprint": "360253bb8d8d9a1dc6ad4cf8256fb7214711e6c9ff4078fa5332e34d31c30088",
    "l2_name": "Gaussian Mixture Model",
    "definition": "A probabilistic model that assumes all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters.",
    "aliases": [
      "GMM",
      "Gaussian mixture",
      "mixture of Gaussians",
      "Gaussian mixture models",
      "Gaussian mixture model estimation",
      "GMM estimation"
    ]
  },
  {
    "topic_id": 111,
    "size": 14,
    "keywords": [
      "linear",
      "regression modeling",
      "modeling linear",
      "combination distributions",
      "distributions",
      "linear combination",
      "linear regression",
      "regression",
      "distributions linear",
      "logistic regression"
    ],
    "examples": [
      "piecewise linear transformation",
      "linear relationship modeling",
      "linear regression analysis",
      "linear regression modeling",
      "linear modification model",
      "logistic regression modeling",
      "linear combination of distributions",
      "linear combination of distributions"
    ],
    "topic_fingerprint": "b5e7cca7bd9185673bf3384ea85d9288f5a68ac739a2b1e84be9f3f83d3e3c25",
    "l2_name": "Linear Regression Modeling",
    "definition": "A statistical method for modeling the linear relationship between a dependent variable and one or more independent variables, including extensions like logistic regression and linear combinations of distributions.",
    "aliases": [
      "linear regression",
      "regression modeling",
      "modeling linear",
      "linear relationship modeling",
      "linear regression analysis",
      "logistic regression",
      "logistic regression modeling",
      "multivariate logistic regression",
      "linear combination of distributions",
      "piecewise linear transformation",
      "time-series regression modeling",
      "time-continuous regression modeling"
    ]
  },
  {
    "topic_id": 112,
    "size": 14,
    "keywords": [
      "programming",
      "algorithm",
      "dynamic routing",
      "routing algorithm",
      "routing",
      "greedy equivalence",
      "greedy",
      "gene expression",
      "expression programming",
      "evolutionary algorithm"
    ],
    "examples": [
      "higher effective gene expression programming",
      "genetic algorithm optimization",
      "dynamic programming optimization",
      "evolutionary algorithm application",
      "evolutionary algorithm based feature selection",
      "dynamic routing algorithm",
      "convex optimization based eda decomposition",
      "multiobjective evolution algorithm"
    ],
    "topic_fingerprint": "d20f6721e4c1064005c9f1cbcc9dc44e26381d330c7d8e2e25e0eb11eb8e8da6",
    "l2_name": "Evolutionary Algorithm",
    "definition": "A population-based metaheuristic optimization method inspired by biological evolution that uses mechanisms such as selection, mutation, and recombination to solve complex problems like dynamic routing and gene expression programming.",
    "aliases": [
      "EA",
      "evolutionary computation",
      "genetic algorithm",
      "gene expression programming",
      "multiobjective evolution algorithm",
      "ant lion optimization",
      "evolutionary optimization"
    ]
  },
  {
    "topic_id": 113,
    "size": 14,
    "keywords": [
      "framework deep",
      "framework endtoend",
      "learning framework",
      "framework",
      "endtoend",
      "endtoend learning",
      "deep learning",
      "deep",
      "endtoend deep",
      "endtoend regression"
    ],
    "examples": [
      "novel deep-learning based framework",
      "end-to-end learning framework",
      "end-to-end learning framework",
      "end-to-end deep learning framework",
      "deep learning framework",
      "deep learning framework",
      "deep learning framework",
      "end-to-end regression framework"
    ],
    "topic_fingerprint": "7e56e40bee78363f0184ab56184e217911a833b69e2fc5c423735eaa49ff2633",
    "l2_name": "End-to-End Deep Learning Framework",
    "definition": "A computational architecture that utilizes deep neural networks to learn a direct mapping from raw input data to final output predictions without requiring manual feature engineering or intermediate processing stages.",
    "aliases": [
      "end-to-end learning framework",
      "deep learning framework",
      "end-to-end deep learning",
      "end-to-end regression framework",
      "novel deep-learning based framework",
      "landmark-assisted collaborative deep framework",
      "consolidated eulerian framework",
      "framework deep",
      "framework endtoend",
      "learning framework",
      "endtoend learning",
      "deep learning",
      "endtoend deep",
      "endtoend regression"
    ]
  },
  {
    "topic_id": 114,
    "size": 14,
    "keywords": [
      "network architecture",
      "network architectures",
      "architecture neural",
      "architecture",
      "architectures",
      "neural network",
      "flat network",
      "flat",
      "architecture design",
      "network"
    ],
    "examples": [
      "flat network architecture",
      "flat network architecture",
      "neural network architectures",
      "convolutional neural network architectures",
      "vectorization network architecture",
      "neural network architecture design",
      "aspect-centralized architecture",
      "parallel neural network architecture"
    ],
    "topic_fingerprint": "3e6c77813accd3ba6003b45100476aebf52df1c211d13e90ab66f6c9a1f36a1a",
    "l2_name": "Network Architecture",
    "definition": "The structural design and organization of layers, nodes, and connections within a neural network that determines how data is processed and transformed.",
    "aliases": [
      "neural network architecture",
      "network architectures",
      "architecture design",
      "model architecture",
      "deep learning architecture",
      "NN architecture"
    ]
  },
  {
    "topic_id": 115,
    "size": 13,
    "keywords": [
      "reinforcement learning",
      "reinforcement",
      "framework reinforcement",
      "policy",
      "rewards",
      "optimization reinforcement",
      "policy optimization",
      "learning framework",
      "onpolicy",
      "framework onpolicy"
    ],
    "examples": [
      "policy gradient reinforcement learning",
      "reinforcement learning framework",
      "reinforcement learning framework",
      "reinforcement learning optimization",
      "reinforcement learning for generation",
      "reinforcement learning controller",
      "q-learning algorithm",
      "proximal policy optimization"
    ],
    "topic_fingerprint": "a2d85c62f7c76564dc51f0f8c7413fc7da3a6fbd3877885891ba871472b9f153",
    "l2_name": "Reinforcement Learning",
    "definition": "A machine learning paradigm where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards through policy optimization.",
    "aliases": [
      "RL",
      "reinforcement learning framework",
      "policy optimization",
      "reinforcement learning optimization",
      "on-policy learning",
      "Q-learning",
      "proximal policy optimization",
      "PPO",
      "policy gradient methods"
    ]
  },
  {
    "topic_id": 116,
    "size": 13,
    "keywords": [
      "dynamic graph",
      "graph convolutional",
      "dynamical graph",
      "dynamical",
      "graph",
      "convolutional networks",
      "dynamic",
      "sparse dynamic",
      "networks sparse",
      "hierarchical dynamic"
    ],
    "examples": [
      "dynamical graph convolutional neural networks",
      "dynamical graph convolutional neural networks",
      "sparse dynamic graph convolutional networks",
      "dynamical graph filtering",
      "deep graph convolution network",
      "hierarchical dynamic graph convolutional networks",
      "hierarchical dynamic graph convolutional networks",
      "adaptive hierarchical graph convolution"
    ],
    "topic_fingerprint": "b40c58e657c2467b3958ca1170972eb722088b98b30d0b118cae8fd477a11919",
    "l2_name": "Dynamic Graph Convolutional Networks",
    "definition": "A method that applies convolutional operations on graph structures where the topology or node features evolve over time.",
    "aliases": [
      "DGCN",
      "dynamical graph convolutional neural networks",
      "dynamic graph CNN",
      "sparse dynamic graph convolutional networks",
      "hierarchical dynamic graph convolutional networks",
      "adaptive hierarchical graph convolution",
      "dynamic graph filtering",
      "deep graph convolution network"
    ]
  },
  {
    "topic_id": 117,
    "size": 13,
    "keywords": [
      "openvocabulary",
      "openvocabulary emotion",
      "modeling openvocabulary",
      "emotion modeling",
      "extraction openvocabulary",
      "recognition openvocabulary",
      "emotion extraction",
      "emotion",
      "emotion recognition",
      "emotion generation"
    ],
    "examples": [
      "open-vocabulary emotion extraction",
      "open-vocabulary emotion extraction",
      "open-vocabulary emotion extraction",
      "open-vocabulary emotion recognition",
      "open-vocabulary annotation",
      "open-vocabulary emotion generation",
      "open-vocabulary multimodal recognition",
      "open-vocabulary emotion recognition"
    ],
    "topic_fingerprint": "b90d1c6161a3f896c579cf38af3fb726c62a099097ff879239beee578a33486e",
    "l2_name": "Open-Vocabulary Emotion Analysis",
    "definition": "A methodological approach for detecting, recognizing, extracting, or generating emotions using flexible, non-fixed label sets rather than predefined categorical taxonomies.",
    "aliases": [
      "open-vocabulary emotion recognition",
      "open-vocabulary emotion extraction",
      "open-vocabulary emotion modeling",
      "open-vocabulary emotion generation",
      "open-vocabulary annotation",
      "open-vocabulary multimodal recognition",
      "modeling open-vocabulary emotion",
      "extraction open-vocabulary emotion"
    ]
  },
  {
    "topic_id": 118,
    "size": 13,
    "keywords": [
      "twostage",
      "twostage training",
      "framework twostage",
      "training framework",
      "imagebased classification",
      "twostage classification",
      "imagebased",
      "training",
      "classification",
      "techniques imagebased"
    ],
    "examples": [
      "two-stage classification method",
      "two-stage classification approach",
      "two-stage sampling framework",
      "two-stage training process",
      "two-stage framework",
      "image-based classification techniques",
      "image-based classification approaches",
      "multi-stage neural network"
    ],
    "topic_fingerprint": "6b08b8b5f551995075c5a9e1d06b630165d3f8f13bb17b7974c42eeb52ee18fe",
    "l2_name": "Two-Stage Training Framework",
    "definition": "A methodological approach that divides the model training or classification process into two distinct sequential phases to improve performance or efficiency.",
    "aliases": [
      "two-stage classification method",
      "two-stage classification approach",
      "two-stage sampling framework",
      "two-stage training process",
      "two-stage framework",
      "image-based classification techniques",
      "image-based classification approaches",
      "multi-stage neural network",
      "two-stage fusion decomposition",
      "two-stage training framework",
      "twostage training",
      "framework twostage",
      "training framework",
      "twostage classification",
      "imagebased classification"
    ]
  },
  {
    "topic_id": 119,
    "size": 13,
    "keywords": [
      "techniques pattern",
      "pattern recognition",
      "recognition techniques",
      "pattern",
      "recognition",
      "techniques",
      "techniques sensitivity",
      "algorithms analysis",
      "analysis variance",
      "systems pattern"
    ],
    "examples": [
      "pattern recognition techniques",
      "pattern recognition techniques",
      "pattern recognition algorithms",
      "analysis of variance techniques",
      "pattern recognition techniques",
      "pattern recognition techniques",
      "pattern recognition techniques",
      "pattern recognition systems"
    ],
    "topic_fingerprint": "84aed612df4596834f43345f332b60ab2c7f549c8a05d26fbf7e9408b014aa62",
    "l2_name": "Pattern Recognition",
    "definition": "The automated identification of patterns and regularities in data through the application of algorithms and statistical techniques.",
    "aliases": [
      "pattern recognition techniques",
      "pattern recognition algorithms",
      "pattern recognition systems",
      "recognition techniques",
      "pattern analysis",
      "sensitivity analysis techniques",
      "analysis of variance techniques"
    ]
  },
  {
    "topic_id": 120,
    "size": 13,
    "keywords": [
      "interaction",
      "interaction transformer",
      "context interaction",
      "localglobal interaction",
      "localglobal",
      "external grammar",
      "grammar interaction",
      "internal",
      "internal context",
      "interaction internal"
    ],
    "examples": [
      "content extension method",
      "virtual environment interaction system",
      "local and global label consistency",
      "video coded interaction validation",
      "virtual interaction modes",
      "external grammar interaction",
      "internal context interaction",
      "external grammar interaction"
    ],
    "topic_fingerprint": "cd30f2c271c260b74cdd63ac72967f0fe6d3ae6f7614eb5ed5e1de9aafe352d7",
    "l2_name": "Context Interaction",
    "definition": "A method that models the dynamic exchange of information between internal and external contexts or between local and global scopes to enhance representation learning.",
    "aliases": [
      "interaction transformer",
      "local-global interaction",
      "global-local interaction",
      "context interaction",
      "grammar interaction",
      "internal context interaction",
      "external grammar interaction",
      "efficient local-global interaction transformer"
    ]
  },
  {
    "topic_id": 121,
    "size": 13,
    "keywords": [
      "attribute",
      "node",
      "feature node",
      "node mapping",
      "views",
      "conditionally",
      "conditionally independent",
      "attribute enhancement",
      "independent",
      "feature feature"
    ],
    "examples": [
      "public display deployment",
      "conditionally independent feature views",
      "conditionally independent attribute views",
      "feature node mapping",
      "feature node mapping",
      "automatic feature sharing mechanism",
      "feature-to-label dependency modeling",
      "feature after feature framework"
    ],
    "topic_fingerprint": "aafb9f1644a00e3c48b283ae209e9dd4ec2df04d197c2df2375f0d53c62fdb80",
    "l2_name": "Feature Node Mapping",
    "definition": "A method for establishing conditional independence between attribute views through explicit node mapping and feature aggregation mechanisms.",
    "aliases": [
      "attribute enhancement",
      "feature node mapping",
      "conditionally independent feature views",
      "automatic feature sharing",
      "explicit attribute controller injection",
      "node feature aggregation"
    ]
  },
  {
    "topic_id": 122,
    "size": 13,
    "keywords": [
      "comparative",
      "analysis comparative",
      "comparative result",
      "result analysis",
      "group analysis",
      "comparison comparative",
      "group",
      "result",
      "trauma",
      "subgroup"
    ],
    "examples": [
      "comparative annotation analysis",
      "subgroup analysis of trauma types",
      "two-group classification strategy",
      "comparative result analysis",
      "comparative result analysis",
      "clinical versus control comparison",
      "comparative cultural perspective analysis",
      "comparative demographic analysis"
    ],
    "topic_fingerprint": "a353f1602d402d7b3d4fad2b914815e80d5d6da38c32412cf5c281d4909872be",
    "l2_name": "Comparative Analysis",
    "definition": "A methodological approach that systematically evaluates differences and similarities between two or more groups, conditions, or datasets to derive meaningful insights.",
    "aliases": [
      "comparative study",
      "group comparison",
      "subgroup analysis",
      "comparative assessment",
      "cross-group analysis",
      "stratified comparison",
      "comparative evaluation",
      "two-group analysis",
      "comparative result analysis"
    ]
  },
  {
    "topic_id": 123,
    "size": 12,
    "keywords": [
      "techniques deep",
      "learning techniques",
      "deep learning",
      "deep",
      "learning technology",
      "based deep",
      "techniques",
      "technology integration",
      "integration deep",
      "learning based"
    ],
    "examples": [
      "deep learning techniques",
      "deep learning based system",
      "deep learning based system",
      "deep learning techniques",
      "deep representation learning techniques",
      "deep learning systems",
      "deep learning technology integration",
      "deep learning technology integration"
    ],
    "topic_fingerprint": "aa48ab3e0bb14e58daae4ddfb03a4142be4138ba8e60aafffb03f1cce4ec35e7",
    "l2_name": "Deep Learning",
    "definition": "A subset of machine learning based on artificial neural networks with multiple layers to learn hierarchical data representations.",
    "aliases": [
      "deep learning techniques",
      "deep learning systems",
      "deep representation learning",
      "DL",
      "deep learning technology",
      "deep learning based methods"
    ]
  },
  {
    "topic_id": 124,
    "size": 12,
    "keywords": [
      "psychology",
      "computational psychology",
      "psychology framework",
      "psychotherapy",
      "computational",
      "pharmacological",
      "orientation modeling",
      "modeling based",
      "antidepressant",
      "pharmacological intervention"
    ],
    "examples": [
      "computational cognition architectures",
      "antidepressant pharmacological intervention",
      "conceptual framework of stressors",
      "computational psychology integration",
      "cognitive modeling based on scalar expectancy theory",
      "social psychology framework",
      "computational psychology frameworks",
      "brief psychotherapy"
    ],
    "topic_fingerprint": "2ce02d64011b4d7130cd02e7125d831143a9bffd4b0bf1dc23faca0f867b33a4",
    "l2_name": "Computational and Clinical Psychology Methods",
    "definition": "This methodological axis encompasses computational modeling frameworks, cognitive architectures, and clinical interventions including psychotherapy and pharmacological treatments.",
    "aliases": [
      "computational psychology",
      "clinical psychology methods",
      "psychotherapeutic interventions",
      "pharmacological interventions",
      "cognitive modeling",
      "psychological orientation modeling",
      "computational cognition",
      "clinical frameworks"
    ]
  },
  {
    "topic_id": 125,
    "size": 12,
    "keywords": [
      "therapy",
      "virtual",
      "reality",
      "virtual reality",
      "transcutaneous",
      "immersive",
      "nerve",
      "therapy virtual",
      "stimulation",
      "nerve stimulation"
    ],
    "examples": [
      "virtual reality simulation environments",
      "pervasive music therapy system",
      "robot-assisted session observation",
      "robot-enhanced therapy validation",
      "supervised autonomous robotic control",
      "transcutaneous vagus nerve stimulation",
      "immersive virtual reality intervention",
      "humanoid robot hardware design"
    ],
    "topic_fingerprint": "a27d5608d51f122553801d1769a9b483830108e4f4d8273f548854ae641a7d7d",
    "l2_name": "Immersive Technology and Neuromodulation Therapy",
    "definition": "Therapeutic methods utilizing immersive virtual reality environments or transcutaneous nerve stimulation techniques to treat medical conditions.",
    "aliases": [
      "VR therapy",
      "virtual reality intervention",
      "transcutaneous nerve stimulation",
      "immersive therapy",
      "tVNS",
      "virtual exposure therapy",
      "robot-assisted therapy",
      "immersive simulation"
    ]
  },
  {
    "topic_id": 126,
    "size": 12,
    "keywords": [
      "binary",
      "local binary",
      "binary patterns",
      "patterns",
      "local",
      "patterns local",
      "pattern features",
      "features local",
      "binary pattern",
      "features"
    ],
    "examples": [
      "local binary patterns",
      "local binary patterns extraction",
      "local binary patterns",
      "local binary patterns on three orthogonal planes",
      "local binary pattern features",
      "local binary pattern features",
      "local binary pattern features",
      "local binary pattern features"
    ],
    "topic_fingerprint": "57ace650c759ef0d65c99a713268f2bed4265926cb8f984da0e7a57cb02724c5",
    "l2_name": "Local Binary Patterns",
    "definition": "A texture analysis method that encodes local image structures by comparing the intensity of a central pixel with its surrounding neighbors to generate a binary pattern.",
    "aliases": [
      "LBP",
      "local binary pattern",
      "local binary patterns extraction",
      "local binary pattern features",
      "binary patterns",
      "local binary patterns on three orthogonal planes",
      "LBP features"
    ]
  },
  {
    "topic_id": 127,
    "size": 12,
    "keywords": [
      "fuzzy",
      "fuzzy logic",
      "logic",
      "fuzzy control",
      "computing integration",
      "systems fuzzy",
      "control systems",
      "soft computing",
      "applications soft",
      "logic applications"
    ],
    "examples": [
      "fuzzy logic integration",
      "finite state machine application",
      "fuzzy weighted averaging operator",
      "intuitionistic fuzzy framework",
      "hesitant fuzzy set modeling",
      "psychological fuzzy measure",
      "fuzzy control systems",
      "fuzzy logic applications"
    ],
    "topic_fingerprint": "c3807e123cea699e90c1f310aeacbc0a899ccb47cc1087133b26a338da6abf78",
    "l2_name": "Fuzzy Logic",
    "definition": "A form of many-valued logic that handles reasoning with approximate rather than fixed and exact values to model uncertainty in control systems and soft computing applications.",
    "aliases": [
      "fuzzy logic",
      "fuzzy control",
      "soft computing",
      "fuzzy systems",
      "fuzzy computing",
      "approximate reasoning"
    ]
  },
  {
    "topic_id": 128,
    "size": 12,
    "keywords": [
      "resonance imaging",
      "resonance",
      "magnetic resonance",
      "magnetic",
      "imaging",
      "functional magnetic",
      "imaging functional",
      "structural magnetic",
      "structural",
      "imaging structural"
    ],
    "examples": [
      "functional magnetic resonance imaging",
      "structural magnetic resonance imaging",
      "structural magnetic resonance imaging",
      "functional magnetic resonance imaging",
      "structural magnetic resonance imaging",
      "structural magnetic resonance imaging",
      "functional magnetic resonance imaging",
      "functional magnetic resonance imaging"
    ],
    "topic_fingerprint": "0b69facc441221785dfc0fed743097c0f9413e375daf3a9d2e0984beb6ad284d",
    "l2_name": "Magnetic Resonance Imaging",
    "definition": "A non-invasive medical imaging technique that uses strong magnetic fields and radio waves to generate detailed images of the body's internal structures or functional activity.",
    "aliases": [
      "MRI",
      "functional magnetic resonance imaging",
      "fMRI",
      "structural magnetic resonance imaging",
      "sMRI",
      "magnetic resonance",
      "resonance imaging"
    ]
  },
  {
    "topic_id": 129,
    "size": 12,
    "keywords": [
      "capsule",
      "capsule network",
      "cascade",
      "cascade perspective",
      "perspective network",
      "architecture capsule",
      "network architecture",
      "perspective",
      "network",
      "network feature"
    ],
    "examples": [
      "cascade classification framework",
      "cascade neural network",
      "bi-channel capsule network",
      "capsule network architecture",
      "capsule network architecture",
      "capsule network feature extraction",
      "capsule network feature extraction",
      "transformer capsule network"
    ],
    "topic_fingerprint": "2078fd26937e571099710c3011e7d615ebe94d0047bf7fc3d878cae06783e7d4",
    "l2_name": "Capsule Network",
    "definition": "A neural network architecture that uses capsules to preserve spatial hierarchies and pose information through dynamic routing mechanisms.",
    "aliases": [
      "CapsNet",
      "capsule network architecture",
      "bi-channel capsule network",
      "transformer capsule network",
      "binary capsule networks",
      "cascade perspective network",
      "network feature extraction"
    ]
  },
  {
    "topic_id": 130,
    "size": 12,
    "keywords": [
      "generative adversarial",
      "generative",
      "adversarial",
      "adversarial networks",
      "networks generative",
      "network framework",
      "adversarial network",
      "adversarial attack",
      "gans",
      "gans generative"
    ],
    "examples": [
      "sequence generative adversarial networks",
      "generative adversarial networks",
      "generative adversarial networks",
      "improved wasserstein gans",
      "generative adversarial networks",
      "generative adversarial network framework",
      "stargan framework",
      "generative adversarial network framework"
    ],
    "topic_fingerprint": "784a5f9ab98caa715c6631d5112c344d05914532c8a59392ef687dcbeb339ad7",
    "l2_name": "Generative Adversarial Networks",
    "definition": "A deep learning framework that trains two neural networks, a generator and a discriminator, in an adversarial process to generate synthetic data indistinguishable from real data.",
    "aliases": [
      "GANs",
      "Generative Adversarial Network",
      "Adversarial Networks",
      "Generative Adversarial Framework",
      "Wasserstein GANs",
      "StarGAN",
      "Sequence GANs"
    ]
  },
  {
    "topic_id": 131,
    "size": 11,
    "keywords": [
      "induction",
      "emotion induction",
      "emotional",
      "laboratory",
      "induction emotional",
      "sampling emotional",
      "laboratory emotion",
      "elicitation procedure",
      "emotion elicitation",
      "emotional state"
    ],
    "examples": [
      "laboratory emotion elicitation procedure",
      "laboratory emotion elicitation procedure",
      "self-report emotion labeling",
      "post-learning emotion induction",
      "post-encoding emotion induction",
      "emotional state induction",
      "emotional sequence sampling",
      "emotional state sampling"
    ],
    "topic_fingerprint": "7a55a994fe8c4f73cc6f2b7cff0faf07505d1918b2ffc2e084cb76bda552cdbe",
    "l2_name": "Emotion Induction",
    "definition": "The systematic application of laboratory procedures or stimuli to elicit specific emotional states in participants for research purposes.",
    "aliases": [
      "emotion elicitation",
      "emotional state induction",
      "laboratory emotion induction",
      "emotion elicitation procedure",
      "emotional sampling",
      "induction of emotion"
    ]
  },
  {
    "topic_id": 132,
    "size": 11,
    "keywords": [
      "smoothing",
      "temporal smoothing",
      "composite temporal",
      "regularization",
      "composite",
      "label smoothing",
      "smoothing regularization",
      "smoothing composite",
      "regularization laplace",
      "laplace"
    ],
    "examples": [
      "spatial smoothness regularization",
      "laplace smoothing so-pmi",
      "label smoothing regularization",
      "label smoothing regularization",
      "regularized empirical mode decomposition",
      "sample reconstruction regularization",
      "multi-scale spatial regularization",
      "post-smoothing strategy"
    ],
    "topic_fingerprint": "6d8bc4ba1553b1b7c9cb8dfe22ae214970c5a7696cab917f7973423286137f38",
    "l2_name": "Smoothing Regularization",
    "definition": "A method that applies smoothing constraints, such as temporal or spatial continuity and label distribution softening, to regularize models and reduce noise or overfitting.",
    "aliases": [
      "smoothing",
      "temporal smoothing",
      "composite temporal smoothing",
      "label smoothing",
      "smoothing regularization",
      "regularization laplace",
      "laplace smoothing",
      "spatial smoothness regularization",
      "post-smoothing strategy",
      "multi-scale spatial regularization"
    ]
  },
  {
    "topic_id": 133,
    "size": 11,
    "keywords": [
      "disentanglement",
      "information bottleneck",
      "disentanglement network",
      "feature disentanglement",
      "representation disentanglement",
      "disentanglement information",
      "disentanglement feature",
      "bottleneck",
      "information",
      "bottleneck disentanglement"
    ],
    "examples": [
      "motion disentanglement technique",
      "deformation texture disentanglement",
      "feature disentanglement network",
      "feature disentanglement network",
      "dynamic causal disentanglement",
      "sentiment-aware representation disentanglement",
      "representation disentanglement",
      "information bottleneck disentanglement"
    ],
    "topic_fingerprint": "2d7559f4634d01b456a056d82485c656993af7d6d6ddbb4e04eeb28335eb2b7a",
    "l2_name": "Disentanglement",
    "definition": "A method for learning latent representations that separate distinct underlying factors of variation in data, often utilizing information bottleneck principles to enforce independence.",
    "aliases": [
      "representation disentanglement",
      "feature disentanglement",
      "disentanglement network",
      "information bottleneck disentanglement",
      "disentangled representation learning",
      "factor disentanglement"
    ]
  },
  {
    "topic_id": 134,
    "size": 11,
    "keywords": [
      "language processing",
      "natural language",
      "natural",
      "processing techniques",
      "techniques artificial",
      "intelligence techniques",
      "artificial intelligence",
      "intelligence",
      "artificial",
      "techniques natural"
    ],
    "examples": [
      "priming technique utilization",
      "local processing techniques",
      "natural language processing techniques",
      "artificial intelligence techniques",
      "artificial intelligence techniques",
      "robust technique development",
      "artificial intelligence techniques",
      "natural language processing techniques"
    ],
    "topic_fingerprint": "bf3297ff7cb7b2c266a22e9b8a06d610912f2373719d97f5f1fea24c9d4c0883",
    "l2_name": "Natural Language Processing Techniques",
    "definition": "Methods and algorithms used to enable computers to understand, interpret, and generate human language within the field of artificial intelligence.",
    "aliases": [
      "NLP techniques",
      "natural language processing methods",
      "language processing techniques",
      "AI language techniques",
      "natural language methods",
      "computational linguistics techniques"
    ]
  },
  {
    "topic_id": 135,
    "size": 11,
    "keywords": [
      "descriptors",
      "spatiotemporal descriptors",
      "descriptors spatiotemporal",
      "spatiotemporal",
      "local spatiotemporal",
      "descriptor",
      "spatiotemporal operators",
      "spatiotemporal descriptor",
      "operators hoof",
      "operators"
    ],
    "examples": [
      "cuboids spatio-temporal descriptor",
      "local spatiotemporal feature descriptors",
      "local spatiotemporal operators",
      "hoof descriptor analysis",
      "spatial contouring algorithms",
      "spatiotemporal descriptors",
      "spatiotemporal descriptors",
      "spatiotemporal descriptors"
    ],
    "topic_fingerprint": "9a14d11b07ad49d4d90d8fa677e5b412b3f212fb51ddc9188cdf4749da8300ba",
    "l2_name": "Spatiotemporal Descriptors",
    "definition": "Methods that extract and encode local features from video data by jointly analyzing spatial appearance and temporal motion information within spatiotemporal volumes.",
    "aliases": [
      "spatiotemporal descriptor",
      "local spatiotemporal descriptors",
      "spatiotemporal operators",
      "local spatiotemporal operators",
      "cuboids spatio-temporal descriptor",
      "spatiotemporal feature descriptors",
      "descriptors spatiotemporal"
    ]
  },
  {
    "topic_id": 136,
    "size": 11,
    "keywords": [
      "sparsityaware",
      "sparsityaware deep",
      "network sparsityaware",
      "deep network",
      "sparsity",
      "sparsity intramodal",
      "learning sparsityaware",
      "intermodal sparsity",
      "intramodal",
      "intermodal"
    ],
    "examples": [
      "sparsity-aware deep learning",
      "sparsity-aware deep learning",
      "sparsity-aware deep network",
      "sparsity-aware deep network",
      "sparsity-aware deep network",
      "sparsity-aware deep network",
      "sparsity-aware deep network",
      "sparsity-aware deep network"
    ],
    "topic_fingerprint": "3797c412aed6fe31c890707d2194e1a6c3b2f9c799c7af06c7712aeff52c2896",
    "l2_name": "Sparsity-Aware Deep Learning",
    "definition": "A methodological approach in deep learning that explicitly incorporates, exploits, or enforces sparsity constraints within network architectures or across data modalities to improve efficiency and performance.",
    "aliases": [
      "sparsity-aware deep network",
      "sparsity-aware learning",
      "deep network sparsity",
      "intermodal sparsity",
      "intramodal sparsity",
      "sparsity-aware modeling"
    ]
  },
  {
    "topic_id": 137,
    "size": 11,
    "keywords": [
      "dynamic texture",
      "texture",
      "texture histograms",
      "histograms dynamic",
      "histograms",
      "dynamic",
      "texture analysis",
      "analysis dynamic",
      "dynamic edge",
      "edge texture"
    ],
    "examples": [
      "dynamic texture histograms",
      "dynamic texture analysis",
      "dynamic texture analysis",
      "dynamic texture histograms",
      "dynamic edge and texture integration",
      "dynamic texture histograms",
      "dynamic texture histograms",
      "dynamic texture histograms"
    ],
    "topic_fingerprint": "5ecbe412f584ded711eecfaa40eac326d10b7bf8fea8a0c61675729805b6dd44",
    "l2_name": "Dynamic Texture Analysis",
    "definition": "A method for analyzing and characterizing textures in image sequences that exhibit temporal motion or variation using statistical descriptors such as histograms.",
    "aliases": [
      "dynamic texture histograms",
      "dynamic edge and texture integration",
      "dynamic image analysis",
      "texture analysis dynamic",
      "histograms dynamic texture"
    ]
  },
  {
    "topic_id": 138,
    "size": 10,
    "keywords": [
      "integration emotional",
      "psychology knowledge",
      "emotion psychology",
      "psychology",
      "knowledge integration",
      "emotional",
      "integration emotion",
      "integration",
      "knowledge",
      "emotion"
    ],
    "examples": [
      "emotion factor integration",
      "emotional vocabulary integration",
      "emotional dictionary expansion",
      "emotional state integration",
      "psychological emotion model integration",
      "emotional psychology theory integration",
      "emotional synergy",
      "emotion psychology knowledge integration"
    ],
    "topic_fingerprint": "997803122ac35c8d141c9e7ed955cdd0aabb1f1a2673879d3fa9d9433280ed71",
    "l2_name": "Emotion Psychology Knowledge Integration",
    "definition": "The methodological process of synthesizing emotional factors, vocabulary, states, and theoretical models into a unified psychological knowledge framework.",
    "aliases": [
      "emotion factor integration",
      "emotional vocabulary integration",
      "emotional dictionary expansion",
      "emotional state integration",
      "psychological emotion model integration",
      "emotional psychology theory integration",
      "emotional synergy",
      "emotion psychology knowledge integration",
      "integration of emotional psychology",
      "knowledge integration in emotion psychology"
    ]
  },
  {
    "topic_id": 139,
    "size": 10,
    "keywords": [
      "label distribution",
      "label",
      "distribution learning",
      "learning label",
      "distribution",
      "progressive",
      "label revision",
      "progressive confidence",
      "progressive circular",
      "outofdistribution data"
    ],
    "examples": [
      "label distribution learning",
      "label distribution learning",
      "label distribution learning",
      "progressive circular loss",
      "label distribution learning",
      "label distribution adaptation",
      "progressive label revision",
      "label distribution learning"
    ],
    "topic_fingerprint": "6798bf6e347ea5f8245f006144dc54e17f7706f82e23495f73bc0c8a25e03319",
    "l2_name": "Label Distribution Learning",
    "definition": "A machine learning paradigm that models the probability distribution of labels for each instance rather than predicting a single discrete class label.",
    "aliases": [
      "LDL",
      "label distribution adaptation",
      "progressive label revision",
      "distribution learning",
      "learning label distribution"
    ]
  }
]

[
  {
    "topic_id": 0,
    "size": 73,
    "keywords": [
      "dependency modeling",
      "dependency",
      "temporal",
      "modeling",
      "context",
      "modeling temporal",
      "longterm",
      "modeling longterm",
      "dynamic",
      "interval localization"
    ],
    "examples": [
      "dynamic sequence analysis",
      "dynamic sequence analysis",
      "spatiotemporal pattern analysis",
      "dynamic expression analysis",
      "temporal alignment of expressions",
      "sequential pattern recognition",
      "utterance independent modeling",
      "temporal alignment of expressions",
      "spatial-temporal dependency modeling",
      "temporal dynamics modeling",
      "modality dependency modeling",
      "temporal information modeling",
      "spatial dependency modeling",
      "cross-modality dependency modeling",
      "interlocutor influence reduction",
      "interlocutor influence reduction",
      "temporal order encoding",
      "temporal stability in video",
      "subtle spatiotemporal change modeling",
      "context-sensitive dependence modeling"
    ]
  },
  {
    "topic_id": 1,
    "size": 69,
    "keywords": [
      "conversion",
      "emotional speech",
      "speech",
      "speakerindependent",
      "expressive",
      "prosody",
      "speakerindependent speech",
      "emotional voice",
      "voice conversion",
      "voice"
    ],
    "examples": [
      "emotional speech classification",
      "emotional prosody generation",
      "speaker-independent speech emotion recognition",
      "prosodic feature modeling",
      "speaker-independent speech emotion recognition",
      "text versus speech emotion discrepancy",
      "speaker-independent emotion classification",
      "exclamatory speech prosody modeling",
      "speech synthesis expressiveness improvement",
      "discrete speech emotion recognition",
      "emotional prosody modeling",
      "expressive speech generation",
      "emotional speech synthesis",
      "expressive prosody generation",
      "neutral to emotional conversion",
      "emotional speech synthesis evaluation",
      "neutral to emotional speech conversion",
      "prosody distribution mapping",
      "expressive talking face generation",
      "speech-driven emotion classification"
    ]
  },
  {
    "topic_id": 2,
    "size": 68,
    "keywords": [
      "multimodal sentiment",
      "analysis multimodal",
      "sentiment analysis",
      "sentiment",
      "multimodal",
      "analysis",
      "incomplete multimodal",
      "incomplete",
      "robust multimodal",
      "prediction multimodal"
    ],
    "examples": [
      "multiword expression analysis",
      "multidimensional sentiment classification",
      "multimodal sentiment prediction",
      "multimodal sentiment analysis",
      "multimodal sentiment prediction",
      "multimodal news sentiment recognition",
      "multi-modal sentiment analysis",
      "multi-modal sentiment analysis",
      "multi-modal sentiment analysis",
      "multimodal sentiment analysis",
      "multimodal sentiment classification",
      "multimodal sentiment analysis",
      "emotion recognition with missing modalities",
      "multimodal sentiment analysis",
      "multimodal sentiment analysis",
      "multimodal sentiment analysis",
      "multimodal sentiment analysis challenge",
      "multimodal sentiment analysis",
      "multimodal sentiment analysis",
      "multimodal sentiment analysis"
    ]
  },
  {
    "topic_id": 3,
    "size": 62,
    "keywords": [
      "task emotion",
      "classification task",
      "reasoning",
      "emotion classification",
      "emotion reasoning",
      "explanation",
      "accuracy",
      "benchmarking",
      "causal",
      "reasoning emotion"
    ],
    "examples": [
      "emotion classification task",
      "emotion classification task",
      "emotion classification task",
      "emotion data representation standards",
      "causal link identification",
      "emotion regression",
      "emotion feature evaluation",
      "image emotion perception task",
      "emotion causation discovery",
      "mean emotion extraction",
      "emotion classification task",
      "emotion classification challenge",
      "emotion classification benchmarking",
      "emotion classification benchmarking",
      "trait anger antecedents",
      "emotion detection benchmarking",
      "emotion-related perceptual thresholds",
      "role of anticipated emotions",
      "feeling versus reason preference",
      "benchmark creation for emotions"
    ]
  },
  {
    "topic_id": 4,
    "size": 60,
    "keywords": [
      "feature",
      "feature extraction",
      "discriminative",
      "extraction",
      "feature selection",
      "selection",
      "acoustic",
      "acoustic feature",
      "emotional feature",
      "feature representation"
    ],
    "examples": [
      "acoustic feature realization",
      "feature representation generation",
      "feature importance analysis",
      "robust emotion feature selection",
      "acoustic feature representation generation",
      "acoustic feature selection",
      "feature selection challenge",
      "high-dimensional feature reduction",
      "high-dimensional feature reduction",
      "feature extraction for emotions",
      "curse of dimensionality mitigation",
      "discriminative feature selection",
      "discriminative information extraction",
      "discriminative information extraction",
      "salient region selection",
      "discriminative information extraction",
      "global region feature extraction",
      "block-level feature contribution analysis",
      "feature selection problem",
      "emotional feature selection"
    ]
  },
  {
    "topic_id": 5,
    "size": 59,
    "keywords": [
      "sentiment",
      "sentiment classification",
      "text sentiment",
      "sentiment analysis",
      "text",
      "task sentiment",
      "classification",
      "discrete sentiment",
      "sentence",
      "short text"
    ],
    "examples": [
      "semantic polarity detection",
      "sentiment inversion handling",
      "metaphor polarity detection",
      "sentiment orientation analysis",
      "social sentiment detection",
      "topic sentiment analysis",
      "sentence sentiment classification",
      "short text sentiment classification",
      "neutral versus un-neutral classification",
      "multiword expression sentiment extraction",
      "non-compositional semantic orientation detection",
      "sentence sentiment classification",
      "sentence polarity judgment",
      "short text sentiment classification",
      "sentiment classification task",
      "sentiment classification task",
      "sentiment analysis for disease detection",
      "sentiment tendency classification",
      "news text classification",
      "product review sentiment"
    ]
  },
  {
    "topic_id": 6,
    "size": 55,
    "keywords": [
      "recognition facial",
      "expression recognition",
      "facial expression",
      "expression",
      "facial",
      "recognition",
      "unsupervised facial",
      "recognition masked",
      "masked",
      "masked facial"
    ],
    "examples": [
      "facial expression recognition",
      "facial expression recognition speed",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "appraisal expression recognition",
      "near-infrared facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial micro-expression recognition",
      "fleeting expression recognition",
      "facial expression recognition ability"
    ]
  },
  {
    "topic_id": 7,
    "size": 54,
    "keywords": [
      "recognition speech",
      "speech emotion",
      "speech",
      "generalization speech",
      "recognition generalization",
      "emotion recognition",
      "generalization",
      "classification speech",
      "recognition",
      "emotion"
    ],
    "examples": [
      "speech emotion classification",
      "speech emotion recognition",
      "speech emotion annotation",
      "speech emotion classification",
      "speech emotion recognition",
      "speech emotion recognition generalization",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion feature reduction",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition",
      "speech emotion recognition overfitting",
      "speech emotion recognition",
      "speech emotion recognition"
    ]
  },
  {
    "topic_id": 8,
    "size": 53,
    "keywords": [
      "subtle facial",
      "subtle",
      "facial movement",
      "movement",
      "occlusion",
      "analysis subtle",
      "motion",
      "movement analysis",
      "movement detection",
      "detection subtle"
    ],
    "examples": [
      "facial feature selection",
      "handling facial occlusion",
      "handling facial occlusion",
      "subtle facial expression analysis",
      "subtle facial movement analysis",
      "subtle facial movement analysis",
      "subtle facial motion analysis",
      "intersubject facial variation suppression",
      "subtle facial movement analysis",
      "subtle facial movement analysis",
      "subtle facial movement analysis",
      "pitch contour modeling",
      "subtle facial emotion detection",
      "subtle facial movement detection",
      "subtle facial movement detection",
      "missing shape attribute modeling",
      "subtle facial emotion recognition",
      "occlusion robustness",
      "subtle facial movement analysis",
      "low-intensity facial movement detection"
    ]
  },
  {
    "topic_id": 9,
    "size": 52,
    "keywords": [
      "task microexpression",
      "recognition task",
      "microexpression recognition",
      "task",
      "microexpression",
      "recognition",
      "challenge microexpression",
      "recognition challenge",
      "microexpression classification",
      "challenge"
    ],
    "examples": [
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "microexpression recognition tasks",
      "micro-expression recognition task",
      "micro-expression recognition task",
      "micro-expression recognition task"
    ]
  },
  {
    "topic_id": 10,
    "size": 50,
    "keywords": [
      "subjective",
      "subjective emotion",
      "modeling subjective",
      "subjectivity",
      "subjective image",
      "perception subjectivity",
      "subjectivity handling",
      "classification subjective",
      "emotion variability",
      "emotion modeling"
    ],
    "examples": [
      "holistic perception hypothesis validation",
      "subjective emotion modeling",
      "subjective emotion variability",
      "term subjectivity classification",
      "subjective image emotion modeling",
      "subjective image emotion modeling",
      "subjective evaluation modeling",
      "subjective emotion variability modeling",
      "subjective emotion variability modeling",
      "subjective emotion variability modeling",
      "subjective emotion classification",
      "subjective emotion classification",
      "subjective emotion classification",
      "subjective emotion evaluation",
      "subjective emotion evaluation",
      "subjective image emotion recognition",
      "subjective image emotion recognition",
      "subjective emotion variation modeling",
      "subjective emotion variation modeling",
      "subjective image emotion modeling"
    ]
  },
  {
    "topic_id": 11,
    "size": 49,
    "keywords": [
      "facial emotion",
      "face",
      "facial affect",
      "analysis facial",
      "facial",
      "facial identity",
      "face recognition",
      "processing",
      "facebased emotion",
      "action analysis"
    ],
    "examples": [
      "face memory recognition",
      "peripheral emotional face recognition",
      "facial emotion classification",
      "facial emotion classification",
      "facial emotion classification",
      "fearful face recognition accuracy",
      "facial identity processing",
      "facial action part localization",
      "facial attention allocation",
      "changeable facial information processing",
      "face network functional integration",
      "face recognition ability",
      "facial identity recognition",
      "facial identity recognition interference",
      "affective disorder facial processing",
      "individual face representation",
      "facial action analysis",
      "facial emotion processing differences",
      "facial affect behavior analysis",
      "fearful face time perception"
    ]
  },
  {
    "topic_id": 12,
    "size": 49,
    "keywords": [
      "action unit",
      "unit",
      "action",
      "unit detection",
      "facial action",
      "detection facial",
      "microexpression action",
      "unit recognition",
      "detection",
      "detection action"
    ],
    "examples": [
      "3d facial action unit detection",
      "facial action unit detection",
      "facial action unit recognition",
      "facial action unit detection",
      "cross-pose action unit detection",
      "cross-pose action unit detection",
      "facial action unit recognition",
      "facial action unit recognition",
      "facial action unit detection",
      "facial action unit intensity estimation",
      "micro-expression action unit detection",
      "facial action unit detection",
      "facial action unit detection",
      "semi-supervised facial action unit recognition",
      "facial action unit recognition",
      "facial action unit detection",
      "micro-expression action unit detection",
      "facial action unit detection",
      "facial action unit detection",
      "facial action unit intensity estimation"
    ]
  },
  {
    "topic_id": 13,
    "size": 46,
    "keywords": [
      "video",
      "videobased",
      "affective video",
      "video emotion",
      "videos",
      "videobased emotion",
      "video based",
      "recognition video",
      "viewer emotion",
      "video classification"
    ],
    "examples": [
      "affective filtering for videos",
      "video-based emotion analysis",
      "video-based emotion analysis",
      "affective video recommendation",
      "emotion-based video classification",
      "affective video recommendation",
      "emotion-based video classification",
      "affective video classification task",
      "viewer emotion analysis",
      "affective video classification task",
      "viewer emotion analysis",
      "affective video segmentation",
      "video affective indexing",
      "viewer emotion analysis",
      "affective video segmentation",
      "video affective indexing",
      "viewer emotion recommendation",
      "video based emotion recognition",
      "flexible video presentation",
      "flexible video presentation"
    ]
  },
  {
    "topic_id": 14,
    "size": 44,
    "keywords": [
      "affective",
      "affective learning",
      "modeling affective",
      "affective impact",
      "analysis affective",
      "impact affective",
      "affective dynamics",
      "effects affective",
      "identification affective",
      "affective content"
    ],
    "examples": [
      "affective learning outcomes",
      "positive affect impact",
      "affective state effects",
      "affective stroop interference",
      "affective-cognitive interdependence analysis",
      "affective response to problem solving",
      "affective content analysis",
      "affective content analysis",
      "affective priming inconsistency",
      "affective learning processes",
      "affective problem identification",
      "affective impact analysis",
      "own-race versus other-race affective learning",
      "affect analysis in groups",
      "inversed affective learning mechanism",
      "affective phrase identification",
      "affective lexicon expansion",
      "affective analysis of groups",
      "affective decision behavior",
      "affective text analysis"
    ]
  },
  {
    "topic_id": 15,
    "size": 43,
    "keywords": [
      "crossdomain",
      "crossdomain emotion",
      "recognition crossdomain",
      "crossdomain speech",
      "analysis crossdomain",
      "crossspeaker",
      "crossdomain sentiment",
      "emotion analysis",
      "speech emotion",
      "interdisciplinary"
    ],
    "examples": [
      "cross-domain emotion classification",
      "cross-domain emotion adaptation",
      "cross-domain sentiment detection",
      "domain-specific emotion detection",
      "cross-domain emotion analysis",
      "cross-domain emotion analysis",
      "cross-domain emotion recognition",
      "cross-domain emotional feature learning",
      "cross-domain sentiment alignment",
      "interdisciplinary emotion analysis",
      "cross-domain emotion classification",
      "cross-speaker emotion recognition",
      "cross-speaker emotion recognition",
      "cross-domain emotion analysis",
      "cross-domain emotion analysis",
      "cross-domain emotion recognition",
      "cross-domain emotion analysis challenges",
      "cross-domain sentiment classification",
      "cross-domain emotion analysis",
      "multi-domain sentiment classification"
    ]
  },
  {
    "topic_id": 16,
    "size": 41,
    "keywords": [
      "mental health",
      "mental",
      "health",
      "assessment",
      "assessment mental",
      "support",
      "personalized mental",
      "health support",
      "health assessment",
      "emergency"
    ],
    "examples": [
      "psychological resilience assessment",
      "existential anxiety assessment",
      "caregiver burden assessment",
      "patient emotional distress",
      "flow experience assessment",
      "dynamic psychological assessment",
      "pandemic impact assessment",
      "risk assessment for mental patients",
      "emergency induced mental health risks",
      "personalized mental health intervention",
      "adverse event incidence",
      "longitudinal mental health monitoring",
      "emergency psychological support gaps",
      "psychiatric patient support evaluation",
      "elderly loneliness assessment",
      "sleep quality mental health association",
      "adolescent mental health analysis",
      "childhood maltreatment impact",
      "flow state assessment",
      "orphan mental health support"
    ]
  },
  {
    "topic_id": 17,
    "size": 40,
    "keywords": [
      "recognition multimodal",
      "multimodal emotion",
      "multimodal",
      "emotion recognition",
      "recognition",
      "emotion reasoning",
      "emotion",
      "reasoning",
      "multimodal continuous",
      "reasoning multimodal"
    ],
    "examples": [
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition task",
      "multimodal continuous emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition"
    ]
  },
  {
    "topic_id": 18,
    "size": 40,
    "keywords": [
      "recognition multimodal",
      "multimodal emotion",
      "multimodal",
      "estimation multimodal",
      "emotion recognition",
      "multimodal stress",
      "stress estimation",
      "task multimodal",
      "recognition",
      "emotion"
    ],
    "examples": [
      "multimodal emotion expression",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion estimation",
      "multimodal emotion recognition task",
      "multimodal emotion inference",
      "multimodal emotion recognition",
      "continuous multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal stress estimation",
      "multimodal stress estimation",
      "multi-modal emotion recognition",
      "multimodal emotion recognition task",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal emotion recognition",
      "multimodal multi-label emotion recognition",
      "multimodal emotion recognition"
    ]
  },
  {
    "topic_id": 19,
    "size": 40,
    "keywords": [
      "labeled",
      "limited",
      "labeled data",
      "data",
      "limited labeled",
      "training",
      "scarcity",
      "data scarcity",
      "data limited",
      "training data"
    ],
    "examples": [
      "utilization of unlabeled data",
      "labeled data scarcity issue",
      "labeled data scarcity issue",
      "limited annotated microblog data",
      "limited labeled data usage",
      "training testing data discrepancy",
      "limited training data",
      "supervised data scarcity",
      "lack of labeled data",
      "limited labeled data utilization",
      "limited labeled data scenario",
      "low-resource sample handling",
      "low-resource sample handling",
      "limited labeled data",
      "limited labeled data availability",
      "limited labeled data",
      "scarce labeled data",
      "limited annotated training data",
      "multimodal data scarcity",
      "supervised label underutilization"
    ]
  },
  {
    "topic_id": 20,
    "size": 38,
    "keywords": [
      "image emotion",
      "emotion classification",
      "image",
      "basic emotion",
      "basic",
      "classification",
      "social image",
      "classification social",
      "classification emotion",
      "emotion pattern"
    ],
    "examples": [
      "basic emotion classification",
      "emotion pattern classification",
      "image emotion recognition",
      "image emotion recognition",
      "image emotion regression",
      "image emotion regression",
      "image emotion regression",
      "automatic user emotion estimation",
      "human emotion recognition",
      "crowd emotion matching",
      "image emotion classification",
      "social image emotion classification",
      "social image emotion classification",
      "social image emotion classification",
      "image emotion classification",
      "basic emotion classification",
      "image-level sentiment prediction",
      "automatic emotion classification",
      "automatic emotion classification",
      "emotion expression recognition"
    ]
  },
  {
    "topic_id": 21,
    "size": 38,
    "keywords": [
      "mitigation domain",
      "domain",
      "shift mitigation",
      "mitigation",
      "reply",
      "shift",
      "generic",
      "generic reply",
      "domain shift",
      "reply generation"
    ],
    "examples": [
      "target-aspect pair extraction",
      "source-target corpus mismatch",
      "source-target domain mismatch",
      "distribution mismatch mitigation",
      "domain distribution mismatch",
      "generic reply reduction",
      "generic reply generation",
      "generic reply generation",
      "generic reply generation",
      "culture influence mitigation",
      "domain shift mitigation",
      "domain shift mitigation",
      "generic reply generation",
      "low reply diversity",
      "generic reply mitigation",
      "domain distribution discrepancy",
      "domain shift mitigation",
      "domain shift adaptation",
      "domain discrepancy mitigation",
      "domain discrepancy mitigation"
    ]
  },
  {
    "topic_id": 22,
    "size": 37,
    "keywords": [
      "interaction modeling",
      "modeling emotion",
      "dynamic emotion",
      "interaction",
      "disentanglement",
      "simulation",
      "modeling",
      "representation modeling",
      "emotional interaction",
      "dynamic"
    ],
    "examples": [
      "dynamic emotion analysis",
      "dynamic emotion analysis",
      "user-specified emotion synthesis",
      "cognition-emotion interaction modeling",
      "fine emotion modeling",
      "family emotional dynamic analysis",
      "elderly emotion interaction modeling",
      "virtual agent interaction",
      "semantic relation extraction",
      "human-robot emotional interaction",
      "dynamic emotion modeling",
      "human-computer emotional interaction",
      "dynamic emotion modeling",
      "dynamic emotion transfer simulation",
      "4d emotion analysis",
      "motion disentanglement",
      "complex emotion relationship modeling",
      "explicit emotion interaction modeling",
      "image emotion representation modeling",
      "image emotion representation modeling"
    ]
  },
  {
    "topic_id": 23,
    "size": 37,
    "keywords": [
      "crossdatabase",
      "recognition crossdatabase",
      "crossdatabase microexpression",
      "microexpression recognition",
      "recognition crossdomain",
      "crossdatabase expression",
      "crossdatabase facial",
      "crossdomain facial",
      "microexpression",
      "crossdomain"
    ],
    "examples": [
      "cross-pose facial expression recognition",
      "cross-domain expression recognition",
      "cross-database facial expression recognition",
      "cross-database micro-expression recognition",
      "cross-database micro-expression recognition",
      "cross-database micro-expression recognition",
      "cross-database micro-expression recognition",
      "unsupervised cross-database expression recognition",
      "cross-database performance validation",
      "cross-database expression recognition",
      "cross-database micro-expression recognition",
      "cross-database micro-expression recognition",
      "cross-domain microexpression recognition",
      "cross-domain microexpression recognition",
      "unsupervised cross-database recognition",
      "cross-database expression recognition",
      "cross-database micro-expression analysis",
      "cross-domain facial expression recognition",
      "cross-database micro-expression recognition",
      "cross-database micro-expression recognition"
    ]
  },
  {
    "topic_id": 24,
    "size": 36,
    "keywords": [
      "dynamic facial",
      "recognition dynamic",
      "dynamic",
      "expression recognition",
      "facial expression",
      "expression",
      "facial",
      "recognition automatic",
      "automatic facial",
      "extraction dynamic"
    ],
    "examples": [
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression analysis",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial pattern analysis",
      "dynamic facial expression recognition",
      "automatic facial expression recognition",
      "automatic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition",
      "dynamic facial change capture",
      "dynamic facial expression recognition",
      "facial dynamic representation extraction",
      "dynamic facial expression recognition",
      "dynamic facial expression recognition"
    ]
  },
  {
    "topic_id": 25,
    "size": 36,
    "keywords": [
      "recognition facial",
      "expression recognition",
      "facial expression",
      "expression",
      "facial",
      "facial microexpression",
      "recognition",
      "expression representation",
      "recognition hierarchical",
      "hierarchical facial"
    ],
    "examples": [
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial micro-expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "facial expression recognition",
      "hierarchical facial expression representation"
    ]
  },
  {
    "topic_id": 26,
    "size": 36,
    "keywords": [
      "recognition microexpression",
      "microexpression recognition",
      "microexpression",
      "recognition accuracy",
      "question answering",
      "visual question",
      "question",
      "microexpression visual",
      "recognition mechanisms",
      "answering"
    ],
    "examples": [
      "micro-expression recognition accuracy",
      "microexpression recognition limits",
      "micro-expression recognition",
      "microexpression recognition mechanisms",
      "macro-expression recognition",
      "micro-expression recognition",
      "micro-expression recognition",
      "macroexpression and microexpression recognition",
      "micro-expression recognition mechanisms",
      "micro-expression recognition ability",
      "micro-expression recognition",
      "micro-expression recognition accuracy",
      "micro-expression category prediction",
      "micro-expression recognition",
      "micro-expression recognition challenges",
      "microexpression recognition accuracy",
      "occluded micro-expression recognition",
      "micro-expression recognition",
      "micro-expression recognition",
      "micro-expression recognition"
    ]
  },
  {
    "topic_id": 27,
    "size": 34,
    "keywords": [
      "genuine emotion",
      "genuine",
      "detection genuine",
      "grouplevel emotion",
      "grouplevel",
      "recognition genuine",
      "emotion detection",
      "emotion concealment",
      "concealment",
      "concealment detection"
    ],
    "examples": [
      "genuine emotion recognition",
      "genuine emotion recognition",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "genuine emotion detection",
      "group-level emotion recognition",
      "group-level emotion recognition",
      "genuine emotion concealment detection",
      "group-level emotion recognition",
      "group-level emotion recognition",
      "concealed emotion recognition",
      "concealed emotion recognition",
      "genuine emotion detection",
      "genuine emotion identification"
    ]
  },
  {
    "topic_id": 28,
    "size": 34,
    "keywords": [
      "crosscorpus",
      "recognition crosscorpus",
      "crosscorpus speech",
      "speech emotion",
      "speech",
      "crosscorpus emotion",
      "ser",
      "emotional corpus",
      "crosscorpus ser",
      "sourcefree crosscorpus"
    ],
    "examples": [
      "automatic emotional corpus construction",
      "cross-corpus emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus facial expression recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition",
      "cross-corpus speech emotion recognition"
    ]
  },
  {
    "topic_id": 29,
    "size": 33,
    "keywords": [
      "influence modeling",
      "personality influence",
      "evaluation",
      "aesthetic",
      "perception evaluation",
      "modeling personality",
      "influence",
      "personality",
      "evaluation multimodal",
      "perception"
    ],
    "examples": [
      "aesthetic quality assessment",
      "user perception evaluation",
      "theoretical model evaluation",
      "urban color perception evaluation",
      "inter-rater agreement evaluation",
      "personal characteristic modeling",
      "multifactorial emotion perception modeling",
      "contrast effects in evaluation",
      "image quality evaluation",
      "personalized aesthetic assessment",
      "user preference modeling",
      "personality influence modeling",
      "personality influence modeling",
      "unconscious aesthetic processing",
      "personality influence modeling",
      "personality influence modeling",
      "modeling decision maker psychology",
      "personalized quality assessment task",
      "subjective aesthetic preference modeling",
      "modeling individual aesthetic preferences"
    ]
  },
  {
    "topic_id": 30,
    "size": 33,
    "keywords": [
      "individual",
      "individual difference",
      "difference",
      "modeling individual",
      "variation",
      "deployment",
      "application",
      "practical",
      "mitigation individual",
      "practical application"
    ],
    "examples": [
      "generalized stigma formation",
      "expression appearance variation modeling",
      "intelligent interaction design",
      "viewpoint variation effects",
      "individual difference mitigation",
      "atypical individual analysis",
      "individual intensity variation",
      "modeling individual differences",
      "resource-constrained robot deployment",
      "real-world application challenges",
      "individual difference overfitting",
      "resource-constrained device deployment",
      "individual variation generalization",
      "individual variation generalization",
      "practical application demands",
      "practical application deployment",
      "practical application deployment",
      "individual difference mitigation",
      "individual difference mitigation",
      "individual difference modeling"
    ]
  },
  {
    "topic_id": 31,
    "size": 32,
    "keywords": [
      "recognition spontaneous",
      "spontaneous microexpression",
      "spontaneous",
      "microexpression recognition",
      "spontaneous facial",
      "facial microexpression",
      "microexpression",
      "detection spontaneous",
      "microexpression analysis",
      "microexpression detection"
    ],
    "examples": [
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression detection",
      "spontaneous micro-expression detection",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression dataset creation",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous facial micro-expression analysis",
      "spontaneous facial micro-expression analysis",
      "spontaneous facial micro-expression recognition",
      "spontaneous facial micro-expression recognition",
      "spontaneous facial micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition",
      "spontaneous micro-expression recognition"
    ]
  },
  {
    "topic_id": 32,
    "size": 32,
    "keywords": [
      "continuous emotion",
      "continuous",
      "recognition continuous",
      "estimation continuous",
      "emotion dimension",
      "joint",
      "dimension",
      "intent",
      "emotion intent",
      "recognition child"
    ],
    "examples": [
      "continuous emotion dimension modeling",
      "kansei engineering application",
      "continuous emotion state modeling",
      "continuous dimensional affect estimation",
      "continuous emotion dimension estimation",
      "continuous emotion dimension estimation",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion estimation",
      "continuous emotion recognition task",
      "continuous emotion recognition task",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion representation",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion recognition",
      "continuous emotion recognition"
    ]
  },
  {
    "topic_id": 33,
    "size": 32,
    "keywords": [
      "crosscultural",
      "crosscultural emotion",
      "recognition crosscultural",
      "analysis crosscultural",
      "perception crosscultural",
      "crossculture",
      "crosscultural sentiment",
      "crosscultural continuous",
      "crosslanguage",
      "emotion perception"
    ],
    "examples": [
      "cross-cultural emotion measurement",
      "psychometric scale validation",
      "cross-sentence sentiment analysis",
      "cross-cultural emotion perception",
      "cross-cultural emotion perception",
      "cross-cultural emotion perception",
      "cross-culture validity assessment",
      "cross-cultural continuous emotion recognition",
      "cross-cultural continuous emotion recognition",
      "cross-cultural emotion recognition",
      "culture independent emotion elicitation",
      "cross-cultural affective engagement analysis",
      "cross-culture emotion recognition",
      "cross-cultural emotional stimulus validation",
      "cross-cultural emotion recognition",
      "cross-cultural emotion preference modeling",
      "cross-language emotion recognition",
      "cross-cultural audience attitude analysis",
      "cross-language sentiment analysis",
      "cultural impact on emotion"
    ]
  },
  {
    "topic_id": 34,
    "size": 32,
    "keywords": [
      "finegrained",
      "finegrained emotion",
      "classification finegrained",
      "finegrained emotional",
      "finegrained facial",
      "recognition finegrained",
      "finegrained sentiment",
      "analysis finegrained",
      "detection finegrained",
      "control finegrained"
    ],
    "examples": [
      "fine-grained sentiment annotation",
      "fine-grained emotion detection",
      "fine-grained emotion detection",
      "fine-grained emotion analysis",
      "fine-grained emotion element extraction",
      "fine-grained sentiment polarity detection",
      "fine-grained sentiment polarity",
      "fine-grained sentiment analysis",
      "fine-grained word classification",
      "fine-grained emotional tagging",
      "fine-grained facial feature capture",
      "fine-grained emotion classification",
      "fine-grained emotion classification",
      "fine-grained emotion classification",
      "fine-grained emotion classification",
      "fine-grained emotion controllability",
      "fine-grained facial expression control",
      "fine-grained emotional distinction",
      "fine-grained facial expression analysis",
      "fine-grained emotional speech control"
    ]
  },
  {
    "topic_id": 35,
    "size": 32,
    "keywords": [
      "multimodal affective",
      "multimodal affect",
      "affect",
      "affect recognition",
      "affective analysis",
      "affect analysis",
      "multimodal",
      "analysis multimodal",
      "multiperson",
      "multiperson affect"
    ],
    "examples": [
      "multimodal affective annotation",
      "multimodal affect analysis",
      "multi-person affect analysis",
      "multi-person affect analysis",
      "multi-modal affective analysis",
      "frame-level affect recognition",
      "multimodal affect analysis",
      "multimodal affect analysis",
      "multimodal affective signal detection",
      "multi-modal affective signal integration",
      "multimodal affective behavior analysis",
      "multi-modal affective analysis",
      "multi-modal affective analysis generalization",
      "multi-modal affective analysis generalization",
      "online meeting affect analysis",
      "joint laughter effect analysis",
      "unified affective metrics lack",
      "multimodal affect recognition",
      "multimodal affect recognition",
      "multimodal affective computing"
    ]
  },
  {
    "topic_id": 36,
    "size": 32,
    "keywords": [
      "intensity",
      "emotional reaction",
      "reaction",
      "emotional intensity",
      "prediction emotional",
      "state prediction",
      "emotional",
      "happiness",
      "control",
      "intensity estimation"
    ],
    "examples": [
      "emotional head motion prediction",
      "group emotional intensity analysis",
      "group happiness intensity estimation",
      "predictability effect on emotion",
      "emotional intensity measurement",
      "group-level happiness intensity estimation",
      "audience emotional reaction analysis",
      "emotional similarity prediction",
      "dimensional emotional state prediction",
      "dimensional emotional state prediction",
      "emotional intensity fluctuation handling",
      "audience emotional reaction assessment",
      "happiness superiority effect",
      "emotional reaction prediction",
      "emotional reaction prediction",
      "emotional reaction analysis",
      "emotion strength assessment",
      "discrete emotion state control",
      "emotional reaction intensity estimation",
      "emotional reaction intensity estimation"
    ]
  },
  {
    "topic_id": 37,
    "size": 31,
    "keywords": [
      "stress",
      "stress state",
      "emotional stress",
      "stress detection",
      "state recognition",
      "detection stress",
      "estimation stress",
      "emotionbased stress",
      "recognition emotional",
      "state"
    ],
    "examples": [
      "mandarin stress prediction",
      "teacher mental pressure analysis",
      "continuous speech stress detection",
      "stress corpus development",
      "emotional stress state recognition",
      "emotional stress state recognition",
      "emotional stress state recognition",
      "psychological stress detection",
      "emotion-based stress detection",
      "stress state estimation",
      "stress state estimation",
      "stress state estimation",
      "emotion-based stress detection",
      "mandarin stress modeling",
      "stress-induced inflammation modulation",
      "epidemic-induced psychosocial stress",
      "emotion-based stress detection",
      "stress indicator prediction",
      "emotional stress state recognition",
      "emotional stress state recognition"
    ]
  },
  {
    "topic_id": 38,
    "size": 30,
    "keywords": [
      "music",
      "music emotion",
      "affective music",
      "image musicalization",
      "emotionbased music",
      "classification music",
      "emotional design",
      "audio emotion",
      "music recommendation",
      "musicalization"
    ],
    "examples": [
      "audio emotion recognition",
      "image musicalization",
      "emotion-based music selection",
      "image musicalization task",
      "affective music classification",
      "web music emotion recognition",
      "dynamic texture description",
      "fuzzy music search",
      "music emotion classification",
      "music mood classification",
      "music emotion segmentation",
      "emotion categorization in music",
      "music emotional design analysis",
      "audio emotion modeling",
      "affective music annotation",
      "music emotion recognition",
      "context-aware music recommendation",
      "music scene classification",
      "musical imagery labeling",
      "large scale music retrieval"
    ]
  },
  {
    "topic_id": 39,
    "size": 30,
    "keywords": [
      "wild",
      "inthewild",
      "recognition wild",
      "recognition inthewild",
      "wild emotion",
      "inthewild affect",
      "wild environment",
      "inthewild facial",
      "environment",
      "analysis inthewild"
    ],
    "examples": [
      "emotion recognition in wild",
      "emotion recognition in the wild",
      "expression recognition in wild",
      "emotion recognition in wild",
      "emotion recognition in the wild",
      "emotion recognition in wild",
      "in-the-wild facial behavior analysis",
      "wild environment classification",
      "in-the-wild affect recognition",
      "in-the-wild affect prediction",
      "emotion recognition in the wild",
      "emotion recognition in the wild",
      "engagement in the wild challenge",
      "wild scenario robustness",
      "wild condition analysis",
      "wild condition emotion analysis",
      "wild environment robustness",
      "emotion recognition in the wild",
      "in-the-wild video emotion recognition",
      "in-the-wild video expression recognition"
    ]
  },
  {
    "topic_id": 40,
    "size": 30,
    "keywords": [
      "expression analysis",
      "analysis facial",
      "facial expression",
      "expression",
      "involuntary facial",
      "involuntary",
      "analysis involuntary",
      "facial",
      "effect facial",
      "expression confusion"
    ],
    "examples": [
      "angry expression effect",
      "facial expression analysis",
      "involuntary facial expression analysis",
      "involuntary facial expression analysis",
      "involuntary facial expression analysis",
      "gaze and expression interaction",
      "facial expression decoding",
      "facial expression processing",
      "facial expression analysis",
      "facial expression self-awareness",
      "facial expression analysis",
      "facial expression analysis",
      "facial pain expression analysis",
      "facial expression confusion",
      "neonatal pain expression recognition",
      "facial expression confusion effect",
      "facial expression analysis",
      "facial expression analysis",
      "ambiguous facial expression analysis",
      "facial expression decoding"
    ]
  },
  {
    "topic_id": 41,
    "size": 29,
    "keywords": [
      "severity",
      "depression severity",
      "depression",
      "severity estimation",
      "assessment depression",
      "estimation depression",
      "prediction depression",
      "symptom",
      "depression assessment",
      "correlation depression"
    ],
    "examples": [
      "depression and physical comorbidity",
      "quality of life in depression",
      "depression severity estimation",
      "depression severity measurement",
      "depression scale prediction",
      "depression severity correlation",
      "depression severity assessment",
      "depression severity prediction",
      "depression severity assessment",
      "depression mediation analysis",
      "clinical symptom severity correlation",
      "depression assessment via emotion",
      "depression severity forecasting",
      "depression severity forecasting",
      "depression severity prediction",
      "depression recovery assessment",
      "depression symptom assessment",
      "depression heterogeneity modeling",
      "depressive symptom correlation analysis",
      "antidepressant drug efficacy prediction"
    ]
  },
  {
    "topic_id": 42,
    "size": 29,
    "keywords": [
      "depression detection",
      "depression",
      "detection depression",
      "depression recognition",
      "task depression",
      "detection",
      "detection task",
      "depressive state",
      "eegbased depression",
      "depression state"
    ],
    "examples": [
      "depression self-abnormality detection",
      "depression detection task",
      "real-time clinical depression detection",
      "depression state diagnosis",
      "depression recognition from eeg",
      "explainable depression detection",
      "depressive state extraction",
      "depressive state extraction",
      "depression state detection",
      "depression detection task",
      "interview-based depression detection",
      "depression emotion disorder detection",
      "depression emotion disorder detection",
      "depression detection from eeg",
      "speech depression detection",
      "depression detection task",
      "depression detection task",
      "depression recognition",
      "elderly depression detection",
      "user-level depression detection"
    ]
  },
  {
    "topic_id": 43,
    "size": 29,
    "keywords": [
      "affective pattern",
      "affective image",
      "image classification",
      "affective region",
      "classification affective",
      "affective",
      "image",
      "pattern",
      "pattern recognition",
      "mapping"
    ],
    "examples": [
      "affective trait mapping",
      "affective pattern recognition",
      "hci-related affect recognition",
      "affective basis of extraversion",
      "affective trait mapping",
      "affective image classification",
      "affective image classification",
      "affective image classification",
      "affective pattern classification",
      "affective region discovery problem",
      "affective image classification",
      "affective region discovery",
      "affective image captioning task",
      "affective pattern classification",
      "affective pattern classification",
      "affective pattern recognition",
      "affective image classification",
      "affective image interpretation",
      "image-text affective region mapping",
      "image-text affective region mapping"
    ]
  },
  {
    "topic_id": 44,
    "size": 28,
    "keywords": [
      "tendency",
      "emotion annotation",
      "descriptive",
      "descriptive emotion",
      "emotion label",
      "annotation",
      "expensive",
      "ignored subtle",
      "expensive emotion",
      "emotional tendency"
    ],
    "examples": [
      "emotional tendency judgment",
      "anger expression processing",
      "interoperable emotion annotation definition",
      "emotion tendency labeling",
      "emotion tendency judgment",
      "emotional tendency mining",
      "emotional tendency judgment",
      "unified emotion annotation criteria",
      "unified emotion annotation criteria",
      "ignored subtle emotion labels",
      "ignored subtle emotion labels",
      "ignored subtle emotion labels",
      "expensive emotion data annotation",
      "expensive emotion data annotation",
      "expensive emotion data annotation",
      "noisy emotion label impact",
      "noisy emotion label impact",
      "binary emotion labeling",
      "binary emotion labeling",
      "ambiguous emotion label handling"
    ]
  },
  {
    "topic_id": 45,
    "size": 27,
    "keywords": [
      "audiovisual",
      "recognition audiovisual",
      "audiovisual emotion",
      "emotional content",
      "openvocabulary",
      "content",
      "content generation",
      "recognition audiovideo",
      "audiovideo",
      "interactive emotional"
    ],
    "examples": [
      "audio video fusion",
      "emotional audio-visual generation",
      "audio-visual emotion recognition",
      "audio-visual affect recognition",
      "audio-visual synchronization",
      "audio-visual emotion recognition",
      "audio-video emotion recognition",
      "audio-only emotion recognition",
      "audiovisual processing of emotional stimuli",
      "emotional content editing",
      "reverberation impact on emotion recognition",
      "audio-video emotion recognition",
      "audio-visual group emotion recognition",
      "audio-visual emotion recognition",
      "audio-visual emotion recognition",
      "audio-visual emotion recognition",
      "open-vocabulary emotion recognition",
      "open-vocabulary emotion recognition",
      "audio-video emotional synchronization",
      "open-vocabulary visual emotion recognition"
    ]
  },
  {
    "topic_id": 46,
    "size": 26,
    "keywords": [
      "multilabel",
      "multiclass",
      "multilabel emotion",
      "multiclass emotion",
      "multiemotion",
      "intensity prediction",
      "prediction multilabel",
      "multilabel affective",
      "emotion intensity",
      "classification multilabel"
    ],
    "examples": [
      "multi-emotion state labeling",
      "multi-class emotion classification",
      "multi-emotion labeling analysis",
      "multi-class speech emotion recognition",
      "multi-class emotion classification",
      "multi-label affective classification",
      "multi-emotion image labeling",
      "multi-class emotion confusion",
      "image-level label learning",
      "multi-emotion intensity prediction",
      "multi-label emotion classification",
      "three-category emotion recognition",
      "multi-label emotion detection",
      "multi-label emotion recognition",
      "three-class emotion classification",
      "multi-label facial expression recognition",
      "multi-label emotion intensity prediction",
      "multi-label emotion intensity prediction",
      "multi-label emotion intensity prediction",
      "single-class emotion modeling"
    ]
  },
  {
    "topic_id": 47,
    "size": 26,
    "keywords": [
      "classification multimodal",
      "multimodal emotion",
      "interpretation multimodal",
      "prediction multimodal",
      "emotion interpretation",
      "interpretation",
      "multimodal",
      "emotion understanding",
      "understanding multimodal",
      "understanding"
    ],
    "examples": [
      "multimodal emotion prediction",
      "multimodal emotion classification",
      "multimodal emotion modeling",
      "multimodal emotion state classification",
      "multimodal emotion classification",
      "multimodal emotion classification",
      "multimodal emotion prediction",
      "multimodal emotion prediction",
      "multimodal emotion understanding",
      "multimodal emotion indexing",
      "multi dimensional emotion classification",
      "multimodal emotion classification",
      "single-modal emotion prediction",
      "multimodal emotion intensity prediction",
      "multimodal emotion understanding",
      "multimodal emotion classification",
      "multimodal emotion classification",
      "multimodal large language model interpretation",
      "multimodal emotion understanding",
      "multi-turn emotion understanding"
    ]
  },
  {
    "topic_id": 48,
    "size": 26,
    "keywords": [
      "expression classification",
      "classification facial",
      "facial expression",
      "expression detection",
      "expression",
      "coding",
      "ensemble",
      "ensemble coding",
      "alien",
      "alien expression"
    ],
    "examples": [
      "facial expression fidelity improvement",
      "facial expression feature learning",
      "facial expression identification",
      "facial expression classification",
      "facial expression classification",
      "facial expression classification",
      "facial expression detection",
      "neural coding strategies",
      "facial expression categorization",
      "facial expression identification errors",
      "ensemble coding of facial expressions",
      "facial expression editing",
      "facial expression analysis with limited labels",
      "seven basic expression classification",
      "facial expression progression modeling",
      "facial expression categorization",
      "facial expression category recognition",
      "facial expression intensity estimation",
      "alien expression detection",
      "alien expression detection"
    ]
  },
  {
    "topic_id": 49,
    "size": 26,
    "keywords": [
      "task speech",
      "recognition task",
      "speech emotion",
      "speech",
      "task",
      "emotion recognition",
      "tasks speech",
      "recognition",
      "emotion",
      "recognition tasks"
    ],
    "examples": [
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition tasks",
      "speech emotion recognition task",
      "speech emotion recognition task",
      "speech emotion recognition task"
    ]
  },
  {
    "topic_id": 50,
    "size": 25,
    "keywords": [
      "physiological",
      "physiological signal",
      "signal",
      "multimodal physiological",
      "recognition physiological",
      "physiologicalemotion",
      "physiologicalemotion recognition",
      "signal analysis",
      "biomarker",
      "recognition physiologicalemotion"
    ],
    "examples": [
      "sentiment classification from physiology",
      "emotion recognition from physiological signals",
      "psychophysiological emotion modeling",
      "sentiment recognition from physiological signals",
      "multimodal physiological signal analysis",
      "multimodal physiological signal correlation",
      "physiological signal based recognition",
      "physiological-emotion recognition",
      "physiological signal analysis",
      "physiological-emotion recognition",
      "multimodal physiological signal fusion",
      "physiological signal monitoring",
      "physiological signal monitoring",
      "physiological signal based recognition",
      "physiological-emotion recognition",
      "physiological signal modeling",
      "physiological biomarker modeling",
      "electrophysiological biomarker discovery",
      "brain signal pattern analysis",
      "neurophysiological pattern analysis"
    ]
  },
  {
    "topic_id": 51,
    "size": 25,
    "keywords": [
      "conversation generation",
      "conversation",
      "generation emotional",
      "emotional conversation",
      "generation",
      "guidance",
      "emotional support",
      "dialogue generation",
      "emotional guidance",
      "dialogue"
    ],
    "examples": [
      "emotional conversation generation",
      "emotional conversation generation",
      "emotional conversation generation",
      "emotional conversation generation",
      "emotional conversation generation",
      "emotion-constrained dialogue generation",
      "emotion-constrained conversation generation",
      "emotional editing in dialogue",
      "emotional conversation generation",
      "emotional guidance generation",
      "emotional guidance sequence generation",
      "diverse and fluent conversation",
      "emotional dialogue generation task",
      "emotional conversation generation",
      "emotional conversation generation",
      "dialog-based emotional guidance",
      "dialog-based emotional guidance",
      "emotional support conversation task",
      "emotional support dialogue generation",
      "emotional support conversation generation"
    ]
  },
  {
    "topic_id": 52,
    "size": 25,
    "keywords": [
      "arousal estimation",
      "arousal",
      "estimation",
      "valence",
      "valence arousal",
      "estimation valence",
      "valencearousal estimation",
      "valencearousal",
      "valence estimation",
      "estimation continuous"
    ],
    "examples": [
      "dimensional valence-arousal estimation",
      "dimensional valence-arousal estimation",
      "dimensional valence-arousal estimation",
      "in-the-wild arousal estimation",
      "in-the-wild valence estimation",
      "valence and arousal estimation",
      "arousal and valence estimation",
      "continuous valence arousal estimation",
      "continuous valence-arousal estimation",
      "continuous arousal and valence estimation",
      "valence and arousal estimation",
      "valence and arousal estimation",
      "continuous valence arousal estimation",
      "valence and arousal estimation",
      "valence and arousal estimation",
      "personalized arousal and valence estimation",
      "valence arousal estimation",
      "valence and arousal estimation",
      "multimodal arousal and valence estimation",
      "continuous arousal valence estimation"
    ]
  },
  {
    "topic_id": 53,
    "size": 24,
    "keywords": [
      "feature distribution",
      "distribution",
      "feature",
      "distribution mismatch",
      "inconsistency feature",
      "distribution inconsistency",
      "mismatch",
      "mismatch feature",
      "inconsistency",
      "distribution discrepancy"
    ],
    "examples": [
      "feature distribution discrepancy mitigation",
      "feature distribution mismatch",
      "feature distribution mismatch",
      "feature distribution mismatch",
      "feature distribution mismatch",
      "feature matching problem",
      "feature distribution inconsistency",
      "feature distribution inconsistency",
      "feature distribution gap",
      "feature distribution gap",
      "feature distribution discrepancy elimination",
      "feature information transmission loss",
      "feature distribution inconsistency",
      "feature distribution inconsistency",
      "feature distribution inconsistency",
      "feature distribution inconsistency",
      "feature distribution mismatch",
      "subtle feature loss mitigation",
      "feature distribution discrepancy",
      "feature distribution mismatch"
    ]
  },
  {
    "topic_id": 54,
    "size": 24,
    "keywords": [
      "state classification",
      "classification affective",
      "affective state",
      "affective signal",
      "state",
      "affective",
      "classification",
      "signal classification",
      "signal",
      "signal generalization"
    ],
    "examples": [
      "affective state assessment",
      "naturalistic affective expression classification",
      "affective signal extraction from microblogs",
      "affective state classification",
      "affective state classification from signals",
      "affective state classification",
      "affective speaker state classification",
      "health state classification",
      "affective state classification",
      "affective state classification",
      "real-time affective state classification",
      "affective state classification",
      "affective signal generalization",
      "affective signal classification",
      "affective audio classification",
      "affective signal classification",
      "affective signal classification",
      "affective state classification",
      "affective event classification",
      "affective imitative expression assessment"
    ]
  },
  {
    "topic_id": 55,
    "size": 24,
    "keywords": [
      "eeg emotion",
      "recognition eeg",
      "eeg",
      "interpretability eeg",
      "interpretability",
      "recognition interpretability",
      "emotion recognition",
      "coarsegrained eeg",
      "overfitting eeg",
      "eeg interpretability"
    ],
    "examples": [
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "emotion recognition from eeg",
      "eeg emotion recognition overfitting",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "coarse-grained eeg interpretability",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition interpretability",
      "eeg emotion recognition interpretability",
      "eeg emotion recognition",
      "eeg emotion recognition",
      "eeg emotion recognition"
    ]
  },
  {
    "topic_id": 56,
    "size": 24,
    "keywords": [
      "eeg",
      "multichannel",
      "multichannel eeg",
      "recognition multichannel",
      "differences eeg",
      "eeg channel",
      "eeg signal",
      "channel",
      "signal",
      "individual differences"
    ],
    "examples": [
      "automatic eeg channel selection",
      "multichannel eeg emotion recognition",
      "dynamic eeg region relationships",
      "individual differences in eeg",
      "eeg feature extraction difficulty",
      "multi-channel eeg emotion recognition",
      "multi-channel eeg emotion recognition",
      "multi-channel eeg emotion recognition",
      "multichannel eeg emotion recognition",
      "eeg channel topology representation",
      "eeg signal distribution mismatch",
      "nonstationary signal feature extraction",
      "eeg channel contribution localization",
      "non-stationary speech signal processing",
      "individual differences in eeg",
      "individual differences in eeg",
      "spurious eeg connection removal",
      "spurious eeg connection removal",
      "eeg signal nonstationarity",
      "eeg signal nonstationarity"
    ]
  },
  {
    "topic_id": 57,
    "size": 24,
    "keywords": [
      "crossmodal",
      "crossmodal emotion",
      "crossmodal interaction",
      "crossmodal semantic",
      "alignment",
      "semantic",
      "inefficiency crossmodal",
      "crossmodal feature",
      "interaction inefficiency",
      "semantic misalignment"
    ],
    "examples": [
      "multimodal temporal alignment",
      "sentiment-oriented cross-modal retrieval",
      "cross-modal emotion recognition",
      "cross-modal emotion matching",
      "cross-modal emotion matching",
      "multimodal interaction limitations",
      "cross-modal interaction modeling",
      "cross-modal emotion analysis",
      "cross-modal complementarity utilization",
      "efficient cross-modal interaction",
      "cross-modal interaction inefficiency",
      "cross-modal interaction inefficiency",
      "cross-modal imagination accuracy",
      "cross-modal feature distribution",
      "cross-modal emotion understanding",
      "cross-modal feature distribution alignment",
      "crossmodal fear generalization",
      "cross-modal temporal alignment",
      "multimodal semantic gap reduction",
      "cross-modal expressive disparities"
    ]
  },
  {
    "topic_id": 58,
    "size": 23,
    "keywords": [
      "personality",
      "personality recognition",
      "emotion personality",
      "recognition personality",
      "recognition emotion",
      "personality trait",
      "personalityaware",
      "workplace",
      "recognition personalityaware",
      "analysis workplace"
    ],
    "examples": [
      "personal emotional factor integration",
      "positive versus negative emotion recognition",
      "personality trait detection",
      "personnel psychology analysis",
      "workplace emotion dynamics",
      "social approval perception modeling",
      "personality detection in interactions",
      "personality recognition",
      "personality recognition",
      "personality recognition",
      "personality-aware emotion recognition",
      "emotion-personality task integration",
      "personality trait recognition",
      "personality trait estimation",
      "multimodal personality-aware analysis",
      "personality recognition via emotion",
      "personality recognition via emotion",
      "personality recognition via emotion",
      "personality recognition via emotion",
      "personality recognition via emotion"
    ]
  },
  {
    "topic_id": 59,
    "size": 23,
    "keywords": [
      "social media",
      "media",
      "chinese",
      "microblog",
      "analysis social",
      "microblog sentiment",
      "media sentiment",
      "analysis chinese",
      "social",
      "media emotion"
    ],
    "examples": [
      "chinese emotion expression",
      "micro-blog sentiment classification",
      "microblog sentiment prediction",
      "fragmented chinese text emotion",
      "microblogging hot event sentiment",
      "chinese microblog emotion analysis",
      "chinese micro-blog sentiment analysis",
      "chinese sentiment lexicon construction",
      "chinese microblog emotion classification",
      "microblog emotion analysis",
      "chinese text emotion detection",
      "social media sentiment analysis",
      "chinese natural emotion recognition",
      "microblog sentiment analysis",
      "social media sentiment monitoring",
      "social media emotion assessment",
      "heterogeneous social media analysis",
      "social media sentiment analysis",
      "social media sentiment analysis",
      "social media emotion detection"
    ]
  },
  {
    "topic_id": 60,
    "size": 23,
    "keywords": [
      "response",
      "response generation",
      "empathy",
      "emotional understanding",
      "empathetic response",
      "empathetic",
      "understanding response",
      "generation",
      "emotional response",
      "response emotional"
    ],
    "examples": [
      "response competition processes",
      "emotional response generation",
      "customizable emotional response",
      "emotionless response generation",
      "children empathy ability analysis",
      "affective response generation",
      "response quality preservation",
      "retail service empathy",
      "empathy and exhaustion relationship",
      "conditioned action generation",
      "charismatic behavior generation",
      "empathetic response generation",
      "empathy component differentiation",
      "empathetic response generation",
      "llm emotional alignment assessment",
      "sticker response selection",
      "empathetic response quality improvement",
      "incomplete user emotional understanding",
      "empathetic response generation",
      "empathy level alignment"
    ]
  },
  {
    "topic_id": 61,
    "size": 23,
    "keywords": [
      "arousal",
      "valence",
      "arousal prediction",
      "arousal valence",
      "valence arousal",
      "valence prediction",
      "prediction arousal",
      "prediction valence",
      "dominance",
      "prediction"
    ],
    "examples": [
      "valence and arousal classification",
      "social dominance evaluation",
      "valence and arousal prediction",
      "valence arousal dominance classification",
      "interaction of attention arousal valence",
      "valence and arousal classification",
      "arousal valence dominance prediction",
      "arousal level mismatch analysis",
      "arousal and valence prediction",
      "arousal and valence prediction",
      "arousal and valence prediction",
      "arousal and valence prediction",
      "high and low arousal differentiation",
      "continuous valence and arousal prediction",
      "psycho-physiological arousal prediction",
      "valence prediction analysis",
      "arousal and valence modeling",
      "valence arousal prediction",
      "valence and arousal prediction",
      "psycho-physiological arousal prediction"
    ]
  },
  {
    "topic_id": 62,
    "size": 22,
    "keywords": [
      "conversational emotion",
      "conversational",
      "recognition conversational",
      "analysis conversational",
      "emotion correction",
      "detection conversational",
      "correction conversational",
      "dialogical",
      "dialogical emotion",
      "task conversational"
    ],
    "examples": [
      "natural speech emotion analysis",
      "affective dialogue consistency",
      "emotion-based robot communication",
      "conversation anomaly detection",
      "conversational emotion analysis",
      "conversational emotion analysis",
      "conversational emotion recognition task",
      "conversational emotion recognition",
      "conversational emotion recognition task",
      "conversational emotion recognition",
      "conversational emotion recognition",
      "dialogical emotion correction",
      "conversational emotion recognition",
      "dialogical emotion correction",
      "conversational emotion recognition",
      "conversational emotion recognition",
      "conversational emotion analysis",
      "conversational emotion recognition",
      "conversational emotion inference",
      "dialogue emotion detection"
    ]
  },
  {
    "topic_id": 63,
    "size": 22,
    "keywords": [
      "prediction continuous",
      "continuous emotion",
      "continuous",
      "emotion prediction",
      "prediction",
      "distribution prediction",
      "emotion distribution",
      "distribution",
      "friendliness",
      "emotionenhanced performance"
    ],
    "examples": [
      "continuous affect prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion distribution prediction",
      "continuous emotion distribution prediction",
      "friendliness degree prediction",
      "continuous emotion distribution prediction",
      "continuous emotion distribution prediction",
      "continuous emotion distribution prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion prediction",
      "continuous emotion dimension prediction"
    ]
  },
  {
    "topic_id": 64,
    "size": 21,
    "keywords": [
      "spotting spontaneous",
      "spontaneous",
      "spotting",
      "microexpression spotting",
      "spotting recognition",
      "spontaneous microexpression",
      "spontaneous expression",
      "spontaneous facial",
      "differentiation spontaneous",
      "integrated spotting"
    ],
    "examples": [
      "spontaneous micro-expression spotting",
      "spontaneous micro-expression spotting",
      "spontaneous versus posed differentiation",
      "spontaneous versus posed expression differentiation",
      "spontaneous micro-expression spotting",
      "spontaneous pain expression monitoring",
      "spontaneous expression recognition",
      "spontaneous facial behavior analysis",
      "spontaneous facial expression analysis",
      "spontaneous facial expression analysis",
      "spontaneous micro-expression spotting",
      "spontaneous expression spotting",
      "spontaneous facial expression recognition",
      "spontaneous micro-expression spotting",
      "spontaneous micro-expression spotting",
      "spontaneous micro-expression spotting",
      "spontaneous expression coding difficulty",
      "integrated spotting and recognition",
      "integrated spotting and recognition",
      "unified micro-expression spotting and recognition"
    ]
  },
  {
    "topic_id": 65,
    "size": 21,
    "keywords": [
      "affective state",
      "state",
      "recognition affective",
      "state recognition",
      "monitoring affective",
      "detection affective",
      "affective",
      "state detection",
      "affect detection",
      "viewer affective"
    ],
    "examples": [
      "user affect measurement",
      "viewer affective state estimation",
      "viewer affective state analysis",
      "suppressed affect detection",
      "suppressed affect detection",
      "user affective state tracking",
      "affective state recognition",
      "affective state recognition",
      "affective state recognition",
      "affective state detection",
      "child affective monitoring",
      "affective behavior detection",
      "affective state detection",
      "affective state monitoring",
      "affective state estimation",
      "affective brain state monitoring",
      "affective state detection",
      "affective state recognition",
      "affective engagement recognition",
      "affective state recognition"
    ]
  },
  {
    "topic_id": 66,
    "size": 21,
    "keywords": [
      "domain adaptation",
      "adaptation",
      "domain",
      "unsupervised domain",
      "unsupervised",
      "adaptation unsupervised",
      "adaptation emotion",
      "adaptation mismatch",
      "adaptation multisource",
      "shift unsupervised"
    ],
    "examples": [
      "domain adaptation for emotion",
      "domain adaptation for emotion",
      "cross subject domain shift",
      "unsupervised domain adaptation",
      "unsupervised domain adaptation",
      "unsupervised domain adaptation",
      "unsupervised domain adaptation",
      "unsupervised domain adaptation",
      "unsupervised domain adaptation",
      "multi-source domain adaptation",
      "multi-source sentiment domain adaptation",
      "domain adaptation challenges",
      "domain adaptation challenges",
      "adversarial attack transferability",
      "domain adaptation for emotion",
      "domain adaptation for emotions",
      "multi-domain distribution shift",
      "unsupervised domain adaptation",
      "source-free domain adaptation",
      "unsupervised domain adaptation mismatch"
    ]
  },
  {
    "topic_id": 67,
    "size": 20,
    "keywords": [
      "brain",
      "connectivity",
      "brain connectivity",
      "functional",
      "brain dynamics",
      "connectivity modeling",
      "connectivity analysis",
      "brain functional",
      "analysis brain",
      "connectivity pattern"
    ],
    "examples": [
      "grey matter volume alterations",
      "inconsistent structural brain findings",
      "brain hemisphere discrepancy modeling",
      "modeling localized brain functional relations",
      "brain region abstraction",
      "functional connection modeling",
      "abnormal brain information interaction",
      "brain connectivity analysis",
      "brain connectivity analysis",
      "brain connectivity analysis",
      "subject-specific brain dynamics variability",
      "statistical uncertainty in brain dynamics",
      "brain connectivity pattern analysis",
      "brain connectivity pattern analysis",
      "reciprocal imbalanced connectivity modeling",
      "brain network modeling",
      "subject-specific brain dynamics",
      "brain functional connectivity modeling",
      "brain functional connectivity modeling",
      "individualized brain abnormality modeling"
    ]
  },
  {
    "topic_id": 68,
    "size": 20,
    "keywords": [
      "autism",
      "autism emotion",
      "spectrum",
      "recognition autism",
      "autism spectrum",
      "spectrum disorder",
      "assessment autism",
      "autistic",
      "asd autism",
      "social skill"
    ],
    "examples": [
      "autism neural substrate identification",
      "autistic behavior assessment",
      "autism therapy engagement recognition",
      "autism spectrum disorder therapy",
      "social skill improvement for asd",
      "autism severity assessment",
      "early autism symptom prediction",
      "attention deficit assessment",
      "autism spectrum disorder screening",
      "emotion recognition in asd",
      "autism emotion assessment",
      "early autism screening",
      "autism spectrum disorder assessment",
      "autism social interaction impairment",
      "autistic social skill deficits",
      "autism emotion recognition",
      "autism emotion recognition",
      "autism emotion recognition",
      "autism emotion recognition",
      "objective autism spectrum assessment"
    ]
  },
  {
    "topic_id": 69,
    "size": 20,
    "keywords": [
      "eegbased emotion",
      "recognition eegbased",
      "eegbased",
      "emotion recognition",
      "recognition",
      "emotion"
    ],
    "examples": [
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition",
      "eeg-based emotion recognition"
    ]
  },
  {
    "topic_id": 70,
    "size": 20,
    "keywords": [
      "automatic depression",
      "automatic",
      "level",
      "depression level",
      "prediction automatic",
      "detection automatic",
      "level prediction",
      "depression",
      "level detection",
      "severity prediction"
    ],
    "examples": [
      "automatic deception detection",
      "automatic engagement level prediction",
      "automatic depression level detection",
      "automatic depression detection",
      "automatic depression level detection",
      "automatic depression level detection",
      "automatic depression level prediction",
      "adolescent suicidal ideation prediction",
      "automatic depression level prediction",
      "automatic depression level assessment",
      "daily depression score prediction",
      "automatic depression severity diagnosis",
      "automatic depression level prediction",
      "automatic depression severity prediction",
      "automatic depression severity prediction",
      "automatic depression level prediction",
      "escalation level detection",
      "automatic depression level prediction",
      "automatic depression detection",
      "automatic depression severity prediction"
    ]
  },
  {
    "topic_id": 71,
    "size": 20,
    "keywords": [
      "small",
      "small sample",
      "limitation",
      "sample",
      "dataset",
      "size",
      "sample size",
      "limitation small",
      "dataset limitation",
      "problem small"
    ],
    "examples": [
      "survey application problems",
      "small sample size challenge",
      "small sample size challenge",
      "single database evaluation limitation",
      "single database evaluation limitation",
      "single-source data limitation",
      "small-scale dataset limitations",
      "small-scale dataset limitation",
      "small sample size limitation",
      "small-scale dataset limitations",
      "small sample size problem",
      "small data sample limitation",
      "small data sample limitation",
      "small sample problem",
      "small sample problem",
      "small sample dataset performance",
      "population-level evaluation limitations",
      "small annotated dataset size",
      "small annotated dataset limitation",
      "low-resource dataset limitation"
    ]
  },
  {
    "topic_id": 72,
    "size": 20,
    "keywords": [
      "interference",
      "noise reduction",
      "head movement",
      "head",
      "noise",
      "reduction",
      "movement noise",
      "movement",
      "movement interference",
      "irrelevant"
    ],
    "examples": [
      "noise and outlier reduction",
      "classification noise reduction",
      "garner interference effect",
      "head movement noise reduction",
      "head movement noise reduction",
      "head movement noise reduction",
      "noise reduction in eeg",
      "wild scenario interference handling",
      "noise interference mitigation",
      "head movement interference",
      "magnification noise reduction",
      "outlier sample interference",
      "head movement interference mitigation",
      "in-the-wild interference handling",
      "noisy feature interference",
      "noisy feature interference",
      "low signal-to-noise ratio data",
      "irrelevant information interference",
      "irrelevant information interference",
      "interference robustness"
    ]
  },
  {
    "topic_id": 73,
    "size": 20,
    "keywords": [
      "neural",
      "basis",
      "correlates",
      "neural basis",
      "neural correlates",
      "emotional intelligence",
      "intelligence",
      "basis emotional",
      "neuroanatomical",
      "correlates social"
    ],
    "examples": [
      "neurogenetic susceptibility mechanisms",
      "neural basis of life satisfaction",
      "neuroanatomical basis of emotional intelligence",
      "neural correlates of social well-being",
      "eudaimonic well-being neural correlates",
      "happy life neural correlates",
      "neural basis of insight emotions",
      "neural basis of mind-body interaction",
      "dispositional mindfulness neural correlates",
      "poverty induced neural atrophy",
      "neuroanatomical correlates of ptsd",
      "neural basis of emotion",
      "emotion neural correlates",
      "neural correlates of emotional words",
      "neural basis of masculinity and femininity",
      "reward sensitivity and social reinforcement",
      "neural basis of self-esteem",
      "emotional intelligence relation",
      "neural correlates of social support",
      "neural basis of emotional intelligence"
    ]
  },
  {
    "topic_id": 74,
    "size": 20,
    "keywords": [
      "major",
      "depressive disorder",
      "major depressive",
      "depressive",
      "disorder",
      "pathology",
      "disorder pathology",
      "detection major",
      "treatment",
      "disorder recognition"
    ],
    "examples": [
      "late-life depression pathophysiology",
      "neuropsychological impairment in mdd",
      "self-processing deficits in depression",
      "major depression pathology",
      "major depressive disorder pathology",
      "major depressive disorder treatment response",
      "depressive disorder treatment",
      "major depressive disorder pathophysiology",
      "major depressive disorder pathology",
      "depression treatment efficacy",
      "major depressive disorder recognition",
      "major depressive disorder recognition",
      "depression pathogenesis exploration",
      "major depressive disorder detection",
      "major depressive disorder identification",
      "major depressive disorder pathology",
      "atypical major depressive disorder characterization",
      "major depressive disorder detection",
      "major depressive disorder detection",
      "major depressive disorder diagnosis"
    ]
  },
  {
    "topic_id": 75,
    "size": 20,
    "keywords": [
      "humor",
      "humor detection",
      "crosscultural humor",
      "detection crosscultural",
      "detection task",
      "crosscultural",
      "sarcasm",
      "multimodal humor",
      "sarcasm detection",
      "task humor"
    ],
    "examples": [
      "humor detection task",
      "multimodal humor detection",
      "multimodal humor detection",
      "multimodal humor detection",
      "cross-cultural humor detection",
      "sarcasm detection",
      "humor detection task",
      "cross-cultural humor detection",
      "humor detection task",
      "humor detection task",
      "sarcasm detection task",
      "humor detection task",
      "humor detection task",
      "cross-cultural humor detection",
      "cross-cultural humor detection",
      "cross-cultural humor detection",
      "cross-cultural humor detection",
      "cross-cultural humor detection",
      "cross-cultural humor detection",
      "multi-modal sarcasm detection"
    ]
  },
  {
    "topic_id": 76,
    "size": 20,
    "keywords": [
      "microexpression detection",
      "automatic microexpression",
      "microexpression",
      "analysis microexpression",
      "microexpression analysis",
      "extraction microexpression",
      "microexpression feature",
      "microexpression model",
      "frame inference",
      "microexpression key"
    ],
    "examples": [
      "automatic micro-expression analysis evaluation",
      "micro-expression detection task",
      "micro-expression detection",
      "automatic micro-expression analysis",
      "micro-expression detection task",
      "micro-expression detection task",
      "micro-expression detection",
      "automatic micro-expression analysis",
      "micro-expression detection",
      "micro-expression detection",
      "limited micro-expression sample robustness",
      "micro-expression feature extraction",
      "micro-expression feature extraction",
      "micro-expression mechanism analysis",
      "micro-expression detection",
      "micro-expression model generalization",
      "micro-expression model generalization",
      "identity-preserving expression animation",
      "micro-expression key frame inference",
      "micro-expression key frame inference"
    ]
  },
  {
    "topic_id": 77,
    "size": 19,
    "keywords": [
      "temporal",
      "temporal emotion",
      "analysis temporal",
      "spatiotemporal emotion",
      "emotion mapping",
      "spatiotemporal",
      "modeling temporal",
      "mapping",
      "temporal metaphor",
      "temporal duration"
    ],
    "examples": [
      "temporal emotion modeling",
      "temporal emotion analysis",
      "temporal emotion analysis",
      "temporal emotion trend analysis",
      "temporal duration effects",
      "diurnal emotion rhythm analysis",
      "temporal emotion dynamics modeling",
      "temporal emotion analysis",
      "temporal compression by fear",
      "temporal stages of processing",
      "spatio-temporal emotion mapping",
      "temporal metaphor perspective",
      "spatio-temporal emotion mapping",
      "emotional interference in temporal processing",
      "temporal sentiment localization task",
      "temporal emotion representation",
      "temporal emotion accumulation",
      "temporal emotion continuity",
      "temporal emotional fluctuation modeling"
    ]
  },
  {
    "topic_id": 78,
    "size": 19,
    "keywords": [
      "multimodal feature",
      "feature fusion",
      "fusion",
      "feature",
      "feature integration",
      "recognition limitation",
      "fusion comparison",
      "single modality",
      "complementarity",
      "comparison"
    ],
    "examples": [
      "multimodal feature fusion",
      "multimodal feature integration challenge",
      "multimodal feature fusion comparison",
      "multimodal feature fusion comparison",
      "high-order feature integration",
      "multi-modal information representation",
      "multimodal feature fusion",
      "multimodal feature fusion",
      "intermediate representation fusion",
      "multi-task feature integration",
      "multi-modal feature underutilization",
      "multimodal feature complementarity",
      "fusion representation complementarity",
      "single modality gesture recognition limitation",
      "single modality recognition limitation",
      "multimodal spatial feature capture",
      "task-specific detail capture",
      "multimodal feature fusion",
      "unimodal feature extraction limitations"
    ]
  },
  {
    "topic_id": 79,
    "size": 18,
    "keywords": [
      "label",
      "noisy label",
      "noisy",
      "label noise",
      "noise management",
      "label handling",
      "management",
      "management label",
      "noise",
      "handling"
    ],
    "examples": [
      "automatic corpus labeling",
      "missing label prediction",
      "noisy label handling",
      "missing label handling",
      "noisy social image data",
      "inference without gold labels",
      "label noise management",
      "label noise management",
      "label noise management",
      "label noise management",
      "noisy label handling",
      "handling noisy labels",
      "noisy label handling",
      "uncertain label correction",
      "handling label ambiguity and noise",
      "handling label ambiguity and noise",
      "noisy label mitigation",
      "noisy label facial expression recognition"
    ]
  },
  {
    "topic_id": 80,
    "size": 18,
    "keywords": [
      "multiview",
      "multiview facial",
      "recognition multiview",
      "analysis multiview",
      "classification multiview",
      "multiview expression",
      "arbitrary",
      "arbitrary view",
      "multiview emotion",
      "view"
    ],
    "examples": [
      "arbitrary view emotion recognition",
      "arbitrary view facial expression recognition",
      "multi-view facial expression recognition",
      "multi-view expression analysis",
      "multi-view emotion classification",
      "multi-view facial expression recognition",
      "multi-view facial expression recognition",
      "multi-view facial expression recognition",
      "multi-view facial expression recognition",
      "multi-view expression classification",
      "multi-view expression classification",
      "multi-view facial expression recognition",
      "multi-view facial expression analysis",
      "multi-view facial action unit detection",
      "multi-view emotion analysis",
      "multi-view facial pattern correlation",
      "multi-view facial expression recognition",
      "multiview facial emotion understanding"
    ]
  },
  {
    "topic_id": 81,
    "size": 18,
    "keywords": [
      "largescale",
      "analysis largescale",
      "emotion analysis",
      "analysis multimodal",
      "dataset collection",
      "analysis multifactor",
      "multimedia",
      "collection",
      "multifactor emotion",
      "multifactor"
    ],
    "examples": [
      "multimodal emotion analysis",
      "multimodal emotion analysis",
      "multi-modal emotion analysis",
      "multi-modal emotion analysis",
      "multi-factor emotion analysis",
      "multi-factor emotion analysis",
      "multifactorial emotion influence analysis",
      "large-scale voice data analysis",
      "multi-modal emotion analysis",
      "large-scale heterogeneous multimedia analysis",
      "multimodal emotion analysis",
      "analyzing large-scale multimedia data",
      "multimodal emotion analysis",
      "multimodal emotion analysis",
      "large-scale dataset collection",
      "large-scale dataset collection",
      "model instability in emotion analysis",
      "large-scale emotion datasets"
    ]
  },
  {
    "topic_id": 82,
    "size": 18,
    "keywords": [
      "spotting",
      "spotting microexpression",
      "microexpression spotting",
      "expression spotting",
      "macro micro",
      "macro",
      "spotting macro",
      "micro expression",
      "micro",
      "interval"
    ],
    "examples": [
      "facial expression spotting",
      "micro-expression spotting",
      "micro-expression spotting evaluation",
      "sub-second interval perception",
      "facial micro-expression spotting",
      "micro-expression spotting",
      "macro and micro expression spotting",
      "micro-expression interval spotting",
      "micro-expression interval spotting",
      "in-the-wild micro-expression spotting",
      "macro and micro expression spotting",
      "micro-expression spotting",
      "macro and micro expression spotting",
      "facial micro-expression spotting",
      "facial micro-expression spotting",
      "cross-cultural micro-expression spotting",
      "cross-cultural micro-expression spotting",
      "micro-expression spotting"
    ]
  },
  {
    "topic_id": 83,
    "size": 17,
    "keywords": [
      "modulation",
      "emotional modulation",
      "emotional context",
      "attention",
      "context effect",
      "attention modulation",
      "context",
      "effect",
      "spatial attention",
      "sensitivity affect"
    ],
    "examples": [
      "emotion modulated identity recognition",
      "emotion-driven attention modulation",
      "contextual sensitivity in affect",
      "emotional context effect",
      "spatial attention modulation by emotion",
      "self-reference effect modulation",
      "automatic attention attraction",
      "emotional context modulation effects",
      "emotional modulation of interval timing",
      "emotional modulation of cognition",
      "emotional context effect",
      "emotion-cognition-sleep interaction",
      "attributional emotion moderation",
      "sense of agency modulation",
      "emotional state modulation of capacity",
      "emotional modulation of collision estimation",
      "attention bias modification"
    ]
  },
  {
    "topic_id": 84,
    "size": 17,
    "keywords": [
      "emotion distribution",
      "distribution",
      "distribution learning",
      "distribution prediction",
      "learning visual",
      "prediction discrete",
      "discrete probability",
      "probability distribution",
      "probability",
      "discrete"
    ],
    "examples": [
      "discrete emotion distribution prediction",
      "discrete emotion distribution prediction",
      "discrete probability distribution modeling",
      "discrete probability distribution modeling",
      "image emotion distribution prediction",
      "image emotion distribution prediction",
      "discrete probability distribution prediction",
      "discrete emotion distribution prediction",
      "discrete probability distribution prediction",
      "text emotion distribution learning",
      "image emotion distribution learning",
      "visual emotion distribution learning",
      "visual emotion distribution learning",
      "visual emotion distribution learning",
      "visual emotion distribution learning",
      "visual emotion distribution learning",
      "diverse expression distribution modeling"
    ]
  },
  {
    "topic_id": 85,
    "size": 16,
    "keywords": [
      "recognition dimensional",
      "dimensional",
      "dimensional emotion",
      "modeling dimensional",
      "dimensional image",
      "scoring",
      "analysis dimensional",
      "emotion scoring",
      "detection dimensional",
      "dimensional speech"
    ],
    "examples": [
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional image emotion analysis",
      "dimensional emotion modeling",
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional emotion estimation",
      "dimensional emotion modeling",
      "dimensional speech emotion recognition",
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional emotion recognition",
      "dimensional image emotion detection",
      "dimensional emotion scoring"
    ]
  },
  {
    "topic_id": 86,
    "size": 16,
    "keywords": [
      "generalization",
      "crossdomain generalization",
      "unseen",
      "generalization unseen",
      "unseen subject",
      "generalization challenge",
      "subject generalization",
      "crossdataset generalization",
      "generalization crossdomain",
      "crossdomain"
    ],
    "examples": [
      "cross-document evidence integration",
      "poor generalization ability",
      "cross-domain generalization gap",
      "cross-domain feature extraction",
      "domain generalization for unseen conditions",
      "limited feature generalization capability",
      "cross-dataset generalization challenge",
      "cross-dataset generalization challenge",
      "cross-domain generalization",
      "unseen speech processing",
      "unseen subject generalization",
      "unseen subject generalization",
      "unconstrained condition generalization",
      "multi-source data generalization",
      "cross-domain generalization",
      "cross-domain generalization"
    ]
  },
  {
    "topic_id": 87,
    "size": 16,
    "keywords": [
      "modality robustness",
      "robustness",
      "robustness noise",
      "noise modality",
      "noise",
      "modality",
      "model",
      "robustness improvement",
      "robustness evaluation",
      "model robustness"
    ],
    "examples": [
      "feature robustness evaluation",
      "model robustness improvement",
      "model robustness improvement",
      "robustness to outliers and noise",
      "modality-wise uncertainty quantification",
      "unreliable model performance metrics",
      "modality robustness under noise",
      "modality robustness under noise",
      "modality robustness under noise",
      "modality robustness evaluation",
      "modality robustness under noise",
      "modality robustness under noise",
      "robustness against shortcuts",
      "single modality robustness issues",
      "model flexibility and scalability",
      "modality-specific noise"
    ]
  },
  {
    "topic_id": 88,
    "size": 16,
    "keywords": [
      "conflict",
      "emotional conflict",
      "conflict resolution",
      "resolution emotional",
      "resolution",
      "communication",
      "difficulties",
      "conflict control",
      "conflict adaptation",
      "communication analysis"
    ],
    "examples": [
      "emotional conflict adaptation",
      "nonverbal communication analysis",
      "cognitive conflict resolution",
      "emotional conflict control",
      "theoretical conflict resolution",
      "emotional conflict control",
      "reform-induced psychological conflict",
      "communication barriers",
      "emotional tradeoff difficulties",
      "nonverbal cue interpretation",
      "emotional conflict adaptation",
      "collaborative negotiation difficulties",
      "emotional cross-talk resolution",
      "emotional conflict resolution",
      "emotional conflict resolution",
      "eating disorder communication analysis"
    ]
  },
  {
    "topic_id": 89,
    "size": 16,
    "keywords": [
      "deep",
      "deep learning",
      "limitation deep",
      "data limitation",
      "learning data",
      "limitation",
      "learning",
      "performance degradation",
      "network performance",
      "deep network"
    ],
    "examples": [
      "data limitation in deep learning",
      "data limitation in deep learning",
      "data limitation in deep learning",
      "data limitation in deep learning",
      "data limitation in deep learning",
      "data limitation in deep learning",
      "deep network performance degradation",
      "deep network performance degradation",
      "manual feature engineering limitations",
      "high model parameter count",
      "low inference efficiency",
      "deep learning model compression",
      "edge device computational constraints",
      "large pretrained model inefficiency",
      "deep learning black-box limitations",
      "mllm reasoning limitations"
    ]
  },
  {
    "topic_id": 90,
    "size": 16,
    "keywords": [
      "recognition gestures",
      "gestures emotion",
      "uncertainty emotion",
      "images emotion",
      "images",
      "recognition images",
      "hci emotion",
      "recognition hci",
      "gestures",
      "recognition uncertainty"
    ],
    "examples": [
      "emotion recognition with history",
      "emotion recognition task",
      "emotion recognition task",
      "emotion recognition from video",
      "emotion recognition in challenging environments",
      "emotion recognition in videos",
      "emotion recognition in hci",
      "emotion recognition from images",
      "emotion recognition from images",
      "emotion recognition from gestures",
      "emotion recognition from gestures",
      "emotion recognition performance",
      "emotion recognition in hci",
      "emotion recognition under uncertainty",
      "emotion recognition under uncertainty",
      "emotion recognition tasks"
    ]
  },
  {
    "topic_id": 91,
    "size": 16,
    "keywords": [
      "visual",
      "visual emotion",
      "painting emotion",
      "recognition visual",
      "painting",
      "master painting",
      "master",
      "visual art",
      "analysis master",
      "emotion analysis"
    ],
    "examples": [
      "master painting emotion analysis",
      "master painting emotion analysis",
      "master painting emotion analysis",
      "visual emotion analysis",
      "visual emotion recognition",
      "visual art emotion recognition",
      "emotion-aware visual perception",
      "system interpretability in emotion",
      "emotional visual art comprehension",
      "source-free visual emotion adaptation",
      "visual emotion analysis generalizability",
      "visual emotion recognition",
      "visual emotion recognition",
      "visual emotion recognition evaluation",
      "visual emotion analysis",
      "interpretable visual emotion analysis"
    ]
  },
  {
    "topic_id": 92,
    "size": 15,
    "keywords": [
      "personalized",
      "prediction personalized",
      "personalized emotion",
      "personalized image",
      "perception personalized",
      "emotion perception",
      "emotion prediction",
      "perception",
      "perception prediction",
      "image emotion"
    ],
    "examples": [
      "personalized emotion perception",
      "personalized emotion perception prediction",
      "personalized emotion perception prediction",
      "personalized emotion perception prediction",
      "personalized image emotion prediction",
      "personalized image emotion perception",
      "personalized image emotion prediction",
      "personalized image emotion prediction",
      "personalized image emotion perception",
      "personalized emotion prediction",
      "individual-specific emotion prediction",
      "individual-specific emotion prediction",
      "personalized emotion prediction",
      "destination image perception",
      "personalized emotion perception modeling"
    ]
  },
  {
    "topic_id": 93,
    "size": 15,
    "keywords": [
      "recognition crosssubject",
      "crosssubject",
      "crosssubject eeg",
      "crosssubject emotion",
      "eeg emotion",
      "eeg",
      "recognition intersubject",
      "intersubject",
      "multisubject emotion",
      "multisubject"
    ],
    "examples": [
      "multi-subject emotion recognition",
      "inter-subject emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject emotion recognition",
      "cross-subject emotion recognition",
      "cross-subject emotion recognition",
      "intersubject generalization in emotion recognition",
      "cross-subject emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition",
      "cross-subject eeg emotion recognition"
    ]
  },
  {
    "topic_id": 94,
    "size": 15,
    "keywords": [
      "recognition conversation",
      "conversation emotion",
      "conversations emotion",
      "conversations",
      "conversation",
      "recognition conversations",
      "multiparty",
      "recognition multiparty",
      "noisy speech",
      "multiparty conversations"
    ],
    "examples": [
      "emotion recognition from noisy speech",
      "emotion recognition from speech",
      "emotion recognition in conversations",
      "emotion recognition in conversation",
      "emotion recognition in conversations",
      "emotion recognition in conversation",
      "emotion recognition in conversation",
      "emotion recognition in multi-party conversations",
      "emotion recognition in conversation",
      "emotion recognition in conversation",
      "emotion recognition in conversations",
      "emotion recognition in conversation",
      "emotion recognition in conversations",
      "emotion recognition in conversation",
      "emotion recognition in conversation"
    ]
  },
  {
    "topic_id": 95,
    "size": 15,
    "keywords": [
      "spotting task",
      "microexpression spotting",
      "spotting",
      "task microexpression",
      "task",
      "microexpression",
      "task facial",
      "expression spotting",
      "facial expression",
      "expression"
    ],
    "examples": [
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "facial expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task",
      "micro-expression spotting task"
    ]
  },
  {
    "topic_id": 96,
    "size": 14,
    "keywords": [
      "memory",
      "memory emotion",
      "item",
      "emotional memory",
      "source memory",
      "source",
      "emotion effect",
      "emotion effects",
      "item memory",
      "effects"
    ],
    "examples": [
      "emotion-memory interaction",
      "encoding versus retrieval effects",
      "attitude-memory dissociation analysis",
      "emotion-induced memory consolidation",
      "gender effects on memory",
      "item versus source memory",
      "emotion effects on item memory",
      "emotion effects on source memory",
      "time course of emotional memory",
      "emotion effect on item memory",
      "emotion effect on source memory",
      "gender differences in emotional memory",
      "working memory capacity reduction",
      "auditory emotional memory creation"
    ]
  },
  {
    "topic_id": 97,
    "size": 14,
    "keywords": [
      "domain shift",
      "shift",
      "domain",
      "shift emotion",
      "data domain",
      "analysis domain",
      "shift affective",
      "emotion data",
      "crosscultural domain",
      "computing adaptive"
    ],
    "examples": [
      "domain shift in emotion analysis",
      "domain mismatch in emotion data",
      "domain shift in emotion data",
      "domain shift in facial expressions",
      "domain shift in subtle dynamics",
      "domain shift in emotion analysis",
      "tourism domain emotion detection",
      "domain shift in emotion data",
      "domain shift in affective computing",
      "adaptive emotion domain shift",
      "domain shift in emotion analysis",
      "domain shift in affective signals",
      "domain variation in emotion recognition",
      "cross-cultural domain shift"
    ]
  },
  {
    "topic_id": 98,
    "size": 14,
    "keywords": [
      "subtle emotion",
      "subtle",
      "emotion detection",
      "detection subtle",
      "perception subtle",
      "longterm emotion",
      "subtle visual",
      "detection longterm",
      "longterm",
      "recognition short"
    ],
    "examples": [
      "subtle emotion recognition task",
      "deep event emotion analysis",
      "subtle emotion detection",
      "public emotion detection",
      "long-term emotion detection",
      "long-term emotion detection",
      "subtle emotion recognition",
      "short duration emotion analysis",
      "understanding subtle user emotional states",
      "subtle visual emotion perception",
      "subtle visual emotion perception",
      "subtle emotion detection",
      "subtle emotion detection",
      "subtle emotion visibility"
    ]
  },
  {
    "topic_id": 99,
    "size": 14,
    "keywords": [
      "4d facial",
      "4d",
      "recognition 4d",
      "recognition 3d4d",
      "3d4d facial",
      "3d4d",
      "facial affect",
      "expression recognition",
      "affect recognition",
      "facial expression"
    ],
    "examples": [
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial expression recognition",
      "4d facial affect recognition",
      "3d/4d facial affect recognition",
      "4d facial affect recognition",
      "3d/4d facial expression recognition"
    ]
  },
  {
    "topic_id": 100,
    "size": 14,
    "keywords": [
      "speaker identity",
      "speaker",
      "identity",
      "bias",
      "bias mitigation",
      "identity bias",
      "mitigation speaker",
      "identity distinction",
      "features speaker",
      "identity mismatch"
    ],
    "examples": [
      "rating data sparsity mitigation",
      "speaker identity distinction",
      "speaker identity distinction",
      "speaker identity mismatch",
      "speaker identity mismatch",
      "subject identity bias mitigation",
      "cross-database bias mitigation",
      "speaker bias in features",
      "speaker bias in features",
      "speaker identity bias mitigation",
      "speaker identity bias mitigation",
      "spurious bias mitigation in emotion data",
      "bias reduction in labeling",
      "speaker identity preservation"
    ]
  },
  {
    "topic_id": 101,
    "size": 14,
    "keywords": [
      "modality",
      "missing",
      "missing modality",
      "modality handling",
      "incomplete modality",
      "handling",
      "feature missing",
      "random modality",
      "modality feature",
      "settings"
    ],
    "examples": [
      "variable-length segment identification",
      "missing modality handling",
      "handling criteria interactions",
      "missing modality handling",
      "handling uncertain modality absence",
      "incomplete modality handling",
      "incomplete modality settings",
      "incomplete modality settings",
      "random modality feature missing",
      "random modality feature missing",
      "missing modality handling",
      "missing modality reconstruction",
      "missing modality handling",
      "missing modality handling"
    ]
  },
  {
    "topic_id": 102,
    "size": 13,
    "keywords": [
      "noise robustness",
      "robustness",
      "noise",
      "robustness analysis",
      "analysis noise",
      "robustness complex",
      "complex environments",
      "robustness recognition",
      "environments",
      "recognition robustness"
    ],
    "examples": [
      "robustness to increasing noise levels",
      "robust me location detection",
      "low recognition robustness",
      "recognition system robustness",
      "noise robustness enhancement",
      "noise robustness analysis",
      "noise robustness analysis",
      "noise robustness analysis",
      "noise robustness in complex environments",
      "noise robustness in complex environments",
      "robust ger systems",
      "noise robustness in recognition",
      "noisy environment robustness"
    ]
  },
  {
    "topic_id": 103,
    "size": 13,
    "keywords": [
      "affective gap",
      "gap",
      "bridging",
      "gap bridging",
      "bridging affective",
      "gap affective",
      "affective",
      "bridging bridging",
      "misalignment crossdomain",
      "macrotomicro intensity"
    ],
    "examples": [
      "affective gap bridging",
      "affective gap bridging",
      "affective gap bridging",
      "affective gap challenge",
      "cultural knowledge transfer gap",
      "affective gap bridging",
      "affective gap bridging",
      "affective gap bridging",
      "affective gap bridging",
      "bridging the affective gap",
      "macro-to-micro intensity gap",
      "affective space misalignment",
      "cross-domain affective gap"
    ]
  },
  {
    "topic_id": 104,
    "size": 13,
    "keywords": [
      "affective speech",
      "synthesis affective",
      "synthesis",
      "speech analysis",
      "speech synthesis",
      "speech pattern",
      "analysis affective",
      "affective",
      "speech",
      "pattern analysis"
    ],
    "examples": [
      "affective speech synthesis",
      "affective gesture synthesis",
      "affective speech pattern analysis",
      "affective response synthesis",
      "affective speech analysis",
      "affective speech analysis",
      "affective speech model robustness",
      "affective speech synthesis",
      "affective speech synthesis",
      "speech-based affective computing",
      "affective speech analysis",
      "sound healing analysis",
      "gender-specific speech pattern analysis"
    ]
  },
  {
    "topic_id": 105,
    "size": 13,
    "keywords": [
      "subjectindependent",
      "recognition subjectindependent",
      "subjectindependent emotion",
      "subjectindependent eeg",
      "subjectdependent emotion",
      "subjectdependent",
      "recognition subjectdependent",
      "eeg emotion",
      "eeg",
      "person independent"
    ],
    "examples": [
      "person independent emotion recognition",
      "subject-independent eeg emotion recognition",
      "subject-independent eeg emotion recognition",
      "subject-independent emotion recognition",
      "subject-independent emotion classification",
      "subject-independent emotion recognition",
      "subject-independent emotion recognition",
      "subject-dependent emotion recognition",
      "subject-dependent emotion recognition",
      "subject-independent emotion recognition",
      "subject-independent emotion recognition",
      "subject-independent eeg emotion recognition",
      "subject-independent eeg emotion recognition"
    ]
  },
  {
    "topic_id": 106,
    "size": 13,
    "keywords": [
      "computing",
      "affective computing",
      "computing integration",
      "computing design",
      "affective",
      "integration affective",
      "realworld affective",
      "realworld",
      "design",
      "deployment affective"
    ],
    "examples": [
      "affective human computer interaction",
      "affective computing research scope",
      "affective computing integration",
      "affective computing foundation",
      "identity-free affective computing",
      "large-scale affective computing deployment",
      "affective computing integration",
      "affective computing challenges",
      "real-world affective computing",
      "real-world affective computing",
      "affective computing system design",
      "affective computing system design",
      "human-pet affective communication"
    ]
  },
  {
    "topic_id": 107,
    "size": 13,
    "keywords": [
      "emotional valence",
      "valence",
      "stimulus",
      "valence assessment",
      "effect child",
      "valencebased",
      "attentional bias",
      "attention valence",
      "valence modulation",
      "valence effect"
    ],
    "examples": [
      "affective stimulus devaluation",
      "stimulus valence difference",
      "emotional valence effects on attention",
      "valence congruency effects",
      "emotional valence processing mechanisms",
      "emotional valence judgment",
      "neutral object valence acquisition",
      "emotional valence effect",
      "child emotional valence induction",
      "valence modulation in word processing",
      "valence-based attentional bias",
      "positive and negative valence differentiation",
      "emotional valence assessment"
    ]
  },
  {
    "topic_id": 108,
    "size": 13,
    "keywords": [
      "eeg based",
      "based emotion",
      "based",
      "recognition eeg",
      "eeg",
      "tracking eegbased",
      "computing eeg",
      "eye tracking",
      "eeg eye",
      "imagebased eeg"
    ],
    "examples": [
      "eeg signal based emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "image-based eeg emotion recognition",
      "eeg based emotion recognition",
      "eeg based emotion recognition",
      "eeg and eye tracking",
      "eeg-based affective computing",
      "eeg based emotion recognition"
    ]
  },
  {
    "topic_id": 109,
    "size": 13,
    "keywords": [
      "macroexpression",
      "expression analysis",
      "viewindependent expression",
      "intertwined",
      "expression scenarios",
      "macroexpression spotting",
      "viewindependent",
      "intertwined expression",
      "analysis macroexpression",
      "scenarios"
    ],
    "examples": [
      "pose invariant expression analysis",
      "automatic versus controlled expression analysis",
      "macroexpression processing differences",
      "view-independent expression analysis",
      "view-independent expression analysis",
      "pose-invariant expression analysis",
      "intertwined expression scenarios",
      "intertwined expression scenarios",
      "macro-expression spotting",
      "expression context inconsistency detection",
      "variable expression intensity handling",
      "real-world expression analysis",
      "macro-expression spotting"
    ]
  },
  {
    "topic_id": 110,
    "size": 13,
    "keywords": [
      "continuous dimensional",
      "timecontinuous",
      "timecontinuous emotion",
      "prediction timecontinuous",
      "dimensional emotion",
      "emotion prediction",
      "dimensional",
      "continuous",
      "recognition continuous",
      "prediction continuous"
    ],
    "examples": [
      "continuous dimensional emotion prediction",
      "continuous dimensional emotion recognition",
      "continuous dimensional emotion prediction",
      "continuous dimensional emotion prediction",
      "continuous dimensional emotion recognition",
      "continuous dimensional emotion recognition",
      "continuous dimensional emotion recognition",
      "continuous mimicked emotion prediction",
      "time-continuous emotion prediction",
      "time-continuous emotion prediction",
      "time-continuous emotion prediction",
      "time-continuous affect recognition",
      "time-continuous emotion recognition"
    ]
  },
  {
    "topic_id": 111,
    "size": 12,
    "keywords": [
      "semisupervised",
      "unseen emotion",
      "unseen",
      "classification unseen",
      "unsupervised emotion",
      "semisupervised emotion",
      "supervised emotion",
      "recognition semisupervised",
      "classification tasks",
      "unsupervised"
    ],
    "examples": [
      "unsupervised emotion classification",
      "unseen emotion classification",
      "semi-supervised emotion analysis",
      "unseen emotion classification",
      "unseen emotion classification",
      "supervised emotion classification tasks",
      "supervised emotion classification tasks",
      "unsupervised emotion class prediction",
      "unsupervised speech emotion recognition",
      "semi-supervised learning",
      "semi-supervised emotion recognition",
      "semi-supervised sentiment recognition"
    ]
  },
  {
    "topic_id": 112,
    "size": 12,
    "keywords": [
      "bimodal emotion",
      "bimodal",
      "recognition bimodal",
      "multimodal speech",
      "openvocabulary multimodal",
      "uncertaintyaware",
      "uncertaintyaware multimodal",
      "recognition uncertaintyaware",
      "recognition multimodal",
      "recognition openvocabulary"
    ],
    "examples": [
      "bimodal emotion recognition",
      "bimodal emotion recognition",
      "bimodal emotion recognition",
      "bimodal emotion recognition",
      "multi-modal emotion recognition",
      "multi-modal emotion recognition",
      "multimodal speech emotion recognition",
      "uncertainty-aware multimodal emotion recognition",
      "multi-modal speech emotion recognition",
      "bimodal emotion recognition",
      "bimodal emotion recognition",
      "open-vocabulary multimodal emotion recognition"
    ]
  },
  {
    "topic_id": 113,
    "size": 12,
    "keywords": [
      "personalized",
      "personalized emotional",
      "recognition personalized",
      "personalized emotion",
      "representation personalized",
      "emotional representation",
      "expression personalized",
      "data privacypreserving",
      "preservation emotion",
      "monitoring personalized"
    ],
    "examples": [
      "personalized emotion recognition",
      "personalized emotion recognition",
      "personalized emotion recognition",
      "personalized emotion recognition",
      "personal music emotion recognition",
      "personalized emotional expression",
      "personalized emotional state monitoring",
      "personalized emotional representation",
      "personalized emotional representation",
      "personalized emotion representation",
      "privacy preservation in emotion data",
      "privacy-preserving emotion recognition"
    ]
  },
  {
    "topic_id": 114,
    "size": 12,
    "keywords": [
      "spontaneous emotion",
      "spontaneous",
      "spontaneous affect",
      "elicitation spontaneous",
      "elicitation",
      "emotion elicitation",
      "detection spontaneous",
      "analysis spontaneous",
      "classification spontaneous",
      "analysis sudden"
    ],
    "examples": [
      "spontaneous emotion corpus creation",
      "acted and spontaneous emotion classification",
      "spontaneous communication analysis",
      "spontaneous emotion analysis",
      "spontaneous emotion detection",
      "spontaneous emotion detection",
      "spontaneous affect identification",
      "spontaneous emotion elicitation",
      "spontaneous emotion elicitation",
      "spontaneous affect analysis",
      "sudden moments of inspiration",
      "spontaneous emotion generation"
    ]
  },
  {
    "topic_id": 115,
    "size": 12,
    "keywords": [
      "contextual emotion",
      "contextual",
      "contextaware emotion",
      "conversational context",
      "modeling conversational",
      "contextaware",
      "evolution",
      "context modeling",
      "context",
      "conversational"
    ],
    "examples": [
      "contextual emotion conveyance",
      "contextual emotion detection",
      "context-dependent emotion analysis",
      "contextual emotion estimation",
      "contextual call for help detection",
      "context-aware emotion classification",
      "context-aware emotion classification",
      "contextual emotion representation learning",
      "conversational context modeling",
      "conversational context modeling",
      "conversational emotion context evolution",
      "contextual emotion evolution"
    ]
  },
  {
    "topic_id": 116,
    "size": 12,
    "keywords": [
      "interaction analysis",
      "dyadic",
      "interaction",
      "dyadic interaction",
      "analysis dyadic",
      "social interaction",
      "clinical dialog",
      "dialog",
      "dialog analysis",
      "interaction effects"
    ],
    "examples": [
      "identity-expression interaction effects",
      "expression-identity interaction effects",
      "dyadic interaction analysis",
      "dyadic interaction analysis",
      "dyadic dialogue analysis",
      "dyadic interaction analysis",
      "large group interaction analysis",
      "clinical dialog analysis",
      "clinical dialog analysis",
      "social interaction analysis",
      "social interaction anxiety mechanisms",
      "social interaction analysis"
    ]
  },
  {
    "topic_id": 117,
    "size": 12,
    "keywords": [
      "moral",
      "processing",
      "neural mechanisms",
      "stimuli",
      "emotional stimuli",
      "processing emotional",
      "mechanisms",
      "emotion processing",
      "impact",
      "cortex"
    ],
    "examples": [
      "differential processing of emotional stimuli",
      "emotional stimuli impact",
      "emotion processing brain mechanisms",
      "internal feeling processing",
      "moral behavior prediction",
      "moral emotion mechanism",
      "prefrontal cortex emotion processing",
      "emotional arousal impact",
      "emotion-related brain region identification",
      "embarrassment neural mechanisms",
      "emotional processing neural mechanisms",
      "moral conscience impact"
    ]
  },
  {
    "topic_id": 118,
    "size": 12,
    "keywords": [
      "semantic",
      "logical",
      "logical coherence",
      "coherence",
      "poor",
      "semantic logic",
      "poor logical",
      "semantic feature",
      "logic",
      "semanticsaware"
    ],
    "examples": [
      "semantics-aware dynamic representation",
      "semantics-aware dynamic representation",
      "logical coherence improvement",
      "poor logical coherence",
      "poor logical coherence",
      "semantic understanding deficiency",
      "poor semantic logic",
      "semantic logic improvement",
      "semantic feature separation",
      "affective semantic representation disentanglement",
      "semantic alignment in fer",
      "semantic feature consistency"
    ]
  },
  {
    "topic_id": 119,
    "size": 12,
    "keywords": [
      "microgesture",
      "spontaneous microgesture",
      "microgesture based",
      "analysis microgesture",
      "microgesture analysis",
      "based emotion",
      "based",
      "microgesture recognition",
      "microgesture interpretation",
      "analysis spontaneous"
    ],
    "examples": [
      "spontaneous micro-gesture analysis",
      "spontaneous micro-gesture analysis",
      "spontaneous micro-gesture analysis",
      "micro-gesture based emotion analysis",
      "micro-gesture based emotion analysis",
      "micro-gesture based emotion analysis",
      "spontaneous micro-gesture interpretation",
      "spontaneous micro-gesture recognition",
      "spontaneous micro-gesture interpretation",
      "micro gesture based emotion understanding",
      "micro-gesture recognition",
      "micro-gesture based emotion recognition"
    ]
  },
  {
    "topic_id": 120,
    "size": 12,
    "keywords": [
      "hidden",
      "hidden emotion",
      "interpretation hidden",
      "analysis hidden",
      "hidden emotional",
      "interpretation",
      "state analysis",
      "emotion interpretation",
      "detection hidden",
      "emotional state"
    ],
    "examples": [
      "hidden emotion analysis",
      "hidden emotion detection",
      "hidden emotion interpretation",
      "hidden emotion interpretation",
      "hidden emotion interpretation",
      "hidden emotional state analysis",
      "hidden emotional state analysis",
      "hidden emotional state analysis",
      "hidden emotion detection",
      "hidden emotion detection",
      "inner feeling interpretation",
      "hidden emotion detection"
    ]
  },
  {
    "topic_id": 121,
    "size": 11,
    "keywords": [
      "correlation modeling",
      "correlation",
      "regional correlation",
      "modeling regional",
      "inter",
      "modeling",
      "regional",
      "intervideo correlation",
      "intramodal",
      "intracue"
    ],
    "examples": [
      "latent correlation modeling among signals",
      "inter- and intra-polarity modeling",
      "inter-video correlation modeling",
      "informative region modeling",
      "frequency domain correlation modeling",
      "intra-modal interaction modeling",
      "complex au correlation modeling",
      "inter- and intra-cue correlation modeling",
      "inter-cue correlation modeling",
      "regional correlation modeling",
      "regional correlation modeling"
    ]
  },
  {
    "topic_id": 122,
    "size": 11,
    "keywords": [
      "affective data",
      "scarcity",
      "scarcity emotion",
      "imbalance affective",
      "dataset scarcity",
      "class imbalance",
      "data scarcity",
      "data",
      "scarcity class",
      "affective dataset"
    ],
    "examples": [
      "affective data representation",
      "multimodal affective data scarcity",
      "data scarcity in affective computing",
      "data scarcity in emotion",
      "data scarcity in emotion",
      "class imbalance in affective data",
      "affective dataset scarcity",
      "emotion dataset scarcity",
      "class imbalance in affective data",
      "affective dataset scarcity",
      "class imbalance in affective data"
    ]
  },
  {
    "topic_id": 123,
    "size": 11,
    "keywords": [
      "annotation",
      "annotation handling",
      "inaccurate annotation",
      "ambiguity handling",
      "handling inaccurate",
      "inaccurate",
      "handling",
      "annotation ambiguity",
      "ambiguity",
      "insufficient annotation"
    ],
    "examples": [
      "annotation ambiguity handling",
      "weak annotation utilization",
      "high annotation cost",
      "expression ambiguity handling",
      "annotation ambiguity handling",
      "insufficient annotation data",
      "noisy annotation handling",
      "inaccurate annotation handling",
      "inaccurate annotation handling",
      "ambiguous expression annotation handling",
      "inaccurate annotation due to fixed labels"
    ]
  },
  {
    "topic_id": 124,
    "size": 11,
    "keywords": [
      "modality",
      "mitigation modality",
      "modality imbalance",
      "contribution",
      "imbalance mitigation",
      "modality contribution",
      "imbalance",
      "unequal modality",
      "unequal",
      "mitigation"
    ],
    "examples": [
      "modality impact on awareness",
      "unequal modality contribution",
      "unequal modality contribution",
      "estimating channel contribution weights",
      "modality contribution analysis",
      "modality heterogeneity mitigation",
      "heterogeneous modality distribution gap",
      "modality imbalance mitigation",
      "modality imbalance mitigation",
      "modality imbalance mitigation",
      "modality bias mitigation"
    ]
  },
  {
    "topic_id": 125,
    "size": 11,
    "keywords": [
      "microexpression database",
      "database",
      "scarcity microexpression",
      "database construction",
      "construction microexpression",
      "microexpression data",
      "construction",
      "scarcity",
      "data scarcity",
      "microexpression"
    ],
    "examples": [
      "micro-expression database scarcity",
      "micro-expression dataset scarcity",
      "micro-expression database construction",
      "micro-expression database construction",
      "micro-expression database construction",
      "micro-expression database construction",
      "micro-expression data scarcity",
      "micro-expression database bias",
      "multimodal micro-expression data scarcity",
      "micro-expression data leakage",
      "micro-expression data scarcity"
    ]
  },
  {
    "topic_id": 126,
    "size": 11,
    "keywords": [
      "image retrieval",
      "retrieval",
      "retrieval task",
      "affective image",
      "image",
      "emotionbased image",
      "task affective",
      "retrieval emotionbased",
      "retrieval affective",
      "emotionbased"
    ],
    "examples": [
      "affective music-image retrieval",
      "affective image retrieval task",
      "emotion-based image search",
      "affective image retrieval task",
      "affective image retrieval",
      "efficient image retrieval",
      "affective image retrieval task",
      "affective image retrieval task",
      "affective image retrieval",
      "emotion-based image retrieval",
      "emotion-based image retrieval task"
    ]
  },
  {
    "topic_id": 127,
    "size": 11,
    "keywords": [
      "ambiguity",
      "ambiguity resolution",
      "resolution",
      "emotional ambiguity",
      "sentiment ambiguity",
      "emotion ambiguity",
      "resolution emotion",
      "ambiguity modeling",
      "ambiguity multimodal",
      "perception ambiguity"
    ],
    "examples": [
      "emotion perception ambiguity modeling",
      "emotion perception ambiguity resolution",
      "emotion ambiguity resolution",
      "emotion ambiguity resolution",
      "multimodal sentiment ambiguity",
      "multimodal sentiment ambiguity",
      "multimodal sentiment ambiguity",
      "emotion label ambiguity",
      "complex emotional ambiguity modeling",
      "emotional ambiguity resolution",
      "emotional ambiguity resolution"
    ]
  },
  {
    "topic_id": 128,
    "size": 10,
    "keywords": [
      "emotional state",
      "state understanding",
      "holistic emotional",
      "holistic",
      "understanding holistic",
      "state",
      "understanding",
      "emotional",
      "detection detecting",
      "detecting emotional"
    ],
    "examples": [
      "emotional state detection",
      "emotional state classification",
      "emotional state dynamics analysis",
      "holistic emotional state understanding",
      "holistic emotional state understanding",
      "holistic emotional state understanding",
      "emotional orientation detection",
      "detecting emotional shift issues",
      "emotional engagement detection",
      "open-vocabulary emotion state description"
    ]
  },
  {
    "topic_id": 129,
    "size": 10,
    "keywords": [
      "negative",
      "negative emotion",
      "emotion impact",
      "negative mood",
      "impact",
      "style mitigation",
      "relief",
      "assessment negative",
      "bereavementrelated",
      "cognition negative"
    ],
    "examples": [
      "negative mood relief",
      "positive emotion reduction",
      "negative mood regulation",
      "negative emotion impact assessment",
      "negative coping style mitigation",
      "negative emotion discrimination impairment",
      "bereavement-related immune alteration",
      "negative emotion impact on cognition",
      "negative emotion impact on filtering",
      "negative emotion alleviation"
    ]
  },
  {
    "topic_id": 130,
    "size": 10,
    "keywords": [
      "dysfunction",
      "emotional dysfunction",
      "adolescent",
      "regulation",
      "emotional dysregulation",
      "adolescent emotional",
      "disorder regulation",
      "characterization adolescent",
      "developmental emotion",
      "deficit characterization"
    ],
    "examples": [
      "emotional self-regulation disturbances",
      "emotional dysfunction mechanisms",
      "ptsd emotional dysfunction",
      "social-emotional deficit characterization",
      "adolescent emotional well-being analysis",
      "taste dysfunction correlation",
      "emotional dysregulation mechanisms",
      "post-stroke emotional disorder regulation",
      "adolescent emotion regulation",
      "developmental emotion risks"
    ]
  },
  {
    "topic_id": 131,
    "size": 10,
    "keywords": [
      "realtime",
      "realtime emotion",
      "detection realtime",
      "performance optimization",
      "optimization realtime",
      "realtime performance",
      "monitoring realtime",
      "emotion monitoring",
      "optimization",
      "negative emotion"
    ],
    "examples": [
      "collective emotion monitoring",
      "real-time negative emotion detection",
      "real-time performance optimization",
      "real-time performance optimization",
      "real-time emotion recognition",
      "emotion arousal state analysis",
      "negative emotion detection",
      "real-time emotion monitoring",
      "real-time emotion recognition",
      "real-time emotion fitting"
    ]
  },
  {
    "topic_id": 132,
    "size": 10,
    "keywords": [
      "quantification",
      "quantification microexpression",
      "microexpression quantification",
      "microexpression",
      "difficulty microexpression",
      "duration measurement",
      "microexpression duration",
      "microexpression characteristic",
      "annotation microexpression",
      "characteristic validation"
    ],
    "examples": [
      "micro-expression duration measurement",
      "micro-expression quantification",
      "micro-expression quantification",
      "micro-expression quantification",
      "micro-expression intensity quantification",
      "micro-expression characteristic validation",
      "micro-expression annotation difficulty",
      "micro-expression data annotation",
      "micro-expression quantification",
      "micro-expression quantification"
    ]
  }
]

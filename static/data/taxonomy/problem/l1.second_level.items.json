[
  {
    "l2_name": "4D Facial Expression Recognition",
    "definition": "The automated analysis and classification of dynamic facial expressions and affective states using time-sequenced three-dimensional data.",
    "aliases": [
      "4d facial recognition",
      "3d/4d facial expression recognition",
      "4d facial affect recognition",
      "3d4d facial expression recognition",
      "dynamic 3d facial expression recognition",
      "spatiotemporal facial expression analysis"
    ],
    "topic_ids": [
      99
    ]
  },
  {
    "l2_name": "Affective Computing",
    "definition": "The study and development of systems and devices that can recognize, interpret, process, and simulate human affects.",
    "aliases": [
      "Emotion AI",
      "Affective HCI",
      "Computational Emotion Analysis",
      "Affective Human-Computer Interaction",
      "Real-world Affective Computing"
    ],
    "topic_ids": [
      106
    ]
  },
  {
    "l2_name": "Affective Data Scarcity",
    "definition": "The challenge of insufficient quantity or imbalanced distribution of labeled data available for training and evaluating affective computing models.",
    "aliases": [
      "emotion dataset scarcity",
      "class imbalance in affective data",
      "data scarcity in affective computing",
      "data scarcity in emotion",
      "multimodal affective data scarcity",
      "affective dataset scarcity",
      "imbalance affective",
      "dataset scarcity",
      "scarcity class",
      "scarcity emotion"
    ],
    "topic_ids": [
      122
    ]
  },
  {
    "l2_name": "Affective Dynamics",
    "definition": "The study of how emotional states, processes, and content influence, interact with, and are modeled within problem-solving and learning contexts.",
    "aliases": [
      "affective learning",
      "modeling affective",
      "affective impact",
      "analysis affective",
      "impact affective",
      "affective dynamics",
      "effects affective",
      "identification affective",
      "affective content",
      "affective-cognitive interdependence",
      "affective response",
      "affective priming"
    ],
    "topic_ids": [
      14
    ]
  },
  {
    "l2_name": "Affective Gap Bridging",
    "definition": "The challenge of resolving misalignments in emotional intensity and representation between different domains or scales, such as macro-to-micro transitions.",
    "aliases": [
      "affective gap",
      "gap bridging",
      "bridging affective gap",
      "affective space misalignment",
      "macro-to-micro intensity gap",
      "cross-domain affective misalignment",
      "emotional gap bridging"
    ],
    "topic_ids": [
      103
    ]
  },
  {
    "l2_name": "Affective Image Analysis",
    "definition": "The computational problem of identifying, classifying, and mapping emotional patterns and regions within visual data.",
    "aliases": [
      "affective pattern recognition",
      "affective image classification",
      "affective region discovery",
      "affective trait mapping",
      "emotion recognition in images",
      "visual affect analysis"
    ],
    "topic_ids": [
      43
    ]
  },
  {
    "l2_name": "Affective Image Retrieval",
    "definition": "The task of retrieving images from a database based on the emotional content or affective response they evoke in users.",
    "aliases": [
      "emotion-based image retrieval",
      "affective image search",
      "emotion-based image search",
      "image retrieval by emotion",
      "affective retrieval",
      "emotion-driven image retrieval"
    ],
    "topic_ids": [
      126
    ]
  },
  {
    "l2_name": "Affective Speech Processing",
    "definition": "The computational analysis and synthesis of speech signals to detect, interpret, and generate emotional content and patterns.",
    "aliases": [
      "affective speech analysis",
      "affective speech synthesis",
      "speech-based affective computing",
      "emotional speech processing",
      "affective pattern analysis",
      "emotion recognition in speech",
      "emotional speech synthesis"
    ],
    "topic_ids": [
      104
    ]
  },
  {
    "l2_name": "Affective State Classification",
    "definition": "The computational task of identifying and categorizing human emotional states from various signals such as speech, text, or physiological data.",
    "aliases": [
      "affective state assessment",
      "emotion classification",
      "affective signal classification",
      "state classification",
      "affective speaker state classification",
      "real-time affective state classification"
    ],
    "topic_ids": [
      54
    ]
  },
  {
    "l2_name": "Affective State Prediction",
    "definition": "The computational task of estimating or classifying emotional dimensions such as valence, arousal, and dominance from data.",
    "aliases": [
      "valence arousal prediction",
      "arousal valence classification",
      "VAD prediction",
      "emotion dimension estimation",
      "affective computing prediction",
      "valence and arousal modeling"
    ],
    "topic_ids": [
      61
    ]
  },
  {
    "l2_name": "Affective State Recognition",
    "definition": "The computational process of detecting, monitoring, and analyzing human emotional states through behavioral and physiological signals.",
    "aliases": [
      "affect detection",
      "emotion recognition",
      "affective state estimation",
      "user affect measurement",
      "viewer affective state analysis",
      "suppressed affect detection",
      "affective behavior detection",
      "state recognition",
      "affect monitoring"
    ],
    "topic_ids": [
      65
    ]
  },
  {
    "l2_name": "Affective Video Analysis",
    "definition": "The computational study of detecting, recognizing, and classifying emotions within video content or from viewer responses to videos.",
    "aliases": [
      "video-based emotion analysis",
      "affective video classification",
      "video emotion recognition",
      "viewer emotion analysis",
      "emotion-based video classification",
      "affective video recommendation",
      "video-based affective computing"
    ],
    "topic_ids": [
      13
    ]
  },
  {
    "l2_name": "Annotation Quality and Ambiguity",
    "definition": "This topic covers challenges related to inaccurate, insufficient, noisy, or ambiguous annotations and the methods developed to handle or mitigate these issues.",
    "aliases": [
      "annotation ambiguity handling",
      "inaccurate annotation handling",
      "noisy annotation handling",
      "insufficient annotation",
      "weak annotation utilization",
      "high annotation cost",
      "ambiguous expression annotation",
      "fixed label inaccuracy",
      "annotation error mitigation"
    ],
    "topic_ids": [
      123
    ]
  },
  {
    "l2_name": "Audio-Visual Emotion Recognition",
    "definition": "The computational task of identifying and classifying emotional states by analyzing and fusing information from both audio and visual modalities.",
    "aliases": [
      "audiovisual emotion recognition",
      "audio-video emotion recognition",
      "audio-visual affect recognition",
      "multimodal emotion recognition",
      "emotional content recognition",
      "audiovideo emotion analysis",
      "open-vocabulary audiovisual emotion recognition"
    ],
    "topic_ids": [
      45
    ]
  },
  {
    "l2_name": "Autism Spectrum Disorder Assessment",
    "definition": "The evaluation, screening, and analysis of autism spectrum disorder including symptom severity, emotional recognition, social skills, and neural substrates.",
    "aliases": [
      "ASD assessment",
      "autism screening",
      "autistic behavior evaluation",
      "autism severity measurement",
      "early autism detection",
      "ASD diagnosis",
      "autism emotion recognition",
      "social skill assessment for autism"
    ],
    "topic_ids": [
      68
    ]
  },
  {
    "l2_name": "Automatic Depression Level Prediction",
    "definition": "The use of computational methods to automatically detect, assess, or predict the severity level of depression in individuals.",
    "aliases": [
      "automatic depression detection",
      "automatic depression severity prediction",
      "depression level detection",
      "automatic depression assessment",
      "depression severity diagnosis",
      "automatic depression level assessment",
      "daily depression score prediction"
    ],
    "topic_ids": [
      70
    ]
  },
  {
    "l2_name": "Brain Connectivity Analysis",
    "definition": "The computational and statistical modeling of functional and structural interactions between brain regions to characterize neural dynamics and connectivity patterns.",
    "aliases": [
      "functional connectivity",
      "brain connectivity",
      "connectivity modeling",
      "connectivity analysis",
      "brain dynamics",
      "functional connection modeling",
      "abnormal brain information interaction",
      "brain region abstraction"
    ],
    "topic_ids": [
      67
    ]
  },
  {
    "l2_name": "Contextual Emotion Modeling",
    "definition": "The computational task of detecting, classifying, or representing emotions by leveraging conversational and situational context to resolve ambiguity and track emotional evolution.",
    "aliases": [
      "context-aware emotion analysis",
      "context-dependent emotion detection",
      "conversational context modeling",
      "contextual emotion estimation",
      "contextual emotion representation learning",
      "conversational emotion context evolution",
      "context-aware emotion classification",
      "contextual emotion conveyance"
    ],
    "topic_ids": [
      115
    ]
  },
  {
    "l2_name": "Continuous Dimensional Emotion Prediction",
    "definition": "The task of predicting emotion states as continuous values along dimensional axes (such as valence and arousal) over a time-continuous sequence.",
    "aliases": [
      "time-continuous emotion prediction",
      "continuous dimensional emotion recognition",
      "dimensional emotion prediction",
      "time-continuous affect recognition",
      "continuous emotion prediction",
      "dimensional affect prediction"
    ],
    "topic_ids": [
      110
    ]
  },
  {
    "l2_name": "Continuous Emotion Prediction",
    "definition": "The task of predicting emotional states as continuous values or distributions over time rather than discrete categories.",
    "aliases": [
      "continuous affect prediction",
      "continuous emotion distribution prediction",
      "emotion distribution prediction",
      "friendliness degree prediction",
      "continuous emotion recognition",
      "dimensional emotion prediction"
    ],
    "topic_ids": [
      63
    ]
  },
  {
    "l2_name": "Continuous Emotion Recognition",
    "definition": "The computational task of estimating emotional states as continuous values along dimensional scales such as valence and arousal over time.",
    "aliases": [
      "continuous emotion estimation",
      "dimensional emotion recognition",
      "continuous affect estimation",
      "continuous emotion dimension modeling",
      "continuous emotion state modeling",
      "joint emotion intent recognition"
    ],
    "topic_ids": [
      32
    ]
  },
  {
    "l2_name": "Conversational Emotion Recognition",
    "definition": "The computational task of detecting, analyzing, and correcting emotional states within multi-turn dialogues or conversational contexts.",
    "aliases": [
      "ERC",
      "affective dialogue analysis",
      "conversation emotion recognition",
      "conversational affect recognition",
      "conversational emotion analysis",
      "conversational emotion detection",
      "conversational emotion recognition task",
      "dialogical emotion recognition",
      "dialogue emotion correction",
      "emotion detection in conversation",
      "emotion recognition from noisy speech",
      "emotion recognition in conversation",
      "emotion recognition in conversations",
      "multi-party emotion recognition"
    ],
    "topic_ids": [
      62,
      94
    ]
  },
  {
    "l2_name": "Correlation Modeling",
    "definition": "The computational process of capturing and leveraging statistical dependencies within and across different modalities, cues, regions, or signals to enhance representation learning.",
    "aliases": [
      "correlation modeling",
      "regional correlation modeling",
      "inter-video correlation modeling",
      "intra-modal interaction modeling",
      "inter-cue correlation modeling",
      "latent correlation modeling",
      "frequency domain correlation modeling",
      "inter- and intra-polarity modeling",
      "complex au correlation modeling",
      "informative region modeling"
    ],
    "topic_ids": [
      121
    ]
  },
  {
    "l2_name": "Cross-Corpus Speech Emotion Recognition",
    "definition": "The task of training and evaluating speech emotion recognition models across different datasets to address domain mismatch and improve generalization.",
    "aliases": [
      "cross-corpus SER",
      "cross-corpus emotion recognition",
      "cross-dataset speech emotion recognition",
      "domain adaptation for SER",
      "source-free cross-corpus SER"
    ],
    "topic_ids": [
      28
    ]
  },
  {
    "l2_name": "Cross-Cultural Emotion Recognition",
    "definition": "The study and development of methods to identify, measure, and analyze human emotions across different cultural and linguistic contexts.",
    "aliases": [
      "cross-cultural emotion perception",
      "cross-cultural sentiment analysis",
      "cross-language emotion recognition",
      "cross-culture validity assessment",
      "culture-independent emotion elicitation",
      "cross-cultural affective engagement",
      "cross-cultural continuous emotion recognition"
    ],
    "topic_ids": [
      33
    ]
  },
  {
    "l2_name": "Cross-Database Expression Recognition",
    "definition": "The task of recognizing facial or micro-expressions where the training and testing data originate from different databases or domains to evaluate generalization capability.",
    "aliases": [
      "cross-database facial expression recognition",
      "cross-database micro-expression recognition",
      "cross-domain expression recognition",
      "cross-pose facial expression recognition",
      "unsupervised cross-database expression recognition",
      "cross-database performance validation",
      "crossdatabase recognition",
      "crossdomain facial recognition"
    ],
    "topic_ids": [
      23
    ]
  },
  {
    "l2_name": "Cross-Domain Emotion Recognition",
    "definition": "The task of identifying and classifying emotional states from speech or text data when the training and testing domains differ in terms of speakers, languages, recording conditions, or contexts.",
    "aliases": [
      "cross-domain emotion classification",
      "cross-domain emotion adaptation",
      "cross-domain sentiment detection",
      "domain-specific emotion detection",
      "cross-domain emotion analysis",
      "cross-domain emotional feature learning",
      "cross-domain sentiment alignment",
      "interdisciplinary emotion analysis",
      "cross-speaker emotion recognition",
      "crossdomain emotion recognition",
      "crossdomain speech emotion analysis"
    ],
    "topic_ids": [
      15
    ]
  },
  {
    "l2_name": "Cross-Domain Generalization",
    "definition": "The challenge of maintaining model performance when applied to unseen domains, subjects, or datasets that differ from the training distribution.",
    "aliases": [
      "domain generalization",
      "cross-dataset generalization",
      "unseen subject generalization",
      "generalization to unseen conditions",
      "cross-domain gap",
      "subject generalization",
      "generalization challenge"
    ],
    "topic_ids": [
      86
    ]
  },
  {
    "l2_name": "Cross-Modal Interaction Inefficiency",
    "definition": "The problem of suboptimal alignment and ineffective feature fusion between different modalities that hinders accurate semantic understanding and emotion recognition.",
    "aliases": [
      "crossmodal interaction inefficiency",
      "semantic misalignment",
      "inefficient cross-modal interaction",
      "cross-modal feature misalignment",
      "multimodal interaction limitations",
      "crossmodal semantic gap"
    ],
    "topic_ids": [
      57
    ]
  },
  {
    "l2_name": "Cross-Subject EEG Emotion Recognition",
    "definition": "The problem of recognizing human emotions from EEG signals by training models on data from one set of subjects and testing on unseen subjects to ensure generalization across individuals.",
    "aliases": [
      "cross-subject emotion recognition",
      "inter-subject emotion recognition",
      "multi-subject emotion recognition",
      "cross-subject EEG",
      "intersubject generalization",
      "cross-subject affective computing",
      "subject-independent emotion recognition"
    ],
    "topic_ids": [
      93
    ]
  },
  {
    "l2_name": "Data Limitation in Deep Learning",
    "definition": "The challenge where deep learning models suffer from performance degradation or inefficiency due to insufficient, poor-quality, or imbalanced training data.",
    "aliases": [
      "data scarcity in deep learning",
      "limited training data",
      "data insufficiency",
      "small data problem",
      "data limitation",
      "learning data limitation",
      "deep learning data constraints"
    ],
    "topic_ids": [
      89
    ]
  },
  {
    "l2_name": "Data Scarcity",
    "definition": "The challenge of developing effective machine learning models when the availability of labeled training data is insufficient or severely limited.",
    "aliases": [
      "limited labeled data",
      "labeled data scarcity",
      "data scarcity",
      "supervised data scarcity",
      "lack of labeled data",
      "limited training data",
      "low-resource scenario",
      "limited annotated data"
    ],
    "topic_ids": [
      19
    ]
  },
  {
    "l2_name": "Depression Detection",
    "definition": "The computational task of identifying depressive states or disorders using data modalities such as EEG, interviews, or behavioral signals.",
    "aliases": [
      "depression recognition",
      "depressive state detection",
      "depression diagnosis",
      "EEG-based depression detection",
      "depression state extraction",
      "clinical depression detection"
    ],
    "topic_ids": [
      42
    ]
  },
  {
    "l2_name": "Depression Severity Assessment",
    "definition": "The evaluation, measurement, and prediction of the intensity of depressive symptoms and their correlation with clinical outcomes.",
    "aliases": [
      "depression severity estimation",
      "depression severity measurement",
      "depression severity prediction",
      "assessment of depression severity",
      "estimation of depression severity",
      "prediction of depression severity",
      "depression scale prediction",
      "clinical symptom severity correlation",
      "severity of depression"
    ],
    "topic_ids": [
      41
    ]
  },
  {
    "l2_name": "Dimensional Emotion Recognition",
    "definition": "The computational task of modeling and detecting human emotions using continuous dimensional scales such as valence, arousal, and dominance rather than discrete categories.",
    "aliases": [
      "dimensional emotion analysis",
      "dimensional emotion modeling",
      "dimensional emotion estimation",
      "dimensional emotion scoring",
      "continuous emotion recognition",
      "dimensional speech emotion recognition",
      "dimensional image emotion analysis"
    ],
    "topic_ids": [
      85
    ]
  },
  {
    "l2_name": "Domain Shift in Emotion Analysis",
    "definition": "The challenge of performance degradation in affective computing models when training and testing data originate from different distributions, such as varying cultures, sensors, or environmental conditions.",
    "aliases": [
      "domain shift",
      "domain mismatch",
      "cross-domain emotion analysis",
      "adaptive domain shift",
      "shift in affective data",
      "data domain shift",
      "cross-cultural domain shift"
    ],
    "topic_ids": [
      97
    ]
  },
  {
    "l2_name": "Domain Shift Mitigation",
    "definition": "Techniques designed to address distribution mismatches between source and target domains to improve model generalization and reduce generic responses.",
    "aliases": [
      "domain shift",
      "source-target domain mismatch",
      "distribution mismatch mitigation",
      "domain distribution mismatch",
      "culture influence mitigation",
      "shift mitigation"
    ],
    "topic_ids": [
      21
    ]
  },
  {
    "l2_name": "Dyadic Interaction Analysis",
    "definition": "The systematic examination of reciprocal behaviors, communication patterns, and mutual influences between two individuals within social or clinical contexts.",
    "aliases": [
      "dyadic interaction",
      "interaction analysis",
      "dyadic dialogue analysis",
      "clinical dialog analysis",
      "social interaction analysis",
      "dialog analysis",
      "analysis dyadic",
      "interaction effects",
      "identity-expression interaction effects",
      "expression-identity interaction effects"
    ],
    "topic_ids": [
      116
    ]
  },
  {
    "l2_name": "Dynamic Emotion Modeling",
    "definition": "The computational representation and simulation of evolving emotional states and their interactions within human-computer or multi-agent systems.",
    "aliases": [
      "dynamic emotion analysis",
      "emotion interaction modeling",
      "cognition-emotion modeling",
      "emotional dynamic simulation",
      "fine-grained emotion modeling"
    ],
    "topic_ids": [
      22
    ]
  },
  {
    "l2_name": "Dynamic Facial Expression Recognition",
    "definition": "The automated analysis and classification of human facial expressions using temporal sequences of video data to capture evolving emotional states.",
    "aliases": [
      "dynamic facial expression recognition",
      "automatic facial expression recognition",
      "dynamic facial expression analysis",
      "dynamic facial pattern analysis",
      "DFER",
      "video-based facial expression recognition",
      "temporal facial expression recognition"
    ],
    "topic_ids": [
      24
    ]
  },
  {
    "l2_name": "EEG Emotion Recognition",
    "definition": "The computational task of identifying and classifying human emotional states from electroencephalogram signals while addressing challenges such as model interpretability, overfitting, and feature granularity.",
    "aliases": [
      "emotion recognition from eeg",
      "eeg-based emotion recognition",
      "eeg emotion classification",
      "interpretable eeg emotion recognition",
      "coarse-grained eeg emotion recognition"
    ],
    "topic_ids": [
      55
    ]
  },
  {
    "l2_name": "EEG-based Emotion Recognition",
    "definition": "The computational task of identifying and classifying human emotional states using electroencephalogram (EEG) signals.",
    "aliases": [
      "EEG and eye tracking for emotion",
      "EEG emotion recognition",
      "EEG signal based emotion recognition",
      "EEG-based affective computing",
      "eeg emotion recognition",
      "eeg-based affect recognition",
      "eegbased emotion recognition",
      "electroencephalogram-based emotion classification",
      "emotion recognition eegbased",
      "emotion recognition using EEG",
      "image-based EEG emotion recognition"
    ],
    "topic_ids": [
      69,
      108
    ]
  },
  {
    "l2_name": "Emotion Classification",
    "definition": "The task of identifying, categorizing, and reasoning about emotional states within data to determine specific emotion labels or causal links.",
    "aliases": [
      "emotion classification task",
      "emotion reasoning",
      "emotion causation discovery",
      "causal link identification",
      "emotion feature evaluation",
      "image emotion perception task",
      "emotion regression",
      "mean emotion extraction",
      "emotion classification challenge"
    ],
    "topic_ids": [
      3
    ]
  },
  {
    "l2_name": "Emotion Distribution Learning",
    "definition": "The task of predicting a probability distribution over discrete emotion categories rather than a single dominant label to capture the ambiguity and subjectivity of emotional perception.",
    "aliases": [
      "emotion distribution prediction",
      "discrete emotion distribution learning",
      "visual emotion distribution learning",
      "image emotion distribution prediction",
      "text emotion distribution learning",
      "distribution learning for emotions",
      "probabilistic emotion recognition"
    ],
    "topic_ids": [
      84
    ]
  },
  {
    "l2_name": "Emotion Recognition",
    "definition": "The computational task of identifying and classifying human emotional states from multimodal inputs such as images, videos, gestures, and contextual uncertainty.",
    "aliases": [
      "Affective Computing",
      "Emotion Detection",
      "Facial Expression Recognition",
      "Gesture-based Emotion Recognition",
      "Multimodal Emotion Recognition",
      "HCI Emotion Analysis"
    ],
    "topic_ids": [
      90
    ]
  },
  {
    "l2_name": "Emotional Ambiguity Resolution",
    "definition": "The computational modeling and disambiguation of conflicting or unclear emotional signals within text, speech, or multimodal data to determine precise sentiment.",
    "aliases": [
      "emotion ambiguity resolution",
      "sentiment ambiguity resolution",
      "emotional ambiguity modeling",
      "ambiguity in emotion perception",
      "multimodal sentiment ambiguity",
      "emotion label ambiguity",
      "resolution of emotional ambiguity"
    ],
    "topic_ids": [
      127
    ]
  },
  {
    "l2_name": "Emotional Conflict Resolution",
    "definition": "The process of identifying, analyzing, and resolving interpersonal or intrapersonal conflicts driven by emotional factors through communication and adaptation strategies.",
    "aliases": [
      "emotional conflict",
      "conflict resolution",
      "emotional conflict control",
      "conflict adaptation",
      "communication difficulties",
      "emotional tradeoff difficulties",
      "collaborative negotiation difficulties"
    ],
    "topic_ids": [
      88
    ]
  },
  {
    "l2_name": "Emotional Conversation Generation",
    "definition": "The task of generating dialogue responses that incorporate specific emotional attributes or provide emotional support and guidance.",
    "aliases": [
      "emotional dialogue generation",
      "emotion-constrained conversation generation",
      "emotion-constrained dialogue generation",
      "emotional guidance generation",
      "emotional editing in dialogue",
      "affective conversation generation",
      "empathetic dialogue generation"
    ],
    "topic_ids": [
      51
    ]
  },
  {
    "l2_name": "Emotional Dysregulation",
    "definition": "Emotional dysregulation refers to the impaired ability to monitor, evaluate, and modify emotional reactions in a manner appropriate to the context, often observed in adolescents and various psychological disorders.",
    "aliases": [
      "emotional dysfunction",
      "emotion regulation deficits",
      "affective dysregulation",
      "emotional self-regulation disturbances",
      "developmental emotion risks",
      "adolescent emotional dysregulation",
      "disorder regulation",
      "social-emotional deficit characterization"
    ],
    "topic_ids": [
      130
    ]
  },
  {
    "l2_name": "Emotional Intensity Estimation",
    "definition": "The computational task of predicting, measuring, or analyzing the magnitude and fluctuation of emotional states and reactions in individuals or groups.",
    "aliases": [
      "emotional intensity prediction",
      "emotion intensity measurement",
      "group emotional intensity analysis",
      "happiness intensity estimation",
      "dimensional emotional state prediction",
      "emotional reaction assessment",
      "intensity estimation",
      "affective intensity prediction"
    ],
    "topic_ids": [
      36
    ]
  },
  {
    "l2_name": "Emotional Memory",
    "definition": "The study of how emotion influences the encoding, consolidation, and retrieval of item and source memory.",
    "aliases": [
      "emotion-memory interaction",
      "emotion effects on memory",
      "emotional memory effects",
      "emotion-induced memory",
      "affective memory"
    ],
    "topic_ids": [
      96
    ]
  },
  {
    "l2_name": "Emotional Modulation",
    "definition": "The process by which emotional states or contexts influence cognitive functions such as attention, perception, and memory.",
    "aliases": [
      "emotion modulation",
      "affective modulation",
      "emotional context effect",
      "emotion-driven attention",
      "contextual sensitivity in affect",
      "emotional modulation of cognition"
    ],
    "topic_ids": [
      83
    ]
  },
  {
    "l2_name": "Emotional State Understanding",
    "definition": "The comprehensive detection, classification, and holistic analysis of an individual's emotional condition and its dynamics.",
    "aliases": [
      "emotional state detection",
      "emotional state classification",
      "holistic emotional state understanding",
      "emotional orientation detection",
      "detecting emotional shift issues",
      "emotional engagement detection",
      "open-vocabulary emotion state description",
      "state understanding",
      "detecting emotional"
    ],
    "topic_ids": [
      128
    ]
  },
  {
    "l2_name": "Emotional Tendency Annotation",
    "definition": "The process of identifying, labeling, and standardizing the directional polarity or subtle nuances of emotions within data, often addressing challenges related to cost and consistency.",
    "aliases": [
      "emotion tendency labeling",
      "emotional tendency judgment",
      "emotion annotation",
      "descriptive emotion labeling",
      "subtle emotion detection",
      "unified emotion annotation",
      "emotion tendency mining"
    ],
    "topic_ids": [
      44
    ]
  },
  {
    "l2_name": "Emotional Valence",
    "definition": "The intrinsic attractiveness or averseness of a stimulus that modulates cognitive processes such as attention, judgment, and memory.",
    "aliases": [
      "valence",
      "affective valence",
      "stimulus valence",
      "emotional tone",
      "valence effect",
      "valence modulation",
      "positive and negative valence"
    ],
    "topic_ids": [
      107
    ]
  },
  {
    "l2_name": "Empathetic Response Generation",
    "definition": "The computational process of generating responses that demonstrate emotional understanding and empathy towards the user.",
    "aliases": [
      "empathetic response",
      "emotional response generation",
      "affective response generation",
      "emotion-aware response",
      "empathy in dialogue"
    ],
    "topic_ids": [
      60
    ]
  },
  {
    "l2_name": "Facial Action Unit Detection",
    "definition": "The automated identification and localization of specific facial muscle movements known as Action Units, including micro-expressions and intensity estimation, from visual data.",
    "aliases": [
      "AU detection",
      "facial action unit recognition",
      "action unit detection",
      "micro-expression action unit detection",
      "3D facial action unit detection",
      "cross-pose action unit detection",
      "facial action unit intensity estimation",
      "unit detection",
      "detection facial action"
    ],
    "topic_ids": [
      12
    ]
  },
  {
    "l2_name": "Facial Expression Analysis",
    "definition": "The computational or psychological study of detecting, interpreting, and decoding human facial movements, including involuntary reactions and emotional states.",
    "aliases": [
      "analysis facial",
      "angry expression effect",
      "effect facial",
      "ensemble coding of facial expressions",
      "expression analysis",
      "expression coding",
      "expression confusion",
      "expression recognition",
      "facial emotion analysis",
      "facial expression analysis",
      "facial expression categorization",
      "facial expression classification",
      "facial expression decoding",
      "facial expression detection",
      "facial expression identification",
      "facial expression processing",
      "facial expression self-awareness",
      "gaze and expression interaction",
      "involuntary facial expression analysis"
    ],
    "topic_ids": [
      40,
      48
    ]
  },
  {
    "l2_name": "Facial Expression Recognition",
    "definition": "The computational process of automatically identifying and classifying human emotional states from facial images or video sequences.",
    "aliases": [
      "FER",
      "expression recognition",
      "facial emotion recognition",
      "facial expression analysis",
      "facial expression recognition",
      "facial micro-expression recognition",
      "masked facial expression recognition",
      "micro-expression recognition",
      "unsupervised facial expression recognition"
    ],
    "topic_ids": [
      6,
      25
    ]
  },
  {
    "l2_name": "Facial Processing",
    "definition": "The cognitive and computational mechanisms involved in perceiving, analyzing, and interpreting facial identity, emotions, and actions.",
    "aliases": [
      "Face Processing",
      "Facial Analysis",
      "Face Recognition",
      "Facial Emotion Recognition",
      "Facial Identity Processing",
      "Face-based Emotion Analysis"
    ],
    "topic_ids": [
      11
    ]
  },
  {
    "l2_name": "Feature Distribution Mismatch",
    "definition": "The problem arising from inconsistencies or discrepancies in the statistical distribution of features between different datasets or domains.",
    "aliases": [
      "feature distribution discrepancy",
      "distribution mismatch",
      "feature distribution inconsistency",
      "distribution discrepancy",
      "feature distribution gap",
      "mismatch feature",
      "inconsistency feature",
      "feature matching problem"
    ],
    "topic_ids": [
      53
    ]
  },
  {
    "l2_name": "Feature Selection and Extraction",
    "definition": "The process of identifying, generating, and reducing discriminative acoustic or emotional features to mitigate high dimensionality and improve representation quality.",
    "aliases": [
      "feature extraction",
      "feature selection",
      "discriminative feature selection",
      "acoustic feature extraction",
      "emotional feature selection",
      "feature representation generation",
      "high-dimensional feature reduction",
      "curse of dimensionality mitigation"
    ],
    "topic_ids": [
      4
    ]
  },
  {
    "l2_name": "Fine-Grained Emotion Analysis",
    "definition": "The computational task of identifying, classifying, or extracting specific and nuanced emotional states, sentiments, or facial features beyond basic categories.",
    "aliases": [
      "fine-grained sentiment analysis",
      "fine-grained emotion detection",
      "fine-grained emotion classification",
      "fine-grained sentiment polarity detection",
      "fine-grained emotional tagging",
      "fine-grained facial feature capture",
      "fine-grained emotion element extraction",
      "fine-grained word classification",
      "FGEA",
      "granular emotion recognition"
    ],
    "topic_ids": [
      34
    ]
  },
  {
    "l2_name": "Genuine Emotion Detection",
    "definition": "The computational task of identifying and distinguishing authentic emotional expressions from concealed or fabricated ones at both individual and group levels.",
    "aliases": [
      "genuine emotion recognition",
      "detection of genuine emotion",
      "emotion concealment detection",
      "concealment detection",
      "group-level emotion recognition",
      "genuine affect detection",
      "fake emotion detection"
    ],
    "topic_ids": [
      27
    ]
  },
  {
    "l2_name": "Hidden Emotion Analysis",
    "definition": "The computational detection, interpretation, and analysis of concealed or unexpressed emotional states from behavioral or textual cues.",
    "aliases": [
      "hidden emotion detection",
      "hidden emotion interpretation",
      "hidden emotional state analysis",
      "inner feeling interpretation",
      "concealed emotion analysis",
      "latent emotion detection"
    ],
    "topic_ids": [
      120
    ]
  },
  {
    "l2_name": "Humor Detection",
    "definition": "The computational task of automatically identifying and classifying humorous content, including sarcasm and cross-cultural variations, often across multimodal data.",
    "aliases": [
      "humor detection task",
      "sarcasm detection",
      "cross-cultural humor detection",
      "multimodal humor detection",
      "humour detection",
      "sarcasm identification",
      "computational humor"
    ],
    "topic_ids": [
      75
    ]
  },
  {
    "l2_name": "Image Emotion Classification",
    "definition": "The task of automatically identifying and categorizing the emotional content or affective states evoked by images.",
    "aliases": [
      "image emotion recognition",
      "emotion classification",
      "social image emotion classification",
      "basic emotion classification",
      "emotion pattern classification",
      "automatic user emotion estimation",
      "human emotion recognition",
      "crowd emotion matching",
      "image emotion regression"
    ],
    "topic_ids": [
      20
    ]
  },
  {
    "l2_name": "In-the-Wild Emotion Recognition",
    "definition": "The task of detecting and classifying human emotions or affective states from facial expressions and behaviors captured in uncontrolled, real-world environments.",
    "aliases": [
      "emotion recognition in the wild",
      "in-the-wild affect recognition",
      "wild emotion analysis",
      "in-the-wild facial behavior analysis",
      "expression recognition in the wild",
      "in-the-wild affect prediction",
      "wild environment emotion detection"
    ],
    "topic_ids": [
      39
    ]
  },
  {
    "l2_name": "Individual Difference Modeling",
    "definition": "The challenge of accounting for and mitigating variations among individuals in the modeling, deployment, and practical application of intelligent systems.",
    "aliases": [
      "individual difference mitigation",
      "modeling individual differences",
      "individual variation modeling",
      "atypical individual analysis",
      "individual difference overfitting",
      "expression appearance variation modeling",
      "viewpoint variation effects",
      "individual intensity variation"
    ],
    "topic_ids": [
      30
    ]
  },
  {
    "l2_name": "Macroexpression Analysis",
    "definition": "The computational study of detecting, spotting, and analyzing full-blown facial expressions under challenging real-world conditions such as pose variations, intertwined scenarios, and view independence.",
    "aliases": [
      "macro-expression analysis",
      "macroexpression spotting",
      "view-independent expression analysis",
      "pose-invariant expression analysis",
      "intertwined expression scenarios",
      "automatic macroexpression detection",
      "real-world expression analysis"
    ],
    "topic_ids": [
      109
    ]
  },
  {
    "l2_name": "Major Depressive Disorder",
    "definition": "A clinical condition characterized by persistent low mood, loss of interest, and significant impairment in daily functioning due to underlying pathophysiological mechanisms.",
    "aliases": [
      "MDD",
      "major depression",
      "clinical depression",
      "unipolar depression",
      "depressive disorder",
      "major depressive episode"
    ],
    "topic_ids": [
      74
    ]
  },
  {
    "l2_name": "Mental Health Assessment",
    "definition": "The systematic evaluation of an individual's psychological state, emotional distress, and mental health risks to inform personalized support and intervention strategies.",
    "aliases": [
      "mental health assessment",
      "psychological assessment",
      "mental status evaluation",
      "emotional distress screening",
      "mental health risk assessment",
      "personalized mental health evaluation",
      "dynamic psychological assessment",
      "mental health monitoring"
    ],
    "topic_ids": [
      16
    ]
  },
  {
    "l2_name": "Micro-expression Database Construction",
    "definition": "The process and challenges associated with creating, curating, and expanding datasets of micro-expressions to address issues of data scarcity and bias.",
    "aliases": [
      "microexpression database construction",
      "micro-expression dataset creation",
      "microexpression data collection",
      "database construction for micro-expressions",
      "micro-expression corpus building",
      "addressing micro-expression data scarcity",
      "micro-expression dataset scarcity"
    ],
    "topic_ids": [
      125
    ]
  },
  {
    "l2_name": "Micro-expression Detection",
    "definition": "The automated identification and analysis of brief, involuntary facial expressions that reveal concealed emotions.",
    "aliases": [
      "automatic microexpression detection",
      "microexpression analysis",
      "micro-expression recognition",
      "ME detection",
      "microexpression feature extraction",
      "automatic micro-expression analysis"
    ],
    "topic_ids": [
      76
    ]
  },
  {
    "l2_name": "Micro-expression Recognition",
    "definition": "The computational task of automatically detecting and classifying fleeting, involuntary facial expressions that reveal concealed emotions.",
    "aliases": [
      "microexpression recognition",
      "micro-expression classification",
      "microexpression classification",
      "MER",
      "micro-expression detection",
      "microexpression detection",
      "recognition of micro-expressions",
      "micro-expression recognition task",
      "microexpression recognition task"
    ],
    "topic_ids": [
      9
    ]
  },
  {
    "l2_name": "Micro-expression Spotting",
    "definition": "The task of detecting and localizing the temporal intervals of fleeting, involuntary facial micro-expressions within video sequences.",
    "aliases": [
      "expression spotting",
      "expression spotting task",
      "facial expression spotting",
      "facial micro-expression spotting",
      "in-the-wild micro-expression spotting",
      "macro and micro expression spotting",
      "micro-expression interval spotting",
      "micro-expression spotting evaluation",
      "micro-expression spotting task",
      "microexpression spotting",
      "spotting macro",
      "spotting microexpression",
      "spotting task",
      "sub-second interval perception",
      "task facial expression",
      "task microexpression"
    ],
    "topic_ids": [
      82,
      95
    ]
  },
  {
    "l2_name": "Microexpression Quantification",
    "definition": "The measurement and validation of microexpression characteristics including duration, intensity, and annotation difficulty.",
    "aliases": [
      "micro-expression quantification",
      "quantification of microexpressions",
      "microexpression duration measurement",
      "microexpression intensity quantification",
      "microexpression characteristic validation",
      "microexpression annotation difficulty",
      "ME quantification"
    ],
    "topic_ids": [
      132
    ]
  },
  {
    "l2_name": "Microexpression Recognition",
    "definition": "The computational or psychological process of detecting, classifying, and analyzing brief, involuntary facial expressions to determine emotional states.",
    "aliases": [
      "micro-expression recognition",
      "microexpression detection",
      "micro-expression detection",
      "facial microexpression analysis",
      "MER",
      "microexpression classification",
      "recognition of microexpressions"
    ],
    "topic_ids": [
      26
    ]
  },
  {
    "l2_name": "Missing Modality Handling",
    "definition": "The process of managing, reconstructing, or adapting to incomplete or absent data modalities within a multimodal system.",
    "aliases": [
      "incomplete modality handling",
      "missing modality reconstruction",
      "modality missing",
      "feature missing",
      "handling uncertain modality absence",
      "random modality feature missing",
      "incomplete modality settings"
    ],
    "topic_ids": [
      101
    ]
  },
  {
    "l2_name": "Modality Imbalance",
    "definition": "The problem where different modalities contribute unequally to model performance, requiring mitigation strategies to balance their impact.",
    "aliases": [
      "modality bias",
      "unequal modality contribution",
      "modality heterogeneity",
      "modality imbalance mitigation",
      "modality contribution imbalance"
    ],
    "topic_ids": [
      124
    ]
  },
  {
    "l2_name": "Modality Robustness",
    "definition": "The capability of a model to maintain reliable performance and accurate predictions across different data modalities despite the presence of noise, outliers, or distributional shifts.",
    "aliases": [
      "robustness to noise",
      "modality-wise robustness",
      "cross-modal robustness",
      "noise robustness",
      "model robustness evaluation",
      "robustness improvement",
      "uncertainty quantification under noise"
    ],
    "topic_ids": [
      87
    ]
  },
  {
    "l2_name": "Multi-label and Multi-class Emotion Classification",
    "definition": "This problem involves assigning one or multiple emotion categories to data instances, potentially including the prediction of emotion intensity levels.",
    "aliases": [
      "multilabel emotion classification",
      "multiclass emotion classification",
      "multi-emotion labeling",
      "multi-emotion state labeling",
      "emotion intensity prediction",
      "multilabel affective classification",
      "multi-class speech emotion recognition",
      "multi-emotion image labeling",
      "three-category emotion recognition"
    ],
    "topic_ids": [
      46
    ]
  },
  {
    "l2_name": "Multi-view Facial Expression Recognition",
    "definition": "The task of identifying and classifying human facial expressions from images or videos captured from multiple or arbitrary camera viewpoints.",
    "aliases": [
      "multi-view expression recognition",
      "multi-view emotion recognition",
      "arbitrary view facial expression recognition",
      "multi-view facial expression analysis",
      "multi-view expression classification",
      "multi-view emotion classification",
      "multiview facial expression recognition",
      "multiview expression analysis"
    ],
    "topic_ids": [
      80
    ]
  },
  {
    "l2_name": "Multichannel EEG Analysis",
    "definition": "The computational processing and interpretation of electroencephalography signals recorded from multiple electrodes to address challenges in feature extraction, channel selection, and individual variability.",
    "aliases": [
      "multichannel eeg",
      "multi-channel eeg",
      "eeg channel analysis",
      "eeg signal processing",
      "multichannel eeg recognition",
      "eeg topology analysis"
    ],
    "topic_ids": [
      56
    ]
  },
  {
    "l2_name": "Multimodal Affect Analysis",
    "definition": "The computational analysis and recognition of human emotional states by integrating and processing multiple data modalities such as audio, visual, and textual signals.",
    "aliases": [
      "multimodal affective computing",
      "multimodal emotion recognition",
      "multi-modal affect analysis",
      "affective signal integration",
      "multiperson affect analysis",
      "multimodal affective behavior analysis",
      "frame-level affect recognition",
      "affect analysis"
    ],
    "topic_ids": [
      35
    ]
  },
  {
    "l2_name": "Multimodal Emotion Analysis",
    "definition": "The computational analysis of human emotions by integrating and processing multiple data modalities such as text, audio, and visual cues from large-scale multimedia datasets.",
    "aliases": [
      "multimodal emotion analysis",
      "multi-modal emotion analysis",
      "multi-factor emotion analysis",
      "multifactorial emotion influence analysis",
      "large-scale heterogeneous multimedia analysis",
      "analysis multimodal",
      "emotion analysis",
      "multifactor emotion"
    ],
    "topic_ids": [
      81
    ]
  },
  {
    "l2_name": "Multimodal Emotion Classification",
    "definition": "The task of identifying and categorizing human emotional states by integrating and analyzing data from multiple modalities such as text, audio, and visual cues.",
    "aliases": [
      "multimodal emotion prediction",
      "multimodal emotion modeling",
      "multimodal emotion state classification",
      "multimodal emotion understanding",
      "multimodal emotion indexing",
      "multi dimensional emotion classification",
      "classification multimodal",
      "multimodal emotion",
      "interpretation multimodal",
      "prediction multimodal",
      "emotion interpretation",
      "emotion understanding",
      "understanding multimodal"
    ],
    "topic_ids": [
      47
    ]
  },
  {
    "l2_name": "Multimodal Emotion Recognition",
    "definition": "The computational task of identifying and classifying human emotional states by integrating and analyzing data from multiple modalities such as text, audio, and visual cues.",
    "aliases": [
      "MER",
      "bimodal emotion recognition",
      "continuous multimodal emotion recognition",
      "emotion recognition multimodal",
      "multi-modal emotion recognition",
      "multimodal affect recognition",
      "multimodal continuous emotion recognition",
      "multimodal emotion estimation",
      "multimodal emotion expression analysis",
      "multimodal emotion inference",
      "multimodal emotion reasoning",
      "multimodal emotion recognition",
      "multimodal emotion recognition task",
      "multimodal speech emotion recognition",
      "multimodal stress estimation",
      "open-vocabulary multimodal emotion recognition",
      "uncertainty-aware multimodal emotion recognition"
    ],
    "topic_ids": [
      17,
      18,
      112
    ]
  },
  {
    "l2_name": "Multimodal Feature Fusion",
    "definition": "The process of integrating complementary information from multiple modalities to overcome single-modality limitations and enhance recognition performance.",
    "aliases": [
      "feature fusion",
      "multimodal feature integration",
      "feature integration",
      "multi-modal information representation",
      "intermediate representation fusion",
      "multi-task feature integration",
      "fusion comparison",
      "high-order feature integration"
    ],
    "topic_ids": [
      78
    ]
  },
  {
    "l2_name": "Multimodal Sentiment Analysis",
    "definition": "The computational task of detecting, extracting, and classifying sentiment or emotion by integrating information from multiple modalities such as text, audio, and visual cues.",
    "aliases": [
      "multimodal sentiment prediction",
      "multimodal sentiment classification",
      "multi-modal sentiment analysis",
      "robust multimodal sentiment analysis",
      "incomplete multimodal sentiment analysis",
      "multimodal news sentiment recognition",
      "multidimensional sentiment classification"
    ],
    "topic_ids": [
      2
    ]
  },
  {
    "l2_name": "Music Emotion Analysis",
    "definition": "The computational study of recognizing, classifying, and generating music based on its emotional content and affective properties.",
    "aliases": [
      "Affective Music Computing",
      "Music Emotion Recognition",
      "Emotion-based Music Classification",
      "Music Mood Analysis",
      "Audio Emotion Detection",
      "Musicalization",
      "Emotional Music Recommendation"
    ],
    "topic_ids": [
      38
    ]
  },
  {
    "l2_name": "Negative Emotion Impact and Regulation",
    "definition": "This topic encompasses the assessment of adverse effects caused by negative emotions on cognition and physiology, as well as strategies for their mitigation, relief, and regulation.",
    "aliases": [
      "negative mood regulation",
      "negative emotion impact assessment",
      "negative coping style mitigation",
      "negative emotion alleviation",
      "negative mood relief",
      "bereavement-related immune alteration",
      "negative emotion discrimination impairment",
      "impact of negative emotions on cognition",
      "negative emotion filtering"
    ],
    "topic_ids": [
      129
    ]
  },
  {
    "l2_name": "Neural Basis of Well-being",
    "definition": "The study of neuroanatomical structures and neural correlates underlying emotional intelligence, social functioning, and various dimensions of psychological well-being.",
    "aliases": [
      "neural basis",
      "neural correlates",
      "neuroanatomical basis",
      "neural basis of emotional intelligence",
      "neural correlates of social well-being",
      "eudaimonic well-being neural correlates",
      "neural basis of emotion",
      "neuroanatomical correlates"
    ],
    "topic_ids": [
      73
    ]
  },
  {
    "l2_name": "Neural Mechanisms of Moral and Emotional Processing",
    "definition": "This topic covers the identification and analysis of brain regions and neural pathways involved in processing emotional stimuli, moral judgments, and related internal feelings.",
    "aliases": [
      "moral emotion mechanism",
      "emotion processing neural mechanisms",
      "differential processing of emotional stimuli",
      "prefrontal cortex emotion processing",
      "neural basis of moral behavior",
      "emotional stimuli impact on brain",
      "embarrassment neural mechanisms",
      "moral conscience neural correlates",
      "brain mechanisms of emotion processing",
      "neural processing of moral stimuli"
    ],
    "topic_ids": [
      117
    ]
  },
  {
    "l2_name": "Noise and Interference Reduction",
    "definition": "The mitigation of unwanted signal artifacts, outliers, and external disturbances such as head movement to improve data quality and classification accuracy.",
    "aliases": [
      "noise reduction",
      "interference mitigation",
      "head movement noise reduction",
      "outlier reduction",
      "movement interference handling",
      "classification noise reduction",
      "signal artifact removal",
      "irrelevant noise filtering"
    ],
    "topic_ids": [
      72
    ]
  },
  {
    "l2_name": "Noise Robustness",
    "definition": "The capability of a system to maintain accurate performance and recognition accuracy despite the presence of noise or operation in complex environments.",
    "aliases": [
      "robustness to noise",
      "noise robustness analysis",
      "recognition robustness",
      "robustness in complex environments",
      "noise tolerance",
      "environmental robustness"
    ],
    "topic_ids": [
      102
    ]
  },
  {
    "l2_name": "Noisy Label Handling",
    "definition": "The study of methods to detect, correct, or robustly train models in the presence of incorrect, missing, or unreliable annotations in datasets.",
    "aliases": [
      "noisy label management",
      "label noise handling",
      "noisy label learning",
      "label noise correction",
      "handling noisy labels",
      "missing label prediction",
      "automatic corpus labeling",
      "inference without gold labels"
    ],
    "topic_ids": [
      79
    ]
  },
  {
    "l2_name": "Perception and Personality Modeling",
    "definition": "The computational modeling and evaluation of human perception, aesthetic judgment, and personality traits along with their mutual influences.",
    "aliases": [
      "aesthetic quality assessment",
      "user perception evaluation",
      "personality influence modeling",
      "personal characteristic modeling",
      "multifactorial emotion perception modeling",
      "personalized aesthetic assessment",
      "user preference modeling",
      "perception evaluation",
      "aesthetic perception modeling"
    ],
    "topic_ids": [
      29
    ]
  },
  {
    "l2_name": "Personality Recognition",
    "definition": "The computational detection and analysis of personality traits and their interplay with emotions, particularly within workplace and social interaction contexts.",
    "aliases": [
      "personality trait detection",
      "personality-aware emotion recognition",
      "personality analysis",
      "workplace personality modeling",
      "emotion-personality integration"
    ],
    "topic_ids": [
      58
    ]
  },
  {
    "l2_name": "Personalized Emotion Perception",
    "definition": "The computational task of predicting or analyzing emotional responses to stimuli, such as images, tailored to the specific characteristics and preferences of individual users.",
    "aliases": [
      "personalized emotion prediction",
      "individual-specific emotion prediction",
      "personalized image emotion perception",
      "personalized image emotion prediction",
      "user-specific emotion analysis",
      "adaptive emotion recognition"
    ],
    "topic_ids": [
      92
    ]
  },
  {
    "l2_name": "Personalized Emotion Recognition",
    "definition": "The development of adaptive systems that identify and interpret individual emotional states while addressing challenges in representation, expression monitoring, and data privacy.",
    "aliases": [
      "personalized emotion recognition",
      "personalized emotional recognition",
      "personal emotion recognition",
      "individualized emotion recognition",
      "user-specific emotion recognition",
      "personalized affective computing",
      "privacy-preserving personalized emotion recognition",
      "personalized emotional state monitoring",
      "personalized emotional representation"
    ],
    "topic_ids": [
      113
    ]
  },
  {
    "l2_name": "Physiological Emotion Recognition",
    "definition": "The computational analysis of physiological signals to detect, classify, and model human emotional states.",
    "aliases": [
      "physiological signal based recognition",
      "psychophysiological emotion modeling",
      "multimodal physiological signal analysis",
      "sentiment classification from physiology",
      "physiological-emotion recognition",
      "biomarker-based emotion detection",
      "physiological signal monitoring"
    ],
    "topic_ids": [
      50
    ]
  },
  {
    "l2_name": "Real-time Emotion Monitoring",
    "definition": "The continuous detection, analysis, and optimization of emotional states, particularly negative emotions, in real-time environments.",
    "aliases": [
      "realtime emotion detection",
      "real-time negative emotion detection",
      "realtime emotion recognition",
      "emotion arousal state analysis",
      "realtime performance optimization",
      "collective emotion monitoring",
      "real-time emotion fitting",
      "emotion monitoring"
    ],
    "topic_ids": [
      131
    ]
  },
  {
    "l2_name": "Semantic Logical Coherence",
    "definition": "The deficiency in maintaining consistent logical relationships and meaningful semantic alignment within dynamic representations or feature structures.",
    "aliases": [
      "poor logical coherence",
      "semantic logic deficiency",
      "semantic feature consistency",
      "semantics-aware representation issues",
      "logical coherence improvement",
      "semantic alignment problems",
      "semantic feature separation",
      "affective semantic disentanglement"
    ],
    "topic_ids": [
      118
    ]
  },
  {
    "l2_name": "Sentiment Analysis",
    "definition": "The computational task of identifying, extracting, and classifying the subjective polarity or emotional orientation expressed in text.",
    "aliases": [
      "Opinion Mining",
      "Sentiment Classification",
      "Semantic Polarity Detection",
      "Sentiment Orientation Analysis",
      "Text Sentiment Analysis"
    ],
    "topic_ids": [
      5
    ]
  },
  {
    "l2_name": "Small Sample Size",
    "definition": "A research limitation arising from the use of a dataset with insufficient observations to ensure statistical power or generalizability.",
    "aliases": [
      "small sample",
      "limited sample size",
      "small-scale dataset",
      "single-source data limitation",
      "single database evaluation",
      "small data sample",
      "dataset size limitation",
      "insufficient sample size"
    ],
    "topic_ids": [
      71
    ]
  },
  {
    "l2_name": "Social Media Sentiment Analysis",
    "definition": "The computational process of identifying, extracting, and classifying emotional expressions and opinions from social media content, with a specific focus on Chinese microblogs.",
    "aliases": [
      "Microblog sentiment analysis",
      "Chinese microblog emotion analysis",
      "Social media emotion detection",
      "Micro-blog sentiment classification",
      "Chinese text emotion detection",
      "Microblogging hot event sentiment",
      "Fragmented Chinese text emotion analysis",
      "Chinese sentiment lexicon construction",
      "Media sentiment analysis",
      "Microblog emotion prediction"
    ],
    "topic_ids": [
      59
    ]
  },
  {
    "l2_name": "Speaker Identity Bias",
    "definition": "The problem of spurious correlations between speaker identity features and target labels that degrade model generalization and fairness.",
    "aliases": [
      "speaker bias",
      "identity bias",
      "speaker identity mismatch",
      "speaker identity distinction",
      "bias mitigation speaker",
      "subject identity bias",
      "spurious speaker bias",
      "speaker-dependent bias"
    ],
    "topic_ids": [
      100
    ]
  },
  {
    "l2_name": "Speech Emotion Recognition",
    "definition": "The computational task of identifying and classifying human emotional states from acoustic speech signals.",
    "aliases": [
      "SER",
      "automatic emotion recognition from speech",
      "emotion detection in speech",
      "emotion recognition in speech",
      "speech emotion classification",
      "speech emotion recognition task",
      "speech-based emotion detection",
      "speech-based emotion recognition"
    ],
    "topic_ids": [
      7,
      49
    ]
  },
  {
    "l2_name": "Speech Emotion Recognition and Synthesis",
    "definition": "This field focuses on the analysis, classification, and generation of emotional content in speech through prosodic modeling and voice conversion techniques.",
    "aliases": [
      "SER",
      "Emotional Speech Processing",
      "Expressive Voice Conversion",
      "Prosody Modeling",
      "Speaker-Independent Emotion Recognition",
      "Emotional Prosody Generation",
      "Expressive Speech Synthesis"
    ],
    "topic_ids": [
      1
    ]
  },
  {
    "l2_name": "Spontaneous Emotion Analysis",
    "definition": "The study and computational processing of naturally occurring emotional expressions, including their elicitation, detection, classification, and corpus creation.",
    "aliases": [
      "spontaneous affect analysis",
      "spontaneous emotion detection",
      "spontaneous emotion classification",
      "spontaneous emotion elicitation",
      "natural emotion analysis",
      "unscripted emotion analysis"
    ],
    "topic_ids": [
      114
    ]
  },
  {
    "l2_name": "Spontaneous Micro-expression Recognition",
    "definition": "The automated detection and classification of involuntary, brief facial expressions that occur naturally in uncontrolled environments.",
    "aliases": [
      "spontaneous microexpression recognition",
      "spontaneous micro-expression detection",
      "spontaneous microexpression analysis",
      "spontaneous facial microexpression recognition",
      "microexpression recognition in spontaneous settings",
      "detection of spontaneous microexpressions"
    ],
    "topic_ids": [
      31
    ]
  },
  {
    "l2_name": "Spontaneous Micro-expression Spotting",
    "definition": "The automated detection and temporal localization of brief, involuntary facial expressions that occur naturally in uncontrolled environments.",
    "aliases": [
      "spontaneous micro-expression spotting",
      "microexpression spotting",
      "spotting spontaneous",
      "spontaneous expression spotting",
      "spontaneous facial behavior analysis",
      "spontaneous versus posed differentiation",
      "integrated spotting"
    ],
    "topic_ids": [
      64
    ]
  },
  {
    "l2_name": "Spontaneous Micro-gesture Analysis",
    "definition": "The computational study and interpretation of involuntary, subtle facial or bodily movements to recognize human emotions and internal states.",
    "aliases": [
      "micro-gesture analysis",
      "spontaneous micro-gesture recognition",
      "micro-gesture based emotion analysis",
      "micro-gesture interpretation",
      "spontaneous micro-gesture understanding",
      "micro-gesture based emotion recognition",
      "analysis of spontaneous micro-gestures"
    ],
    "topic_ids": [
      119
    ]
  },
  {
    "l2_name": "Stress Detection and Recognition",
    "definition": "The computational identification, estimation, and classification of human psychological or emotional stress states using various data modalities.",
    "aliases": [
      "stress state recognition",
      "emotional stress detection",
      "stress estimation",
      "psychological stress analysis",
      "stress state estimation",
      "emotion-based stress detection"
    ],
    "topic_ids": [
      37
    ]
  },
  {
    "l2_name": "Subject-Independent Emotion Recognition",
    "definition": "The task of recognizing human emotions from physiological signals or behavioral cues using models trained on data from individuals other than the target user to ensure generalizability across subjects.",
    "aliases": [
      "person independent emotion recognition",
      "subject-independent eeg emotion recognition",
      "subject-independent emotion classification",
      "cross-subject emotion recognition",
      "user-independent emotion recognition",
      "subject-independent affective computing"
    ],
    "topic_ids": [
      105
    ]
  },
  {
    "l2_name": "Subjective Emotion Modeling",
    "definition": "The computational modeling and analysis of human emotional responses to stimuli while accounting for inherent subjectivity, perception variability, and individual differences.",
    "aliases": [
      "subjective emotion modeling",
      "modeling subjective emotion",
      "subjectivity handling",
      "emotion variability modeling",
      "subjective image emotion modeling",
      "perception subjectivity modeling",
      "subjective evaluation modeling",
      "classification of subjective emotion",
      "holistic perception hypothesis validation"
    ],
    "topic_ids": [
      10
    ]
  },
  {
    "l2_name": "Subtle Emotion Detection",
    "definition": "The computational task of identifying and analyzing low-intensity, short-duration, or long-term emotional states from visual and behavioral cues that are difficult for humans to perceive.",
    "aliases": [
      "subtle emotion recognition",
      "micro-expression detection",
      "long-term emotion detection",
      "short duration emotion analysis",
      "subtle visual emotion perception",
      "deep event emotion analysis",
      "understanding subtle user emotional states",
      "public emotion detection"
    ],
    "topic_ids": [
      98
    ]
  },
  {
    "l2_name": "Subtle Facial Movement Analysis",
    "definition": "The computational detection and analysis of minute facial motions and expressions, often in the presence of occlusion or noise.",
    "aliases": [
      "subtle facial motion analysis",
      "micro-expression analysis",
      "subtle movement detection",
      "facial motion analysis",
      "subtle facial expression analysis"
    ],
    "topic_ids": [
      8
    ]
  },
  {
    "l2_name": "Temporal Dependency Modeling",
    "definition": "The computational task of capturing and representing dynamic, long-term, and contextual dependencies within sequential or spatiotemporal data.",
    "aliases": [
      "temporal dynamics modeling",
      "dynamic sequence analysis",
      "long-term dependency modeling",
      "spatiotemporal dependency modeling",
      "sequential pattern recognition",
      "temporal alignment",
      "contextual temporal modeling",
      "dynamic expression analysis",
      "modality dependency modeling",
      "utterance independent modeling"
    ],
    "topic_ids": [
      0
    ]
  },
  {
    "l2_name": "Temporal Emotion Analysis",
    "definition": "The study of how emotions evolve, fluctuate, and are represented across time dimensions including duration, rhythm, and spatiotemporal contexts.",
    "aliases": [
      "temporal emotion modeling",
      "spatiotemporal emotion analysis",
      "emotion dynamics",
      "temporal emotion mapping",
      "diurnal emotion rhythm",
      "temporal duration effects",
      "time-dependent emotion analysis"
    ],
    "topic_ids": [
      77
    ]
  },
  {
    "l2_name": "Unseen Emotion Classification",
    "definition": "The task of identifying and categorizing emotional states that were not present in the training data, often utilizing semi-supervised or unsupervised learning techniques.",
    "aliases": [
      "unseen emotion recognition",
      "zero-shot emotion classification",
      "semi-supervised emotion analysis",
      "unsupervised emotion classification",
      "open-set emotion recognition",
      "novel emotion detection"
    ],
    "topic_ids": [
      111
    ]
  },
  {
    "l2_name": "Unsupervised Domain Adaptation",
    "definition": "The problem of adapting a model trained on a labeled source domain to perform well on an unlabeled target domain despite distribution shifts.",
    "aliases": [
      "UDA",
      "unsupervised adaptation",
      "domain shift",
      "cross-domain adaptation",
      "multi-source domain adaptation",
      "domain mismatch"
    ],
    "topic_ids": [
      66
    ]
  },
  {
    "l2_name": "Valence-Arousal Estimation",
    "definition": "The computational task of predicting continuous dimensional values for valence and arousal to quantify emotional states.",
    "aliases": [
      "arousal estimation",
      "valence estimation",
      "dimensional valence-arousal estimation",
      "continuous valence arousal estimation",
      "valence and arousal estimation",
      "arousal and valence estimation",
      "VA estimation",
      "in-the-wild arousal estimation",
      "in-the-wild valence estimation"
    ],
    "topic_ids": [
      52
    ]
  },
  {
    "l2_name": "Visual Emotion Analysis",
    "definition": "The computational task of recognizing, interpreting, and analyzing emotional content within visual art such as paintings.",
    "aliases": [
      "visual emotion recognition",
      "painting emotion analysis",
      "master painting emotion analysis",
      "visual art emotion recognition",
      "emotion-aware visual perception",
      "emotional visual art comprehension",
      "source-free visual emotion adaptation",
      "visual emotion analysis generalizability"
    ],
    "topic_ids": [
      91
    ]
  }
]
